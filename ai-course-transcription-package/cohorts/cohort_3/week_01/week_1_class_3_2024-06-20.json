{
  "source_url": "https://aitra-main.s3.us-east-2.amazonaws.com/afdp_cohort_3_recordings/week_1_class_3_2024-06-20.mp4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA6ELKOKYDDOCGTW4H%2F20250814%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20250814T194307Z&X-Amz-Expires=3600&X-Amz-Signature=196177c74d0647e74cf1cd55e4c6c30f373f8f8f99b69132badf7847718030ff&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject",
  "duration": 4596.224,
  "language": "en",
  "processing_time": 400.44578313827515,
  "segments_count": 1532,
  "transcript_text": "[00:19 - 00:23] that recording, eight o'clock on the dots.\n[00:23 - 00:26] All right, the waiting room thing is gonna,\n[00:26 - 00:30] gonna be tricky for me for a little bit.\n[00:30 - 00:34] All right, folks, thank you for joining.\n[00:34 - 00:35] Happy Thursday.\n[00:37 - 00:40] Let's, we actually got quite a bit to go over.\n[00:40 - 00:42] So it'll probably be a quick,\n[00:42 - 00:43] I'm gonna go ahead and assume\n[00:43 - 00:44] that most of them are comfortable\n[00:44 - 00:46] with getting the environment set up.\n[00:46 - 00:49] So it might just be a kind of quick overflow over\n[00:50 - 00:51] how to get all those things down.\n[00:52 - 00:53] First things first, I'd like to go ahead\n[00:53 - 00:56] and set a questions thread on the Slack channel.\n[00:56 - 01:01] So if you have any questions that you don't feel like\n[01:01 - 01:04] you want to kind of announce\n[01:04 - 01:06] to the, you know, you don't want to use your voice,\n[01:06 - 01:09] that's totally okay, I highly recommend you\n[01:09 - 01:11] share your questions on the questions thread.\n[01:11 - 01:14] I'll make sure to keep an eye on the Slack channel.\n[01:15 - 01:17] But yeah, if I've missed something in writing,\n[01:17 - 01:18] by all means please give me a shout out.\n[01:18 - 01:21] I do occasionally miss when messages\n[01:21 - 01:22] are coming either from the questions\n[01:22 - 01:24] that I had in the Zoom chat or things like that.\n[01:24 - 01:26] So generally, I prefer Slack,\n[01:26 - 01:28] that's just my big heads amount of mountain.\n[01:30 - 01:32] All right, happy Thursday.\n[01:32 - 01:33] Welcome back.\n[01:33 - 01:35] Let's share my screen.\n[01:35 - 01:40] Let's get started and then yeah, that's our first page.\n[01:42 - 01:45] All right, so folks, today we are diving into,\n[01:45 - 01:47] today's a little bit of a combination\n[01:47 - 01:49] of both kind of working and code in VS code\n[01:49 - 01:51] and working with a platform.\n[01:52 - 01:54] LangSmith is essentially where we're going to be\n[01:54 - 01:55] not quite hosting our code,\n[01:55 - 01:58] but essentially comparing and letting our code operate\n[01:58 - 02:01] and allows to actually evaluate\n[02:01 - 02:03] whether our LLMs are operating in a way\n[02:03 - 02:05] that's beneficial for us.\n[02:05 - 02:07] This is going to be a very introductory first session.\n[02:07 - 02:10] The idea is being like introduce you to\n[02:10 - 02:14] what LangSmith is able to do behind the scenes\n[02:14 - 02:19] and what it can do for you as one of like,\n[02:19 - 02:21] as one of the tools that you're going to,\n[02:21 - 02:25] that we're going to be using for most of our LLM creation\n[02:25 - 02:28] fine tuning experimentation, all of that.\n[02:29 - 02:33] Which is kind of, so I know with what speed\n[02:33 - 02:37] and what kind of cadence I should be talking about\n[02:37 - 02:38] our concepts today.\n[02:38 - 02:39] Can I get a thumbs up from folks\n[02:39 - 02:46] if you've worked with LangSmith before?\n[02:46 - 02:48] And Lang, Lang, Lang, okay, okay.\n[02:48 - 02:50] Cool, all right.\n[02:50 - 02:51] I'll pick it slow then.\n[02:51 - 02:56] With that said, I have all of our,\n[02:56 - 02:57] like all of our repo was already shared\n[02:57 - 03:00] on the Slack channel, so I'm going to go ahead and ask you\n[03:00 - 03:03] to go ahead and fork if you need to\n[03:03 - 03:07] or just clone this repository, whichever one you want it.\n[03:07 - 03:09] If you don't fork it, it's fine by me.\n[03:09 - 03:12] But if you want to go ahead and clone this repository\n[03:12 - 03:14] and you can go ahead and see the slides\n[03:14 - 03:15] that we're going to be using today\n[03:15 - 03:18] as part of the slides folder, there are only eight slides\n[03:18 - 03:19] and I'm not going to be doing a lot of swapping\n[03:19 - 03:20] between the slides.\n[03:20 - 03:24] Just going to be a point where I hit the code element.\n[03:24 - 03:26] And a lot of the rest of the classes\n[03:26 - 03:29] just going to be me navigating through the LangSmith\n[03:29 - 03:34] and my VS code environment and the LangSmith platform.\n[03:36 - 03:40] So I won't be coming back too much to the slides itself,\n[03:40 - 03:44] but if you still want to recognize where we are\n[03:44 - 03:48] in at which portion of the class,\n[03:48 - 03:51] just think of the slides as chapters, for example.\n[03:51 - 03:54] But I just want to kind of try to minimize\n[03:54 - 03:57] a lot of my screen swapping here.\n[03:57 - 04:04] So with that said, good job on day one, welcome to day two.\n[04:04 - 04:05] And great job on some of the assignments.\n[04:05 - 04:08] I know Jonathan's been going over like overseeing\n[04:08 - 04:11] some of the home of some of the assignments\n[04:11 - 04:13] and some of the some of the submissions\n[04:13 - 04:14] you've been making.\n[04:14 - 04:15] I've been hearing some really cool stories\n[04:15 - 04:17] on the little bit that I've been able to see\n[04:17 - 04:18] and we're seeing some really cool stuff.\n[04:18 - 04:20] So keep up the wild squirrels.\n[04:20 - 04:24] That is an inside jump between Jonathan and me\n[04:24 - 04:28] regarding some of the LLM tools that you've been turning in.\n[04:28 - 04:29] So let's go ahead and get started.\n[04:29 - 04:30] What are we going to be doing today?\n[04:30 - 04:31] Or what are we going?\n[04:31 - 04:34] What can we expect to be done with at the end of the day?\n[04:34 - 04:35] We're going to introduce you to LangSmith.\n[04:35 - 04:37] You're going to have a chance to create an account.\n[04:37 - 04:41] You're going to have a chance to create your own API key with them.\n[04:41 - 04:43] We're going to talk a little bit about how to set it up,\n[04:43 - 04:47] how to kind of create your own free account with LangSmith.\n[04:47 - 04:51] Now there are a number of tiers available in LangSmith.\n[04:52 - 04:55] Kind of can get a little bit too,\n[04:55 - 04:58] it can be a little bit pricey after a certain amount of use.\n[04:58 - 05:02] So we are also going to showcase and recommend\n[05:02 - 05:06] and potentially depending on how our comfort developers\n[05:06 - 05:07] operate and how comfortable we're feeling\n[05:07 - 05:08] with one tool versus the other.\n[05:08 - 05:12] We may end up adopting some of a very similar product\n[05:12 - 05:14] called LangFuse.\n[05:14 - 05:17] Think of it as an open source version of LangSmith.\n[05:17 - 05:19] We're going to do a little bit of coding.\n[05:19 - 05:25] We're going to send some LLM code up to the LangSmith platform\n[05:25 - 05:26] and we're going to be able to see\n[05:26 - 05:28] how those calls operate within LangSmith.\n[05:28 - 05:30] And we're going to be able to really manually,\n[05:30 - 05:35] very manually access and create some data sets within LangSmith.\n[05:35 - 05:37] And hopefully if we have time,\n[05:37 - 05:39] I do have a little bit of code, a little bit of the script\n[05:39 - 05:47] to use some of the generated content that GPT creates\n[05:47 - 05:53] to use as prompts in order to improve the,\n[05:53 - 05:57] use the prompts, use the code that GPT creates to prompt\n[05:57 - 05:59] and create and improve some of the code\n[05:59 - 06:02] we build down around all of this on LangSmith.\n[06:02 - 06:03] But what is really like this meant?\n[06:03 - 06:07] So essentially a platform of tools and services\n[06:07 - 06:10] that is built into the link chain or built with link chain\n[06:10 - 06:14] to really help us build a debug and monitor some of the LLMs\n[06:14 - 06:18] that we're going to be creating and building applications for.\n[06:18 - 06:20] This is a tool that sort of adds,\n[06:20 - 06:23] it creates a one stop, one stop place for all\n[06:23 - 06:26] of the different steps from tracking, debugging,\n[06:26 - 06:29] creating, looking at a history of all of the LLM calls\n[06:29 - 06:32] helps us build some insights into some of the systems\n[06:32 - 06:35] that are happening behind the scenes.\n[06:35 - 06:38] It'll allow us to look at the monitor,\n[06:38 - 06:42] the performance of the LLM and really the debugging aspect\n[06:42 - 06:46] of LangSmith is actually really powerful.\n[06:46 - 06:52] It's really interesting to be able to see every step of code.\n[06:52 - 06:56] It's fun to see like it's not necessarily building\n[06:56 - 07:00] a kind of error prompting for every little block of code.\n[07:00 - 07:02] But to a certain extent, it will tell you\n[07:02 - 07:03] where there might be limitations,\n[07:03 - 07:07] there were there might be blockers at which particular component.\n[07:07 - 07:09] And that was something that I ended up working with today\n[07:09 - 07:12] because as we continue to improve some of the curriculum,\n[07:12 - 07:14] I was like building it into LangSmith,\n[07:14 - 07:20] we were able to see where some of the models were getting hung up.\n[07:20 - 07:25] It's also really cool tool for user interaction\n[07:25 - 07:28] in the sense of how to score and how to evaluate your results.\n[07:28 - 07:29] We're going to see Bob.\n[07:29 - 07:35] I'm going to just show you some of the evaluation tools\n[07:35 - 07:36] that LangSmith has.\n[07:36 - 07:39] We're not going to be spending too much time on that today.\n[07:39 - 07:42] But I am going to show you how you can either through yourself\n[07:42 - 07:44] or through a fellow team member,\n[07:44 - 07:46] you can evaluate some of the responses\n[07:46 - 07:49] that your GPT creates.\n[07:49 - 07:52] And of course, it's always good for an environment\n[07:52 - 07:55] to store your LLM responses.\n[07:55 - 07:59] So with that said, any questions before I move forward?\n[08:00 - 08:04] So this is pretty much about all we're going to do with the slides.\n[08:04 - 08:06] I'm going to go ahead and just start us off\n[08:06 - 08:10] by navigating over to the repository.\n[08:10 - 08:14] While I was talking, I'm hoping you've had a chance to fork\n[08:14 - 08:15] and clone this repository.\n[08:15 - 08:17] We're going to go through very similar steps\n[08:17 - 08:20] to what we did yesterday.\n[08:20 - 08:24] My advice at this point is for the most part,\n[08:24 - 08:28] a lot of our packages are going to be very similar.\n[08:28 - 08:30] So we are adding a couple of extra requirements\n[08:30 - 08:31] to our TXT file.\n[08:31 - 08:36] So in this case, we are including both LangSmith and LangFuse.\n[08:36 - 08:38] I'm actually going to be incorporating python.end\n[08:38 - 08:41] and the LangShave Hub.\n[08:41 - 08:44] This, the beautiful suit for, I do recommend\n[08:44 - 08:47] you have your own environment set up for that\n[08:47 - 08:50] because it can be a little bit tricky sometimes\n[08:50 - 08:53] to depending on your versions of a beautiful suit\n[08:53 - 08:56] to access with one of these tools.\n[08:56 - 09:02] So I just want to make sure, if I need to go through this step,\n[09:02 - 09:05] is there anyone who reads through this list of steps\n[09:05 - 09:11] and is a little like, I'm not super comfortable with this?\n[09:11 - 09:13] You can go ahead and give me a thumbs up.\n[09:13 - 09:13] Like no harm, no fault.\n[09:13 - 09:15] Otherwise, I'm just going to go straight\n[09:15 - 09:17] into assuming that your environment is set up\n[09:17 - 09:19] and you're good to go.\n[09:19 - 09:22] I see one on, which is a good thing.\n[09:22 - 09:25] I'm OK with that.\n[09:25 - 09:26] And if you're having trouble with this,\n[09:26 - 09:29] OK, you're welcome to go back to class number one.\n[09:29 - 09:31] We had a walkthrough of this session.\n[09:31 - 09:32] These instructions are super clear.\n[09:32 - 09:34] So if you have any trouble with that,\n[09:34 - 09:36] give me a call out, give me a shout out.\n[09:36 - 09:39] And sorry, I didn't mean to call anyone out specifically there.\n[09:39 - 09:41] I actually, that really helps me in terms of feedback.\n[09:41 - 09:43] That means like, cool, we can get going.\n[09:43 - 09:44] We can get ahead and get moving.\n[09:44 - 09:49] So yeah, if you have your environment set up,\n[09:49 - 09:55] I'm going to be doing my first initial bit of code in VSCount.\n[09:55 - 09:57] I like to use its terminal there in that environment.\n[09:57 - 10:00] And I'm going to go ahead and ask you,\n[10:00 - 10:02] give you a couple of minutes to kind of settle in.\n[10:02 - 10:05] You have any questions?\n[10:05 - 10:06] Good.\n[10:06 - 10:07] Yeah, no, I get it.\n[10:07 - 10:08] No harm, no foul.\n[10:08 - 10:11] It is, like I said, I want to know,\n[10:11 - 10:14] I want to keep up to the pace that works for you.\n[10:14 - 10:16] But here's what I'm going to do first.\n[10:16 - 10:18] We're essentially going to start this lecture off\n[10:18 - 10:24] with a little bit of a demo of the session itself.\n[10:24 - 10:29] And in this case, we actually are calling the,\n[10:29 - 10:30] because this is, I think, some of the code\n[10:30 - 10:31] from the documentation directly,\n[10:31 - 10:40] we're actually calling OpenAI directly from the OpenAI API\n[10:40 - 10:43] from its own API instead of, like, directly from Langston.\n[10:43 - 10:44] And the reason for that is I do want\n[10:44 - 10:47] to be able to just kind of loss over a little bit\n[10:47 - 10:49] about what these tools are doing.\n[10:49 - 10:52] So the OpenAI is coming directly from OpenAI.\n[10:52 - 10:55] I think this is the only instance where we use that.\n[10:55 - 10:58] But Langston and Langshane offer a couple of different wrappers\n[10:58 - 11:02] and decorators that we're going to be using in our code.\n[11:02 - 11:06] Again, this is intended to be able to fit the packages\n[11:06 - 11:11] that we're using within the Langshane framework.\n[11:11 - 11:15] This is also a lecture, we'll talk a little bit about how\n[11:15 - 11:18] the chains actually operate in the Python code.\n[11:18 - 11:21] So wrap OpenAI is going to be a wrapper\n[11:21 - 11:24] that we're going to be using for accessing the OpenAI\n[11:24 - 11:27] within the Langshane framework.\n[11:27 - 11:28] Traceable is going to be a decorator\n[11:28 - 11:31] that we're going to be using for some of the code\n[11:31 - 11:32] in order to commute.\n[11:32 - 11:37] Essentially, think of it as a way to aim to Langshanith\n[11:37 - 11:42] that an operation is being performed with Langshanith.\n[11:42 - 11:44] And we'll be able to see the code that we're running\n[11:44 - 11:51] in our local environment on the Langshanith framework.\n[11:51 - 11:52] With that said, the code behind this\n[11:52 - 11:55] is essentially just going to be creating a decorator\n[11:55 - 11:56] over the pipeline.\n[11:56 - 12:00] We're just going to create a very simple hello world\n[12:00 - 12:06] just going to be asking our LLM to communicate just\n[12:06 - 12:08] a very simple prompt.\n[12:08 - 12:12] Before we run this command, I do want\n[12:12 - 12:14] to make sure that we talk a little bit about making\n[12:14 - 12:18] sure that you have your OpenAI keys set up.\n[12:19 - 12:22] One more thing to make sure we're set here.\n[12:27 - 12:31] And then we'll make sure to create an account in Langshanith\n[12:31 - 12:33] after that.\n[12:33 - 12:40] So hang on there.\n[12:40 - 12:46] So this is PT, which we'll post.\n[12:46 - 12:51] And then this is AI school.\n[12:51 - 12:55] Let's go to Langshanith, let's do that up.\n[12:55 - 12:59] And what am I doing here?\n[12:59 - 12:59] Yeah.\n[12:59 - 13:10] So what I want to showcase is the environment here.\n[13:10 - 13:13] All right, so showcasing a little bit of my keys,\n[13:13 - 13:14] these are going to be deleted after today.\n[13:14 - 13:18] So if you do just add to showcase those, that's fine.\n[13:18 - 13:21] But what are we going to need for today?\n[13:21 - 13:23] Is I'm going to need you to have access to the API key\n[13:23 - 13:25] for OpenAI.\n[13:25 - 13:28] We're going to go to Langshanith and Langshanith\n[13:28 - 13:31] to access both the API keys from them.\n[13:31 - 13:34] And we're also going to be accessing Langshanith\n[13:34 - 13:36] just as a demo process.\n[13:36 - 13:41] So once you have that built into your.environment file,\n[13:41 - 13:44] you're either welcome to use that in your.environment file.\n[13:44 - 13:48] Or you can also use the code from that load environment,\n[13:48 - 13:51] or from load.environment to include that\n[13:51 - 13:55] in the environment you created.\n[13:55 - 13:57] I'm still using, where I should still be using.\n[14:01 - 14:05] Second, there.\n[14:05 - 14:07] Okay, I'm not actually operating in my environment,\n[14:07 - 14:10] so I'll fix that in just a moment.\n[14:10 - 14:14] But what we're going to be doing first from here\n[14:14 - 14:19] is actually just opening up an instance of Langshanith.\n[14:20 - 14:26] So Langshanith is pretty straightforward to open up.\n[14:26 - 14:31] Just go over to the, just do a quick search for it.\n[14:31 - 14:33] You actually can go into the sign-up session.\n[14:33 - 14:35] I've already created an account with BloomTech,\n[14:35 - 14:40] but I want you to get first through this section here.\n[14:40 - 14:50] This is the first part where we're going to be calling out information.\n[14:50 - 14:51] And once you've created an account,\n[14:51 - 14:55] usually there's a little bit of a series of prompts.\n[14:55 - 14:57] Because your dashboard have got zero projects\n[14:57 - 14:59] I've essentially been deleting everything\n[14:59 - 15:21] as I've been creating it, but that was there for a second.\n[15:21 - 15:24] And from here, you can actually create your own API keys\n[15:24 - 15:26] from going over to the settings,\n[15:26 - 15:29] and simply create an API key.\n[15:29 - 15:32] Now, hopefully you selected your free billing.\n[15:32 - 15:35] The cut, we're not really going to be paying\n[15:35 - 15:36] for the $39 per month.\n[15:39 - 15:42] We've been going hard on Langshanith all month,\n[15:42 - 15:46] and I still haven't gotten close to the 5,000 free traces.\n[15:46 - 15:51] So we should be able to use this for a significant run\n[15:51 - 15:53] of the lectures and class.\n[15:53 - 15:57] But if you don't end up having trouble with that,\n[15:57 - 16:00] I do want to go ahead and also recommend\n[16:00 - 16:03] the Langfuse environment.\n[16:03 - 16:08] So Langfuse is a very similar project to Langsmith.\n[16:09 - 16:12] It's just intended to be much more open-sourced.\n[16:12 - 16:14] You can access the tool by logging in.\n[16:14 - 16:15] It's very similar.\n[16:15 - 16:18] You can see we played around with this just a little bit\n[16:18 - 16:20] on this today, but a lot of the framework\n[16:20 - 16:22] is going to be very similar.\n[16:22 - 16:23] And a lot of the things you can do here\n[16:23 - 16:27] are going to follow a lot of the same processes.\n[16:27 - 16:30] It allows you to kind of create that evaluation process.\n[16:30 - 16:34] I don't expect it to necessarily seem like no, what's going on.\n[16:34 - 16:38] But we'll have a much more in-depth tour in just a moment.\n[16:38 - 16:41] But I just wanted to highlight that between these two tools\n[16:41 - 16:45] we've got a very similar framework\n[16:45 - 16:48] or a similar user experience.\n[16:48 - 16:50] So you can go from here to the settings.\n[16:50 - 16:53] At this point, it's a little bit different\n[16:53 - 16:57] in the sense that for Langfuse, you're actually creating\n[16:57 - 16:59] and you're actually going to need both a secret key\n[16:59 - 17:01] and a public key.\n[17:01 - 17:05] So make sure you have both of those elements set up.\n[17:05 - 17:11] Once you've had a chance to do that,\n[17:11 - 17:18] your environment should hopefully look a little bit like this.\n[17:18 - 17:30] That's not where we're at.\n[17:30 - 17:32] But your environment should look something like this.\n[17:32 - 17:34] And the only parts that you need to include\n[17:34 - 17:37] are the your super secret key elements for OpenAI.\n[17:37 - 17:42] That's the one that BloomTech is sharing with you.\n[17:42 - 17:44] So that's on Slack, Langshane API key.\n[17:44 - 17:47] That's going to be the same one you can use for Langsmith.\n[17:47 - 17:50] And your super secret key for Langfuse\n[17:50 - 17:52] just make sure to include that in your secret key.\n[17:52 - 17:56] But also make sure that your public key is also included there.\n[17:56 - 18:00] And I'll give you a minute to get that set up.\n[18:00 - 18:04] Really, when it comes to setting up Langfuse Langshane,\n[18:04 - 18:06] that's it.\n[18:06 - 18:14] It's not easy.\n[18:14 - 18:18] So again, not trying to rush there.\n[18:18 - 18:20] We're just trying to go over a couple\n[18:20 - 18:21] like quite a bit of things\n[18:21 - 18:22] and I want to make sure that you're set up.\n[18:22 - 18:25] But I'm going to do a quick check-in.\n[18:25 - 18:27] You're feeling okay.\n[18:27 - 18:31] Let's keep it going.\n[18:31 - 18:33] Okay.\n[18:33 - 18:34] So with that said,\n[18:34 - 18:38] really all that I'm doing with this demonstration\n[18:38 - 18:40] is essentially just showcasing what,\n[18:40 - 18:42] like how to connect our local computer\n[18:42 - 18:44] to the Langsmith framework.\n[18:44 - 18:47] So what happens here is that all I'm really doing\n[18:47 - 18:52] is essentially creating a decorator\n[18:52 - 18:53] that's going to take this function.\n[18:53 - 18:56] It's going to create essentially\n[18:56 - 19:01] invoke a specific invoke in Langsmith,\n[19:02 - 19:04] I'm sorry, the language for me is still stuck\n[19:04 - 19:06] on the Langsmith language.\n[19:06 - 19:11] But with the base open AI tool,\n[19:11 - 19:13] we're simply just creating a chat objects\n[19:13 - 19:15] to create a series of messages.\n[19:15 - 19:17] Again, this is the role that we created earlier.\n[19:17 - 19:21] We're creating a user-based message.\n[19:21 - 19:25] The content's going to come from us here.\n[19:25 - 19:28] We're going to be using the 3.5 to do the turbo.\n[19:28 - 19:31] And then simply put all I'm going to have it do is\n[19:31 - 19:34] just do a standard call out world.\n[19:34 - 19:39] Let me run a terminal right here in this environment, perfect.\n[19:39 - 19:46] And it's going to be Python 3 in class.\n[19:46 - 19:49] You get down one level there so that I'm\n[19:49 - 19:51] not typing back for much.\n[19:51 - 19:53] Yeah, perfect.\n[19:53 - 19:58] So Python 3 for me in class,\n[19:58 - 20:04] and this one's the Langsmith demo.\n[20:04 - 20:08] Come on, I can type.\n[20:08 - 20:09] All right, so pretty straightforward.\n[20:09 - 20:12] That's how that works, or really all I'm doing is\n[20:12 - 20:14] is having it print out the hello world in my environment.\n[20:14 - 20:19] But what I want to actually notice,\n[20:19 - 20:21] is that if we go now to our Langsmith,\n[20:21 - 20:22] we'll see that our project's popped up\n[20:22 - 20:27] on my local computer, or on my Langsmith platform.\n[20:27 - 20:29] That Langsmith platform, essentially,\n[20:29 - 20:31] you can see that I just created a moment ago.\n[20:31 - 20:33] We've got a lot of information about the tool\n[20:33 - 20:34] that I've just created.\n[20:34 - 20:36] I've only run this once.\n[20:36 - 20:38] No errors.\n[20:38 - 20:41] Pretty standard number of tokens, a little bit of information.\n[20:41 - 20:45] This is so inexpensive on my side, but it's essentially\n[20:45 - 20:49] calling the pipeline that I've created.\n[20:49 - 20:51] Again, this is under the trace pipeline\n[20:51 - 20:53] that we built a second ago.\n[20:53 - 20:55] Let me close this up as I'm not going to.\n[20:55 - 20:57] I might not, I may need that again in a second.\n[20:57 - 20:59] But all we're doing is essentially\n[20:59 - 21:02] telling that we ran this code within this environment.\n[21:02 - 21:06] And there's a lot of information that we can get from it.\n[21:06 - 21:08] It can essentially tell us what the input was,\n[21:08 - 21:13] what the output from the GBT framework returned.\n[21:13 - 21:14] You click on this.\n[21:14 - 21:16] It's essentially just a little bit more\n[21:16 - 21:18] additional data, including metadata\n[21:18 - 21:24] about the call and the output itself.\n[21:24 - 21:25] Pretty straightforward, right?\n[21:25 - 21:27] Nothing too complex from that.\n[21:27 - 21:30] But this is where things start.\n[21:30 - 21:33] If we know that our LLMs are being recorded somewhere,\n[21:33 - 21:36] it means that we can now do a lot more with this.\n[21:36 - 21:39] We can essentially take a look at how we can add this\n[21:39 - 21:40] to a data set.\n[21:40 - 21:42] We'll talk a little bit more about the annotation queue.\n[21:42 - 21:44] But the information behind this is\n[21:44 - 21:46] that we are now starting to create a framework\n[21:46 - 21:51] where we can either run it again, perhaps\n[21:51 - 21:53] with a different message.\n[21:53 - 21:54] Hello folks.\n[21:54 - 21:57] I don't know, we'll do that if we wanted to.\n[21:57 - 21:58] Pretty straightforward.\n[21:58 - 22:03] And it's going to be recorded inside the call\n[22:03 - 22:04] as its own separate call.\n[22:04 - 22:06] But it's still going to be part of the same project.\n[22:06 - 22:11] Because we traced this, this particular script\n[22:11 - 22:13] as part of this default, this project\n[22:13 - 22:16] that we just happened to name the fault.\n[22:16 - 22:19] And there's additional metadata about that.\n[22:19 - 22:24] So the same thing will happen with Langfews.\n[22:24 - 22:29] So in this case, we're using again, a very similar operator\n[22:29 - 22:34] or excuse me, decorator to the traceable decorator\n[22:34 - 22:36] that exists within LangSmith.\n[22:36 - 22:38] But the observer decorator is essentially\n[22:38 - 22:40] going to be built about around this function\n[22:40 - 22:44] that's going to be using the OpenAI chat create framework.\n[22:44 - 22:47] Again, this is all exactly the same thing\n[22:47 - 22:53] as we did with the LangSmith code.\n[22:53 - 22:55] We're just going to pull the content directly.\n[22:55 - 22:57] The decorator is going to look at the function itself,\n[22:57 - 22:59] and it's going to return that main story\n[22:59 - 23:01] or the main story function that we created here.\n[23:01 - 23:03] And again, we're just asking it's\n[23:03 - 23:05] OK, you're a great storyteller.\n[23:05 - 23:09] Fill out the rest of the content here\n[23:09 - 23:10] and what would that look like?\n[23:10 - 23:15] So if I were to run this code instead of LangSmith,\n[23:15 - 23:20] just going to take Langfews demo.\n[23:20 - 23:21] It's got a second.\n[23:21 - 23:23] Looks like it ran.\n[23:23 - 23:33] If I go over to Langfews, I should have projects.\n[23:33 - 23:37] Yeah.\n[23:37 - 23:39] Could you do?\n[23:39 - 23:42] Let's see.\n[23:42 - 23:43] OK.\n[23:43 - 23:45] So this is my full of the trace.\n[23:45 - 23:46] There you go.\n[23:46 - 23:47] Let's look it up.\n[23:47 - 23:50] Here we go.\n[23:50 - 23:50] Yep.\n[23:50 - 23:52] So here's that.\n[23:52 - 23:54] I can click on the trace detail.\n[23:54 - 23:58] And it's all essentially very similar.\n[23:58 - 23:59] Except this one's open source.\n[23:59 - 24:02] It's a little bit less expensive than LangSmith.\n[24:02 - 24:06] So everything's just kind of organized a little bit different.\n[24:06 - 24:08] So we just wanted to introduce both tools\n[24:08 - 24:13] to give you the chance to select your preferred path to work with.\n[24:13 - 24:16] And from there, you can essentially\n[24:16 - 24:20] operate from that environment.\n[24:20 - 24:22] Any questions in this case?\n[24:22 - 24:23] You don't need to use both.\n[24:23 - 24:24] You're not going to be expected to use both.\n[24:24 - 24:26] Most of the material as it's built so far\n[24:26 - 24:27] is built using LangSmith.\n[24:27 - 24:30] So it's up to you if you have a preference.\n[24:30 - 24:31] But if you're going to be putting your own credit card down,\n[24:31 - 24:33] and that's a budget as a concern,\n[24:33 - 24:38] Langfews is another option.\n[24:38 - 24:44] Moment there to see if any questions have come through.\n[24:44 - 24:45] OK, wait, one question.\n[24:45 - 24:46] Oh, hang on.\n[24:46 - 24:47] Next session, small nifty.\n[24:47 - 24:48] Irish is quite craft.\n[24:48 - 24:50] Ooh, thank you.\n[24:50 - 24:54] Up the resolution, Luke, are we talking about?\n[24:54 - 24:55] Alex, thank you for that feedback.\n[24:55 - 25:00] Sorry that I took me a second to actually look at it.\n[25:00 - 25:01] It's no rush.\n[25:01 - 25:03] It's fine for this session.\n[25:03 - 25:04] Oh, OK.\n[25:04 - 25:05] Or better?\n[25:05 - 25:06] Yeah, perfect.\n[25:06 - 25:08] Yeah, man, I can see it.\n[25:08 - 25:10] Yeah, and again, if I miss a message,\n[25:10 - 25:13] which is a thing that happens, please call me out.\n[25:13 - 25:16] That happens sometimes.\n[25:16 - 25:19] I'm not shy.\n[25:19 - 25:24] OK.\n[25:24 - 25:27] Cool, all right, so no questions about Langfews.\n[25:27 - 25:29] Let's go ahead and I'm going to go ahead for myself.\n[25:29 - 25:31] I'm going to close up Langfews because most of the rest\n[25:31 - 25:38] of the content is going to be built on top of Langfews' tool.\n[25:38 - 25:41] And that was for later.\n[25:41 - 25:44] I'm going to skip the prompting demo for right now\n[25:44 - 25:47] because that's going to make sense in a little bit\n[25:47 - 25:50] in a little bit for the next bit.\n[25:50 - 25:54] So I'm going to pull up the slides once more.\n[25:54 - 25:57] The slides I've managed to actually close up.\n[25:57 - 26:01] Sorry about that.\n[26:01 - 26:03] Yeah.\n[26:03 - 26:06] Because we've tested both of these tools.\n[26:06 - 26:07] This is Langfews.\n[26:07 - 26:09] We actually did it through this.\n[26:09 - 26:11] We're going to be spending more time next week\n[26:11 - 26:12] talking about Rags in general.\n[26:12 - 26:15] But I do want to essentially address a little bit\n[26:15 - 26:19] about how you can use Rags within Langsmiths environment\n[26:19 - 26:23] to kind of see the different steps that we've just talked about.\n[26:23 - 26:26] How do you evaluate the multiple steps\n[26:26 - 26:28] that kind of go through?\n[26:28 - 26:32] How you can eventually evaluate the individual costs\n[26:32 - 26:33] of a particular process.\n[26:33 - 26:36] Like you could actually monitor where a specific element\n[26:36 - 26:38] is potentially created.\n[26:38 - 26:40] So I'm going to be guiding the next part\n[26:40 - 26:43] of this lecture with these questions in mind.\n[26:43 - 26:46] But I don't want to have necessarily the slides open\n[26:46 - 26:48] for this whole time.\n[26:48 - 26:52] But I am going to ask that if you want to follow along,\n[26:52 - 26:54] if you want to see for yourself what this looks like\n[26:54 - 26:59] in the Langsmith environment, check out the notebook format.\n[26:59 - 27:01] And I created this in a notebook format simply\n[27:01 - 27:04] because I want to be able to talk a little bit about the couple\n[27:04 - 27:08] of different parts of the code here.\n[27:08 - 27:14] So again, some of this we'll talk more about next week.\n[27:14 - 27:20] A lot of our tools are going to be saved into the vector databases\n[27:20 - 27:23] that we're going to be using as a local database called\n[27:23 - 27:24] Chroma, more on that later on.\n[27:24 - 27:27] But essentially all of these come from the Langchain package,\n[27:27 - 27:29] including the Langchain community.\n[27:29 - 27:31] Again, Langchain community is essentially\n[27:31 - 27:34] where users can submit their own tools\n[27:34 - 27:36] or their own frameworks, models, things like that\n[27:36 - 27:41] in order to create different scrapers, web loaders,\n[27:41 - 27:45] interpreters of like beautiful text, for example,\n[27:45 - 27:48] which is web-based loader, like I don't know about you,\n[27:48 - 27:50] but once I started using this, like BS4,\n[27:51 - 27:57] it just doesn't, it works so well.\n[27:57 - 28:00] If you remember in the last class, we were adding dot content\n[28:00 - 28:03] at the end of all of our LLM calls.\n[28:03 - 28:06] String out parser is essentially Langchain's alternative\n[28:06 - 28:07] to that.\n[28:07 - 28:09] And again, this will be more about it next week.\n[28:09 - 28:12] But I do want to be familiar with that what this does\n[28:12 - 28:14] or what String out parser does essentially just\n[28:14 - 28:19] takes the output or the text-based output of the code itself.\n[28:19 - 28:22] We'll be embedding all of these tools, again,\n[28:22 - 28:25] that's going to be getting back into Chrome itself.\n[28:25 - 28:27] The other tool that you may have heard for,\n[28:27 - 28:29] you may have been familiar with this Python gun,\n[28:29 - 28:32] but that's what we're going to be working with here.\n[28:32 - 28:34] And again, recursive character text\n[28:34 - 28:38] litter, all of this are just cleaning tools.\n[28:38 - 28:39] Make sure that works.\n[28:39 - 28:41] So what I'm going to be taking is I'm\n[28:41 - 28:47] going to be accessing a specific document\n[28:47 - 28:51] from Lillian Wang from this particular GitHub,\n[28:51 - 28:55] just to showcase where we're getting our notes from.\n[28:55 - 29:00] This is a blog that's going to have pretty much instructions\n[29:00 - 29:04] on how to create autonomous agents or LLM-powered autonomous\n[29:04 - 29:06] agents.\n[29:06 - 29:08] We'll talk, feel free to read through this,\n[29:08 - 29:09] but we're not actually going to be spending too much time\n[29:09 - 29:10] on the blog.\n[29:10 - 29:13] We're actually just going to have our LLM take all of this\n[29:13 - 29:19] and summarize it for us and create it in a framework\n[29:19 - 29:25] that I can then build an agent or a mini LLM that's\n[29:25 - 29:28] going to take the data that it learned from looking\n[29:28 - 29:32] through this document to return its own answers for us.\n[29:32 - 29:36] So there's a lot of text here, again, not really worth our\n[29:36 - 29:41] time to read through it, but we can actually use some\n[29:41 - 29:46] of the LLM-chain properties, in this case, GBT3.5,\n[29:46 - 29:52] to access that website, load it, essentially re-graded into\n[29:52 - 29:56] a SUP object from beautiful SUP, which is going to take\n[29:56 - 29:58] some of the contents of none of the images,\n[29:58 - 30:01] and I want to load it into a document.\n[30:01 - 30:04] I'm going to take all of the text from that document,\n[30:04 - 30:07] and I want to split it into individual documents that's\n[30:07 - 30:09] essentially going to be what I'm going to be embedding\n[30:09 - 30:13] into the, essentially, I'm going to be embedding all of that text\n[30:13 - 30:15] into that interpretable format.\n[30:15 - 30:17] So this is doing it for me.\n[30:17 - 30:19] The code is pretty straightforward.\n[30:19 - 30:23] And then I'm going to be taking from the Community Hub,\n[30:23 - 30:26] essentially the same network where you can look at different\n[30:26 - 30:29] models, and I want to essentially be able to create a\n[30:29 - 30:36] prompt based off of that document.\n[30:36 - 30:38] This last function is essentially going to take all of that\n[30:38 - 30:40] content formatted into a document.\n[30:40 - 30:44] And I'm like, this might be some syntax that you may not\n[30:44 - 30:47] have seen, even if you've been working with Python for a while.\n[30:47 - 30:51] This is usually the like, and signifier, if you're trying\n[30:51 - 30:56] to compare two values, in LLM-chain, what this tool does is\n[30:56 - 30:59] essentially creates that step-by-step process in the chain.\n[30:59 - 31:02] And I'll showcase another example in just a moment so that\n[31:02 - 31:04] we can kind of take it slow.\n[31:04 - 31:07] But what our tool is going to be doing is essentially going to\n[31:07 - 31:10] be taking the retriever within the context that we created\n[31:10 - 31:14] above, along with the documents as we formatted.\n[31:14 - 31:16] And that the question is going to be processed through a\n[31:16 - 31:18] multiple pass through, essentially going to be\n[31:18 - 31:22] interpreting all of the content on all the embedded contents.\n[31:22 - 31:26] Finally, like after we created the prompt object, this is\n[31:26 - 31:32] as it was pulled from one of the like, the prompt that\n[31:32 - 31:36] we're creating early on, I can actually showcase what\n[31:36 - 31:40] that looks like for us.\n[31:40 - 31:49] And that prompt, as it was built out, is simply a chat\n[31:49 - 31:53] prompt template, essentially the prompt that we, like, if\n[31:53 - 31:55] you remember from last last, when we talked about like, hey,\n[31:55 - 31:57] I want you to structure my answer.\n[31:57 - 32:00] I want your answers to sort of look like this.\n[32:00 - 32:04] So the prompt itself is going to look like, let me just scroll\n[32:04 - 32:04] through this.\n[32:04 - 32:07] You're an assistant for question answering tasks.\n[32:07 - 32:10] Use the following pieces of retrieved context to answer\n[32:10 - 32:11] the question.\n[32:11 - 32:13] If you don't know the answer, just say you don't know, but\n[32:13 - 32:15] three cents and maximum keep the answer concise.\n[32:15 - 32:19] This is something that a different user has built.\n[32:19 - 32:23] And again, this is all essentially going to be what it\n[32:23 - 32:26] returns for the document that we created or that we move\n[32:26 - 32:28] from online.\n[32:28 - 32:32] So when we created that prompt, we're\n[32:32 - 32:35] accessing, we're telling the prompt to, we're\n[32:36 - 32:41] telling our LLM to build answers using that prompt.\n[32:41 - 32:45] And finally, the last step is going to be to, like, to\n[32:45 - 32:51] output the answer or the answer that the LLM invoked as\n[32:51 - 32:53] essentially a string text.\n[32:53 - 32:57] So this case, what I'm trying to do is take all of the\n[32:57 - 33:04] information from this document and tell me what is task\n[33:04 - 33:08] to composition for the record.\n[33:08 - 33:11] This is something that I technically advise with folks\n[33:11 - 33:15] when I've been working for them like longer class sessions.\n[33:15 - 33:17] I grew up in Puerto Rico, English is actually my second\n[33:17 - 33:18] language.\n[33:18 - 33:21] So there's a B words that occasionally like, I don't\n[33:21 - 33:22] pronounce correctly.\n[33:22 - 33:23] You'll free to call me out.\n[33:23 - 33:27] It's always a fun time.\n[33:27 - 33:28] But there are some words that I'm going to look at\n[33:28 - 33:30] and I'm like, to composition, the composition never\n[33:30 - 33:32] quite sure how it's pronounced.\n[33:32 - 33:33] But yeah, so the answer we get from this is tasked\n[33:33 - 33:36] composition together like, OK, we're familiar with that\n[33:36 - 33:36] part.\n[33:36 - 33:37] We understand what happens.\n[33:37 - 33:41] We can expect that the answer from that is going to be\n[33:41 - 33:46] built from the, is going to be built in their summer from\n[33:46 - 33:48] from the document that it returned.\n[33:48 - 33:50] That's not the point of what we're trying to do.\n[33:50 - 33:55] We're trying to see how this worked within the framework\n[33:55 - 33:57] of our LLAMG Smith environment.\n[33:57 - 34:00] So that ran properly.\n[34:00 - 34:08] We should have built, let's see where that put.\n[34:08 - 34:09] Yep, there we go.\n[34:09 - 34:12] Inside our default, inside our default process, you'll see\n[34:12 - 34:16] this runable sequence object.\n[34:16 - 34:19] And here, we do a dropdown.\n[34:19 - 34:21] We're actually beginning to see all of the different\n[34:21 - 34:25] tasks that we just created, including that final answer,\n[34:25 - 34:29] like that final answer, what is tasked composition.\n[34:29 - 34:30] And we can start to see that there are all of the\n[34:30 - 34:34] different steps are listed for us, including but not\n[34:34 - 34:39] limited the input that the model essentially decided to\n[34:39 - 34:43] incorporate what is tasked composition and the context of\n[34:43 - 34:47] what it built, the, like, what context it actually used to\n[34:47 - 34:49] create the answer.\n[34:49 - 34:51] The prompt template, remember what we said earlier, is\n[34:51 - 34:59] essentially, how to create, where is that?\n[34:59 - 35:02] Yeah, how to create what the, like, what, like, what that\n[35:02 - 35:04] content would look like.\n[35:04 - 35:07] And the chat, like, the chat, the, the, the, the year we got.\n[35:07 - 35:08] This is what it was looking for.\n[35:08 - 35:11] So this is what it would look like if we were answering this\n[35:11 - 35:13] within a chat, open AI framework.\n[35:13 - 35:15] This was us answering the question.\n[35:15 - 35:20] There is the prompt that we hold from the community light\n[35:20 - 35:22] from the length and community hub.\n[35:22 - 35:25] And it essentially was able to create and output that\n[35:25 - 35:28] within that specific, within that specific prompt\n[35:28 - 35:29] structure.\n[35:29 - 35:33] At the string out parser, like we discussed earlier,\n[35:33 - 35:36] was essentially being able to take all of that information and\n[35:36 - 35:40] remove all of the additional data that metadata and call\n[35:40 - 35:42] that information as a string.\n[35:42 - 35:45] So what I like about this is that it's already beginning to\n[35:45 - 35:47] tell you and create, give you a lot of additional information\n[35:47 - 35:49] about the tool itself.\n[35:49 - 35:54] We can look at how long it took 1.54 seconds to run from\n[35:54 - 35:55] beginning to end.\n[35:55 - 35:59] We can look at other elements, including how much did\n[35:59 - 36:05] each particular step where we had to invoke the open AI\n[36:05 - 36:08] processes or the, like the parts that cost money, we can\n[36:08 - 36:11] actually begin to incorporate that.\n[36:11 - 36:14] So this guy's not, you know, negligibly expensive.\n[36:14 - 36:16] But of course, it's going to be much more expensive than\n[36:16 - 36:19] we're incorporating additional information.\n[36:19 - 36:24] The documents that we pulled again were pulled from the,\n[36:24 - 36:26] from the Lillian Wing website.\n[36:26 - 36:30] And that can be determined based off of the,\n[36:30 - 36:32] based off of this tool.\n[36:32 - 36:36] So we can see that as part of our chat prompt template.\n[36:36 - 36:39] We can see that from where we got the information itself.\n[36:39 - 36:42] So it's essentially seeing that it is built to follow the\n[36:42 - 36:46] same steps that we built in our local environment.\n[36:46 - 36:50] And that context essentially is created here in our code\n[36:50 - 36:54] from the very beginning.\n[36:54 - 36:57] So these components are essentially intended for us to then\n[36:57 - 37:00] make certain choices as to what we want to do with it.\n[37:00 - 37:02] Like, is there a specific test?\n[37:02 - 37:04] Is there a specific output that we're interested in working\n[37:04 - 37:08] with a little bit more, a little bit more fully?\n[37:08 - 37:11] Perhaps that's going to be the next thing we're going to be\n[37:11 - 37:13] talking about in just a moment.\n[37:13 - 37:17] So if I'm the last question is, this is a question I'm going\n[37:17 - 37:21] to pose for you, given your ability to kind of explore this\n[37:21 - 37:25] or your, like, from what we're seeing here,\n[37:25 - 37:27] do you get the sense that you're able to, can you determine\n[37:27 - 37:33] what the response should I put this question?\n[37:33 - 37:37] How do I find this question?\n[37:37 - 37:39] What are some of the methods?\n[37:39 - 37:41] What are some of the methods?\n[37:41 - 37:43] What comes to mind as far as usefulness for something\n[37:43 - 37:46] like this, particularly if you're working\n[37:46 - 38:00] within a team dynamic?\n[38:00 - 38:14] This is a leading question to some extent.\n[38:14 - 38:16] I don't have a good sense of this tool yet.\n[38:16 - 38:19] But if I had to make an assumption, if different parts of the\n[38:19 - 38:23] team are working on different parts of the overall process,\n[38:23 - 38:27] this gives you that granularity to see what exactly each\n[38:27 - 38:29] piece is doing, how it's configured, how it's performing,\n[38:29 - 38:31] how much it costs, et cetera, et cetera.\n[38:31 - 38:34] So I guess it gives you a better cross functional visibility.\n[38:34 - 38:36] But again, that's for that a lot of context.\n[38:36 - 38:37] For sure.\n[38:37 - 38:39] And what happens if, you know, for another example,\n[38:39 - 38:41] perhaps one day if you're not a fan of like,\n[38:41 - 38:44] what if you have someone who's suggesting that open AI maybe\n[38:44 - 38:46] that that enthropic may be a better model\n[38:46 - 38:49] to use in a specific scenario?\n[38:49 - 38:50] What is this useful for?\n[38:50 - 38:52] Well, like you can actually come up with like a particular,\n[38:52 - 38:55] you can create different projects that actually compare,\n[38:55 - 38:58] like that you can actually compare the different models\n[38:58 - 39:01] at the different steps the model is taking.\n[39:01 - 39:02] So you can actually monitor speed.\n[39:02 - 39:04] You can actually monitor price.\n[39:04 - 39:08] You can actually monitor a lot of like back granularity\n[39:08 - 39:10] that you're talking about Ryan can essentially be incorporated\n[39:10 - 39:13] with tools like this to then compare what's the best tool\n[39:13 - 39:14] for the job?\n[39:14 - 39:18] Any other comments or thoughts to face?\n[39:18 - 39:20] I'm guessing that also really helps you\n[39:20 - 39:22] understand if different pieces are built\n[39:22 - 39:24] by different team members, the place and where they touch\n[39:24 - 39:26] and how they may be interacting incorrectly there?\n[39:26 - 39:28] For sure.\n[39:28 - 39:30] And yeah, with essentially being a part of a team\n[39:30 - 39:32] just kind of sharing that language,\n[39:32 - 39:35] like that language, like that language key,\n[39:35 - 39:37] you can essentially begin to create a specific set,\n[39:37 - 39:40] like you can essentially begin to really dive\n[39:40 - 39:43] into the nitty gritty of like what your model is doing.\n[39:43 - 39:45] And this is essentially how you begin\n[39:45 - 39:46] to build a successful model.\n[39:46 - 39:48] And this is essentially step one.\n[39:48 - 39:49] Of course, we're going to be diving,\n[39:49 - 39:51] we're going to be spending a lot of time here,\n[39:51 - 39:54] but I just want you to kind of take this class,\n[39:54 - 39:57] start kind of flicking around.\n[39:57 - 39:59] There's not a whole lot to click around.\n[39:59 - 40:01] The next bit that we're going to be talking about right now\n[40:01 - 40:05] is going to be a little bit more in depth.\n[40:05 - 40:07] But yeah, that's about it.\n[40:07 - 40:09] And again, next week we'll talk a little bit more\n[40:09 - 40:11] about Rags in detail so that we can kind of talk\n[40:11 - 40:15] a little bit about how those documents get embedded,\n[40:15 - 40:17] how those documents work behind the scenes.\n[40:17 - 40:20] So, that doesn't quite yet.\n[40:20 - 40:24] Let's talk a little bit, not that.\n[40:24 - 40:27] Let's talk about one more thing here.\n[40:27 - 40:30] As in order for you to do that your specific homework,\n[40:30 - 40:33] there's one of the elements that I started the class\n[40:33 - 40:35] talking about, and one of the comments\n[40:35 - 40:39] that really usually comes up with this sort of conversation.\n[40:39 - 40:44] It's like, hey, how do I know if my LLM is working?\n[40:44 - 40:49] How do I know for a fact that my output\n[40:49 - 40:51] is providing the right answer for my customers,\n[40:51 - 40:54] for my clients, for my team?\n[40:54 - 41:01] Really, how do you evaluate those specific responses?\n[41:01 - 41:03] And so, there's a couple of different answers to that.\n[41:03 - 41:06] One, you have both automated methods\n[41:06 - 41:11] and where you can essentially determine whether the model\n[41:11 - 41:15] seems to be correctly identifying a particular value.\n[41:15 - 41:17] If it's correctly identifying a specific label,\n[41:17 - 41:19] that's specifically if you're working with labeled data set.\n[41:19 - 41:24] But what if your data is necessarily\n[41:24 - 41:28] like a value that can be easily labeled?\n[41:28 - 41:32] What if it's something like, for example, a terrible joke\n[41:32 - 41:34] or what if it's something like a specific assessment\n[41:34 - 41:38] or a particular think of it as maybe a creative opinion\n[41:38 - 41:41] or even like, I don't know, a lot of the work I do,\n[41:41 - 41:45] I've been doing recently has been like trying to create\n[41:45 - 41:50] tools that work best with posting on social media in a way\n[41:50 - 41:54] that includes variety, creativity and different values.\n[41:54 - 41:58] So, how do you evaluate what makes a good social media post?\n[41:58 - 42:00] For example, the answer to that's often\n[42:00 - 42:02] similar complicated, there's some few metrics\n[42:02 - 42:05] you can evaluate from there, but beyond that,\n[42:05 - 42:06] let's kind of assess this within the context\n[42:06 - 42:11] of what makes a good dad joke for our purposes right now.\n[42:11 - 42:16] Well, it's whether your kids like you enough\n[42:16 - 42:18] to laugh at your jokes, I don't know.\n[42:18 - 42:20] What's the metric we want to use there?\n[42:20 - 42:22] Well, right now, the answer or the short answer\n[42:22 - 42:24] that I'm sort of like jumping around to is that\n[42:24 - 42:27] we can actually incorporate our own opinion\n[42:27 - 42:30] or our own evaluation with lagsmith.\n[42:30 - 42:33] And if we want to do that manual evaluation,\n[42:33 - 42:35] lagsmith allows us the chance to do that.\n[42:35 - 42:39] It also allows us the chance to create some automated processes\n[42:39 - 42:41] to evaluate those specific tools.\n[42:41 - 42:45] And we're talking more about that automated evaluation\n[42:45 - 42:46] a little bit down the line right now.\n[42:46 - 42:49] I just want to showcase, how do you incorporate\n[42:49 - 42:53] a specific output from an LLM into data value\n[42:53 - 42:55] or a data set that you can store?\n[42:55 - 42:58] And then you can create that evaluation\n[42:58 - 43:00] within lagsmiths framework.\n[43:00 - 43:05] So I'm going to go over to the lagsmith.jokes.py tool,\n[43:05 - 43:07] going back to the chat-open AI tool\n[43:07 - 43:10] from lag chain itself.\n[43:10 - 43:13] This is these other packages should be fairly familiar.\n[43:13 - 43:15] I don't actually need this,\n[43:15 - 43:17] but if you want to incorporate your code\n[43:17 - 43:21] into your environment, that's absolutely fine.\n[43:21 - 43:25] But all I'm doing here is asking open AI\n[43:25 - 43:28] to create five dad jokes.\n[43:28 - 43:31] And I want those dad jokes to be in story format.\n[43:31 - 43:32] Excuse me.\n[43:32 - 43:36] And I'm just going to have that run behind the scenes\n[43:36 - 43:41] in class examples that is lagsmith dad joke.\n[43:41 - 43:44] So we run that on its own.\n[43:44 - 43:48] And that'll take a second or two.\n[43:48 - 43:51] It's running in the lagsmith environment.\n[43:51 - 43:55] I'm going to close that up here and close this up.\n[43:55 - 43:57] Not going to need that.\n[43:57 - 43:59] That should be done running.\n[43:59 - 44:07] All right, so I took about 10 seconds.\n[44:07 - 44:09] Took about 589 tokens.\n[44:09 - 44:13] Each joke took about 2.27 seconds to run.\n[44:13 - 44:16] And we can actually start to evaluate the jokes\n[44:16 - 44:17] directly from here.\n[44:17 - 44:19] If you click on each or particular object,\n[44:19 - 44:20] we have one joke.\n[44:20 - 44:21] Jokes should be in story format.\n[44:21 - 44:23] That's about a time of dad to send tickets into the zoo, blah, blah, blah.\n[44:23 - 44:25] OK, it's probably a terrible joke.\n[44:25 - 44:26] Let's look at this next joke.\n[44:26 - 44:27] It's a little bit long when it's about 10.\n[44:27 - 44:30] So there's like three paragraphs out about the not actually\n[44:30 - 44:31] reading through those jokes.\n[44:31 - 44:32] They're probably terrible.\n[44:32 - 44:35] But this one's a little bit longer.\n[44:35 - 44:38] OK, this was a waste of time.\n[44:38 - 44:38] World their eyes.\n[44:38 - 44:42] OK, and this one's a lot shorter.\n[44:42 - 44:46] So I'm going to ask you to kind of help me out a little bit\n[44:46 - 44:48] for this next step, because I'm going\n[44:48 - 44:51] to go ahead and try to evaluate these jokes by commending.\n[44:51 - 44:53] We're not going to do any specific metric.\n[44:53 - 44:58] But the way you can begin to create and create that manual evaluation,\n[44:58 - 45:00] there's three tools up here.\n[45:00 - 45:02] There's the annotate tool.\n[45:02 - 45:05] Essentially means that you can make some create.\n[45:05 - 45:08] You can essentially make some adjustments to the input\n[45:08 - 45:11] and the output of the LLM responses themselves.\n[45:11 - 45:15] We have the ability to incorporate these objects into a data set.\n[45:15 - 45:17] We'll get to that in just a moment.\n[45:17 - 45:19] But I want to be able to add each one of these jokes\n[45:19 - 45:21] to an annotation queue.\n[45:21 - 45:24] So I can just show you guys what we're going to do here.\n[45:24 - 45:27] So I'm going to go ahead and select that.\n[45:27 - 45:29] I haven't created any particular queue yet.\n[45:29 - 45:32] So let's go ahead and just to show you what that looked like.\n[45:32 - 45:34] I'm going to click on annotation queue.\n[45:34 - 45:37] I'm going to click on new to create a new queue.\n[45:37 - 45:45] And I'm going to name this, see if it's not letting me detect.\n[45:45 - 45:46] Here we go.\n[45:46 - 45:48] OK, here we go.\n[45:48 - 45:53] Yeah, perfect.\n[45:53 - 45:59] I'm going to name it here again, add annotation queue, new.\n[45:59 - 46:05] A list, a list of terrible jokes.\n[46:05 - 46:06] And I need a name.\n[46:06 - 46:13] So let's call this an annotation joke judgment.\n[46:13 - 46:16] I don't know, doing a little spicy there.\n[46:16 - 46:18] That's all we need.\n[46:18 - 46:19] I can also create a data set that I'm\n[46:19 - 46:23] going to be adding these tools if I feel like the joke actually\n[46:23 - 46:29] fits the standard of what I want to fill in my particular\n[46:29 - 46:32] to fill in to create essentially a model that\n[46:32 - 46:35] makes the best dad jokes that we as a group\n[46:35 - 46:37] are potentially like working with.\n[46:37 - 46:41] So this is going to be my selection for joke judgment.\n[46:41 - 46:43] I'm going to create a new data set.\n[46:43 - 46:46] We can actually upload already built in data sets.\n[46:46 - 46:46] We can name this.\n[46:46 - 46:54] This is going to be my selected jokes, the jokes,\n[46:54 - 46:57] and for the description, I'm just adding some description for here.\n[46:57 - 47:03] And this is just the jokes that made the cut.\n[47:03 - 47:06] And we have three different data set times.\n[47:06 - 47:10] We have key value pairs, essentially, the input output type objects.\n[47:10 - 47:14] We can actually also include different types of frameworks\n[47:14 - 47:18] for this type of, for this type of the value.\n[47:18 - 47:21] They're essentially, they're similar in structure.\n[47:21 - 47:23] But for all I'm trying to do here\n[47:23 - 47:28] is essentially create a chat-based dictionary type object.\n[47:28 - 47:32] So the input is going to be the joke that we're\n[47:32 - 47:36] asked or the prompt that we're asking the AI to create.\n[47:36 - 47:38] And the joke will be whatever the output is.\n[47:38 - 47:41] So in this case, it's just kind of a chat-based conversation.\n[47:41 - 47:43] So that's what I'm going to be creating.\n[47:43 - 47:45] This is going to be my default data set.\n[47:45 - 47:49] Joke judgment, and I'm going to create an evaluator.\n[47:49 - 47:53] So that's going to be, we've added one object to the annotation tool.\n[47:54 - 47:57] I'm just going to go ahead and do that for the rest here.\n[47:57 - 47:59] And this is a little bit manual.\n[47:59 - 48:01] There's easier ways to do this.\n[48:01 - 48:04] But I do just want to showcase those individual steps.\n[48:04 - 48:07] Just kind of click and click.\n[48:07 - 48:09] And then I can then go to the annotation tool.\n[48:09 - 48:11] I'm going to get right there for a second.\n[48:11 - 48:12] Sorry.\n[48:12 - 48:17] And as you can see here, this is our joke judgment evaluator tool.\n[48:17 - 48:20] And the way that this is going to be evaluated in our case,\n[48:20 - 48:23] because we're creating this in a kind of manual user\n[48:23 - 48:25] like the human is going to be the person who's evaluated,\n[48:25 - 48:28] whether this prompt makes sense to use.\n[48:28 - 48:32] We can then have a certain set of tools\n[48:32 - 48:37] to determine whether I want this to be part of my data set object.\n[48:37 - 48:41] So we can either add this back to our data set.\n[48:41 - 48:47] We can evaluate this as saying like this joke is super proper.\n[48:47 - 48:49] And then we can actually make an evaluation\n[48:49 - 48:52] as to whether this input seems correct.\n[48:52 - 48:55] So if I said, tell me a dad joke of joke should be its story format.\n[48:55 - 48:58] What's fun of time with dad to say so?\n[48:58 - 48:59] They were walking around.\n[48:59 - 49:02] So I'm sure they're curious about this as a primate.\n[49:02 - 49:03] OK, run.\n[49:03 - 49:05] Does this look like it met the prompt?\n[49:05 - 49:06] Let's go ahead and say, yeah, sure.\n[49:06 - 49:07] It looks like a story.\n[49:07 - 49:08] It looks like a joke.\n[49:08 - 49:13] I didn't laugh, but we're going to go ahead and just call that.\n[49:13 - 49:14] And we're just going to evaluate that as done.\n[49:14 - 49:15] Let's go to the next one.\n[49:15 - 49:17] This is another joke.\n[49:17 - 49:18] Another story.\n[49:18 - 49:20] This one's a little bit longer.\n[49:20 - 49:22] Dad laughed and said, well, I guess you could say that\n[49:22 - 49:23] deal was half day.\n[49:23 - 49:24] It does start with once upon a time.\n[49:24 - 49:26] So it does sort of look like a story.\n[49:26 - 49:30] OK, let's go ahead and say, maybe that's correct too.\n[49:30 - 49:33] Let's go ahead and do finish that up.\n[49:33 - 49:35] Let's say that for whatever reason,\n[49:35 - 49:37] we think that the joke doesn't quite match.\n[49:37 - 49:40] Maybe it's not actually funny for us.\n[49:40 - 49:41] Maybe we're not just a fan of it.\n[49:41 - 49:43] And maybe we're tired of seeing this repetitive.\n[49:43 - 49:46] Like we're kind of starting to see a pattern here\n[49:46 - 49:48] for whatever reason.\n[49:48 - 49:50] Let's say that for what some arbitrary reason,\n[49:50 - 49:51] I don't like this joke.\n[49:51 - 49:55] I'm going to go ahead and label that as incorrect.\n[49:55 - 49:56] I'm not interested in using that.\n[49:56 - 49:59] I'm going to go ahead and click Done.\n[49:59 - 50:04] And I want to make sure that I'm adding about the data set.\n[50:04 - 50:07] Let's say this one's correct too.\n[50:07 - 50:09] I'm going to go ahead and click Done with that one.\n[50:09 - 50:11] And this one isn't so much of a story,\n[50:11 - 50:13] so I'm just going to go ahead and click that as incorrect.\n[50:13 - 50:15] Label that done.\n[50:15 - 50:18] So that should be good.\n[50:18 - 50:21] Let's see if I added this to my data sets automatically.\n[50:21 - 50:22] Yes.\n[50:22 - 50:26] So as part of my data sets, how I did that,\n[50:26 - 50:27] I'm directly to it by that.\n[50:27 - 50:30] I forgot to be adding these tools to the keys themselves.\n[50:30 - 50:33] So the other thing is as part of the annotation key,\n[50:33 - 50:37] you can also add those tools to the data set itself.\n[50:37 - 50:39] But if you just like I just did now,\n[50:39 - 50:43] forgot to add it to the tool itself.\n[50:43 - 50:45] Let's go back to the run sequence.\n[50:45 - 50:48] Just going to go ahead and take all of these objects\n[50:48 - 50:52] added to the data set.\n[50:52 - 50:54] You just submit that as part of the data set.\n[50:54 - 50:58] And I think I said that one was correct.\n[50:58 - 51:00] This one was correct.\n[51:00 - 51:08] And I think I decided that last one was correct.\n[51:08 - 51:12] So we're going to add that to the data set itself.\n[51:12 - 51:14] Submit that in.\n[51:14 - 51:15] And when I look at the data set,\n[51:15 - 51:18] I now have an input output based information\n[51:18 - 51:21] that gives me both information about the output,\n[51:21 - 51:25] what it was created, and how that information worked.\n[51:25 - 51:27] Excuse me.\n[51:27 - 51:30] So this is essentially where we are\n[51:30 - 51:32] beginning to like create a data set of the prompts\n[51:32 - 51:35] that worked for us.\n[51:35 - 51:39] These were the elements where as part of that framework\n[51:39 - 51:41] or as part of that team dynamic,\n[51:41 - 51:43] we checked in with our other users\n[51:43 - 51:44] and the other users in our environment\n[51:44 - 51:47] and essentially said, hey, this joke worked.\n[51:47 - 51:49] Open AI did a good job here.\n[51:49 - 51:50] The other two that we've decided\n[51:50 - 51:52] to keep out of the data set that now works.\n[51:52 - 51:55] So we implied those values as an evaluation\n[51:55 - 51:59] of zero, not correct outputs for the prompts we created.\n[51:59 - 52:03] There's a few other things that we can also look at.\n[52:03 - 52:05] Like, if we're not feeling like going through every single joke\n[52:05 - 52:07] and determining whether it's correct,\n[52:07 - 52:10] open AI and some of the other packages\n[52:10 - 52:11] have evaluators that essentially create\n[52:11 - 52:13] this in an automatic environment.\n[52:13 - 52:17] So all you need to do is just select the new experiment\n[52:17 - 52:19] and you can see that it's pretty much the same code\n[52:19 - 52:20] over and over again.\n[52:20 - 52:23] All you're really doing is just adding a line of code\n[52:23 - 52:25] to the evaluators at the end.\n[52:25 - 52:28] So you can evaluate each output\n[52:28 - 52:31] or if you wish to include that information\n[52:31 - 52:33] for correctness, relevance, and helpfulness.\n[52:33 - 52:38] And each one of these terms has its own specific definition.\n[52:38 - 52:39] A lot of these definitions, these evaluators\n[52:39 - 52:41] are essentially built to look\n[52:41 - 52:44] or specifically keywords or specific embeddings\n[52:44 - 52:49] that would follow or fit that specific evaluation.\n[52:50 - 52:54] But again, this is if you wanna automate that process,\n[52:54 - 52:56] that's an option that you have.\n[52:56 - 52:59] And this is simply something that you code through,\n[52:59 - 53:01] apply into the model itself\n[53:01 - 53:06] and build it into your particular platform.\n[53:06 - 53:10] But that is step one,\n[53:10 - 53:12] and that is essentially one of the advantages\n[53:12 - 53:17] of using LancsNet as part of your evaluation process.\n[53:18 - 53:20] Okay, I've got maybe about seven minutes ago,\n[53:20 - 53:22] so I might go a little bit above time.\n[53:22 - 53:24] But let's talk about this.\n[53:24 - 53:27] I've now got three jokes that I decided\n[53:27 - 53:31] arbitrarily or that we decided as part of the class\n[53:31 - 53:31] kind of worked.\n[53:33 - 53:36] So what I want is, I wanna bring this back in.\n[53:41 - 53:44] And I'm going to take them back to my prompting panel.\n[53:44 - 53:49] So I'm going to open up another tool here.\n[53:49 - 53:53] And what I want to showcase is how do we use\n[53:53 - 53:57] Lancchains tool, I might have to bounce\n[53:57 - 54:02] a little bit between, but just to be able to let us see this.\n[54:02 - 54:04] This is a, this is pretty much,\n[54:04 - 54:08] this is similar to what we can create within LancsNet.\n[54:08 - 54:11] But let's say that we've already done the evaluation.\n[54:11 - 54:13] We've determined that those three jokes\n[54:13 - 54:14] are the best dad jokes ever.\n[54:14 - 54:15] They're not, I read them,\n[54:15 - 54:17] just skimming through them, they look terrible.\n[54:17 - 54:21] But let's say we want our LLM to start creating dad jokes\n[54:21 - 54:23] that follow that same framework.\n[54:23 - 54:26] Well, there's a bit, like the bit of code\n[54:26 - 54:28] just requires us to create\n[54:28 - 54:33] and create, use those jokes that we used as the prompts\n[54:34 - 54:38] for our model to create the next set of jokes,\n[54:38 - 54:41] following what it learned from reading\n[54:41 - 54:44] those prompts that we created earlier.\n[54:44 - 54:48] So I'm going to use two tools, the chat prompt template\n[54:48 - 54:51] and the few shot chat message prompt template.\n[54:51 - 54:54] And this is where the few shot prompting comes into play.\n[54:54 - 54:57] And the way this works, and again,\n[54:57 - 54:59] otherwise everything else is the same.\n[54:59 - 55:01] I'm using the low dot environment to call the environment.\n[55:01 - 55:03] I'm accessing, not actually accessing\n[55:03 - 55:05] LLM at this point, I'm just doing this\n[55:05 - 55:09] from the joke itself,\n[55:09 - 55:11] from like, from the jokes themselves.\n[55:11 - 55:15] So I'm just going to go ahead and take these jokes.\n[55:15 - 55:18] And it's going to be a little bit manual.\n[55:18 - 55:22] But what I'm going to do is I'm going to add to these jokes,\n[55:22 - 55:29] the output that you would for that specific tool.\n[55:29 - 55:31] Let me just go ahead and add,\n[55:31 - 55:34] because I decided to use three jokes here.\n[55:34 - 55:35] Let's leave that.\n[55:35 - 55:40] So my input is tell me the joke should be in story format.\n[55:40 - 55:43] So I'm just going to update the output I got\n[55:43 - 55:44] from those three jokes.\n[55:44 - 55:48] So bear with me, this is going to be a little bit manual.\n[55:48 - 55:52] I'm going to copy that output, put that there.\n[55:52 - 55:55] So that was a messier than I wanted that to be.\n[55:55 - 56:02] But sorry, bear with me for five seconds.\n[56:02 - 56:12] Right, too many, too much of that.\n[56:12 - 56:15] Much of that, I might limit myself to two,\n[56:15 - 56:20] because this is this might get tedious.\n[56:20 - 56:23] And the other joke I'm creating is the same thing.\n[56:23 - 56:25] Both of these jokes, actually that's a pretty good example.\n[56:25 - 56:29] Once upon a time there's that, but it starts the same way.\n[56:29 - 56:30] Let's do that.\n[56:30 - 56:32] Let's do that.\n[56:32 - 56:35] Let's do that.\n[56:36 - 56:52] That is a lot of dialogue here.\n[56:52 - 56:54] OK, let's see.\n[56:54 - 56:56] I'll put this that look right.\n[56:56 - 56:58] All right, so let's clean this up a little bit.\n[56:58 - 57:00] All right, so I have two sets of inputs.\n[57:00 - 57:01] So I'm just going to use two prompts.\n[57:01 - 57:03] Those are my few shots here.\n[57:03 - 57:05] That works.\n[57:05 - 57:08] All right, so from here, my example prompt\n[57:08 - 57:11] is taking the chat prompt template from these messages,\n[57:11 - 57:13] from these examples that I just created.\n[57:13 - 57:15] Both of these jokes start with once upon a time.\n[57:15 - 57:18] There was a dad or a dad.\n[57:18 - 57:20] So both of these jokes are going to start out the way.\n[57:20 - 57:23] And the human message is essentially always going to be,\n[57:23 - 57:25] or you would presume that the input,\n[57:25 - 57:28] when you get an input, that looks like,\n[57:28 - 57:28] tell me a dad joke.\n[57:28 - 57:30] The joke should be in story format.\n[57:30 - 57:33] The output should look something like this.\n[57:33 - 57:35] And this few shot prompt is essentially\n[57:35 - 57:38] going to be taking that prompt template\n[57:38 - 57:40] from the example prompts that we created above.\n[57:40 - 57:43] And it's going to be taking a case from the examples\n[57:43 - 57:49] that we used in our prompts from earlier.\n[57:49 - 57:53] And format those jokes so that they potentially\n[57:53 - 57:55] look a little bit alike this.\n[57:55 - 57:57] So any time the human asks something about a dad joke,\n[57:57 - 58:00] the joke should be in story format,\n[58:00 - 58:05] we can expect the AI to respond something like this.\n[58:05 - 58:06] Let's try that out.\n[58:06 - 58:09] We've trained our model quote unquote\n[58:09 - 58:11] with the framework or the prompts\n[58:11 - 58:13] that we created earlier.\n[58:13 - 58:16] And I want to add one final prompt, which\n[58:16 - 58:19] is I'm telling the system we're adding a system message\n[58:19 - 58:21] just to make sure that this is working\n[58:21 - 58:24] or that the model has learned from both the prompts\n[58:24 - 58:25] and the information that I've created.\n[58:25 - 58:27] I want all of these jokes and with the phrase\n[58:27 - 58:31] visinga, because I'm terrible like that sometimes.\n[58:31 - 58:34] Still going to follow the few shot prompts\n[58:34 - 58:37] and still going to require that human input.\n[58:37 - 58:39] So if I have this run on its own,\n[58:39 - 58:43] I'm going to use the Langshan chat open AI, just importing that.\n[58:43 - 58:45] And I'm going to call that final prompt.\n[58:45 - 58:47] And again, essentially just informing the chain\n[58:47 - 58:50] that I'm going to be using as part of open AI.\n[58:50 - 58:53] Remember that with chat open AI on Monday,\n[58:53 - 58:57] we created a chat open AI tool that invoked the information\n[58:57 - 58:59] or the call.\n[58:59 - 59:01] In this case, the difference is that I'm\n[59:01 - 59:04] calling the final prompt first so that it actually,\n[59:04 - 59:06] the chain actually learns from the information\n[59:06 - 59:08] I shared in that final prompt, the examples\n[59:08 - 59:10] I created earlier.\n[59:10 - 59:14] And again, the few shot prompts are already built into that final\n[59:14 - 59:15] prompt.\n[59:15 - 59:17] I've got it set to a temperature of 7.\n[59:17 - 59:20] And I'm actually asking the joke so that it follows\n[59:20 - 59:24] the joke to be in that story format.\n[59:24 - 59:26] And I should probably include and string up parts of what\n[59:26 - 59:28] I'm not going to do that.\n[59:28 - 59:28] So all right.\n[59:28 - 59:32] And now, when I've run the package,\n[59:32 - 59:34] I've added somewhat quite a bit amount of creativity.\n[59:34 - 59:37] Let me just go ahead and add a little bit more creativity.\n[59:37 - 59:39] And I'm just going to run this a few times.\n[59:39 - 59:41] But once upon a time, my dad was helping\n[59:41 - 59:44] his son with his math homework, a terrible joke.\n[59:44 - 59:46] And even though he was still frustrating with the math,\n[59:46 - 59:48] oh, didn't he mount and clean with a single?\n[59:48 - 59:49] Did I miss that mark?\n[59:49 - 59:56] Run that, run that, let's see.\n[59:56 - 59:56] Oh, there he is.\n[59:56 - 59:57] All right.\n[59:57 - 59:58] So there's the busy end beyond.\n[59:58 - 59:59] So that's correct.\n[59:59 - 01:00:00] Once upon a time, there was a daddy while he's\n[01:00:00 - 01:00:02] dreamed of being a comedic great.\n[01:00:02 - 01:00:03] So let's try this again.\n[01:00:03 - 01:00:05] This is three times.\n[01:00:05 - 01:00:07] Once upon a time, my dad decided to use that.\n[01:00:07 - 01:00:09] So now we're seeing that all of the jokes that\n[01:00:09 - 01:00:12] we're starting to come out have the information\n[01:00:12 - 01:00:13] from the prompts that we created earlier.\n[01:00:13 - 01:00:15] And again, that's because we, as a group,\n[01:00:15 - 01:00:18] decided that the prompts or a good dad joke\n[01:00:18 - 01:00:21] must start with once upon a time,\n[01:00:21 - 01:00:23] and or at least the two prompts that we use all\n[01:00:23 - 01:00:27] had to start with once upon a time.\n[01:00:27 - 01:00:28] And this is essentially where you start to,\n[01:00:28 - 01:00:31] even with a temperature of high as 0.09,\n[01:00:31 - 01:00:34] like that framework, that structure,\n[01:00:34 - 01:00:41] that those elements of those elements\n[01:00:41 - 01:00:45] of the model of the prompts are essentially helping us\n[01:00:45 - 01:00:50] inform what we want our model to return and look like.\n[01:00:50 - 01:00:51] All right.\n[01:00:51 - 01:00:53] So what does that mean?\n[01:00:53 - 01:00:56] This is something that we can essentially\n[01:00:56 - 01:00:59] help determine using a tool like Lancement.\n[01:00:59 - 01:01:01] We can essentially do all of this in Python JavaScript,\n[01:01:01 - 01:01:04] whatever tool you want to use, and essentially build\n[01:01:04 - 01:01:06] and manually create what prompts seems to work for you\n[01:01:06 - 01:01:11] and add that into like a future LLM\n[01:01:11 - 01:01:13] that you would build on your own.\n[01:01:13 - 01:01:15] Or you could essentially use a tool that essentially keeps\n[01:01:15 - 01:01:20] all of the calls you've made in a nice organized fashion.\n[01:01:20 - 01:01:23] So Lancement, on top of a couple of other different features\n[01:01:23 - 01:01:24] that we're going to be working with,\n[01:01:24 - 01:01:27] has a method and certain set love sets of tools\n[01:01:27 - 01:01:33] that allow you to kind of annotate, evaluate,\n[01:01:33 - 01:01:36] and determine whether a specific step is worthwhile\n[01:01:36 - 01:01:38] for you to use.\n[01:01:38 - 01:01:41] One thing I didn't mention as part of the annotation tool,\n[01:01:41 - 01:01:44] let me just go ahead and showcase that one more time.\n[01:01:44 - 01:01:49] We go back to this dad and show a tool basis.\n[01:01:52 - 01:01:53] There it is, there's the run.\n[01:01:53 - 01:01:57] Let me just go ahead and add that back to the annotation queue.\n[01:01:57 - 01:02:00] Okay, I'm gonna go back to the judgment.\n[01:02:00 - 01:02:03] You can actually modify your tools\n[01:02:03 - 01:02:05] as like your evaluations as well.\n[01:02:05 - 01:02:08] So this is where like a human or a team member\n[01:02:08 - 01:02:09] can essentially all sit down and be like,\n[01:02:09 - 01:02:13] I don't like how open AI is like building out these prompts.\n[01:02:13 - 01:02:17] Maybe a human can like help create a better joke,\n[01:02:17 - 01:02:20] for example, to like structure this in a better way.\n[01:02:20 - 01:02:21] And once you've done that,\n[01:02:21 - 01:02:22] you can then add that back into the data set.\n[01:02:22 - 01:02:24] That was the stuff that I wasn't doing\n[01:02:24 - 01:02:31] as I was going through the annotation tool.\n[01:02:31 - 01:02:35] Fun stuff, thank you, we'll use it.\n[01:02:35 - 01:02:37] Maybe, I don't know.\n[01:02:37 - 01:02:39] Well, if you don't use that, we also again,\n[01:02:39 - 01:02:40] like I said, Langfuse is another option.\n[01:02:40 - 01:02:43] A lot of the same things work very similarly.\n[01:02:45 - 01:02:47] I haven't used, to be honest, I haven't used Langfuse\n[01:02:47 - 01:02:49] a whole lot, it is Jonathan.\n[01:02:49 - 01:02:53] Do we know how old Langfuse is currently,\n[01:02:53 - 01:02:57] or how long have it's been around town?\n[01:02:57 - 01:02:59] I'm not exactly sure.\n[01:02:59 - 01:03:01] I heard of it a while back,\n[01:03:01 - 01:03:03] but the first time I've messed with it\n[01:03:03 - 01:03:05] was a few days ago when it got brought up.\n[01:03:05 - 01:03:07] Say, no.\n[01:03:07 - 01:03:08] No, but it looks really cool.\n[01:03:08 - 01:03:11] I mean, if it's your dime on it,\n[01:03:11 - 01:03:15] I'm not a bit like I would recommend it.\n[01:03:19 - 01:03:21] Let me just check my notes here.\n[01:03:21 - 01:03:24] Yeah, but that is about it.\n[01:03:24 - 01:03:27] We are showcasing here how to use Langsmith\n[01:03:27 - 01:03:28] and essentially showcasing a place\n[01:03:28 - 01:03:31] where you can now build like the code that you built,\n[01:03:31 - 01:03:33] the things that your model's evaluated.\n[01:03:33 - 01:03:35] You now have a place where you can look and study\n[01:03:35 - 01:03:37] and analyze and think about whether\n[01:03:38 - 01:03:41] those tools work for you behind the scenes\n[01:03:42 - 01:03:46] and the next step is up to you to practice with this\n[01:03:46 - 01:03:48] and literally like laying around with us\n[01:03:48 - 01:03:51] it's a very easy user interface.\n[01:03:51 - 01:03:52] You won't get too hung up on this,\n[01:03:52 - 01:03:54] like you'll find everything that you need to do\n[01:03:54 - 01:03:55] fairly quickly.\n[01:03:55 - 01:03:57] But one of the things we're going to recommend\n[01:03:57 - 01:03:59] for you to practice with one of their homeworks\n[01:03:59 - 01:04:03] is to take a look at all of these different reviews,\n[01:04:04 - 01:04:07] build them into like think of them as customer feedback\n[01:04:07 - 01:04:12] from a particular company and just determine\n[01:04:12 - 01:04:15] what the results would look like in Langsmith.\n[01:04:15 - 01:04:18] So you determine what is a good response,\n[01:04:18 - 01:04:20] what is a good review\n[01:04:20 - 01:04:25] and determine from there, assign it to a data set.\n[01:04:25 - 01:04:28] You want to prompt it so that you can now create\n[01:04:28 - 01:04:31] for the person who I think there was one person in the class,\n[01:04:31 - 01:04:34] wanted to like start creating a Twitter bots\n[01:04:34 - 01:04:36] or something like that.\n[01:04:36 - 01:04:38] This is how you can begin to determine\n[01:04:38 - 01:04:40] what kind of tweet, Twitter bot message\n[01:04:40 - 01:04:45] you want to start creating.\n[01:04:45 - 01:04:47] That's it.\n[01:04:47 - 01:04:49] That's all I have for you today.\n[01:04:49 - 01:04:53] So you are released unless you have any questions\n[01:04:53 - 01:04:55] you'd like to take a look at something\n[01:04:55 - 01:04:57] a little bit more deeply.\n[01:04:57 - 01:04:59] Feel free to stick around.\n[01:04:59 - 01:05:03] Both Jonathan and I are here for the next few moments.\n[01:05:03 - 01:05:09] Thank you.\n[01:05:09 - 01:05:11] Hopefully you'll have some fun with this.\n[01:05:11 - 01:05:44] Have a wonderful evening otherwise.\n[01:05:44 - 01:05:47] Projects.\n[01:05:47 - 01:05:48] Yeah, all right.\n[01:05:48 - 01:05:49] Oh, wow.\n[01:05:49 - 01:05:50] Oh, my gosh, I just looked at myself\n[01:05:50 - 01:05:52] and I am sitting in darkness.\n[01:05:52 - 01:05:54] That.\n[01:05:54 - 01:06:15] Ah.\n[01:06:15 - 01:06:19] It's up to Julian that I've lied.\n[01:06:19 - 01:06:22] Lang came for and you mentioned it a little bit\n[01:06:22 - 01:06:26] of playground is just going straight from the trace\n[01:06:26 - 01:06:29] into the playground you were talking about\n[01:06:29 - 01:06:30] trying to decide models.\n[01:06:30 - 01:06:33] Most of them you have to use put an API key in there.\n[01:06:33 - 01:06:37] I've got some API keys in mind and they have a couple\n[01:06:37 - 01:06:39] free options like chat fireworks,\n[01:06:39 - 01:06:41] but you can actually experiment around\n[01:06:41 - 01:06:43] with the different models and see the same response\n[01:06:43 - 01:06:46] based on the prompt and change the parameters\n[01:06:46 - 01:06:48] and it logs all of that.\n[01:06:48 - 01:06:50] So I actually use that at work\n[01:06:50 - 01:06:52] when we were arguing.\n[01:06:52 - 01:06:56] Professionally arguing about what model we were going\n[01:06:56 - 01:06:57] to use for something.\n[01:06:57 - 01:07:00] And it was the first time I had seen it use.\n[01:07:00 - 01:07:03] This was a couple months ago, I guess.\n[01:07:03 - 01:07:06] The actual playground that we were messing around\n[01:07:06 - 01:07:08] in the playground and saving all the outputs in.\n[01:07:08 - 01:07:12] And it's pretty handy for a tool\n[01:07:12 - 01:07:17] that we all picked up on using within an hour or so.\n[01:07:17 - 01:07:18] Yeah.\n[01:07:18 - 01:07:19] From what I saw from the curriculum,\n[01:07:19 - 01:07:23] it looks like the playground comes into the vogue a lot\n[01:07:23 - 01:07:25] in what we started talking about the valuation\n[01:07:25 - 01:07:28] of the fine tuning, but it could be meant,\n[01:07:28 - 01:07:31] but yeah, no, I feel like if that's something I missed,\n[01:07:31 - 01:07:34] I'm happy to like go deeper into it\n[01:07:34 - 01:07:38] on connecting the next session for sure.\n[01:07:38 - 01:07:40] Yeah, when you're in it, all you gotta,\n[01:07:40 - 01:07:41] when you're on a specific trace,\n[01:07:41 - 01:07:46] if you just hit the playground, the playground opens up\n[01:07:46 - 01:07:49] and it'll bring the input and output into the playground\n[01:07:49 - 01:07:52] and you can just on the side, there's a side bar\n[01:07:52 - 01:07:55] where you can start choosing providers and models,\n[01:07:55 - 01:07:58] set temperatures and tokens and whatnot.\n[01:07:58 - 01:08:00] Now it's, I just went into it now\n[01:08:00 - 01:08:04] because with that 3.5, my results were less than stellar\n[01:08:04 - 01:08:07] and funny enough, one of their free models\n[01:08:07 - 01:08:09] was giving me incredibly better results\n[01:08:09 - 01:08:12] with the cat fireworks without even using tokens on\n[01:08:12 - 01:08:16] that I'm paying for.\n[01:08:16 - 01:08:20] Yeah, I guess I didn't touch on that.\n[01:08:21 - 01:08:25] That's good.\n[01:08:25 - 01:08:27] No, yeah, I didn't really, really,\n[01:08:27 - 01:08:30] let me just go over that.\n[01:08:30 - 01:08:35] Yeah, there's a lot to Lang Smith.\n[01:08:35 - 01:08:41] I'm hoping to the end of the second on Tuesday.\n[01:08:41 - 01:08:45] Are there, I was trying to think about my question is,\n[01:08:45 - 01:08:48] today's lesson felt to me a little like the 10 minute\n[01:08:48 - 01:08:51] video that you all sent, like there's a huge amount\n[01:08:51 - 01:08:52] of information and there's a huge amount of like\n[01:08:52 - 01:08:54] capability in the platform.\n[01:08:54 - 01:08:58] I still don't necessarily feel clarity, I suppose.\n[01:08:58 - 01:09:02] And that's also just because obviously it's only been an hour.\n[01:09:02 - 01:09:04] I'm curious if there's any resources you recommend\n[01:09:04 - 01:09:05] outside the ones that you've already posted.\n[01:09:05 - 01:09:07] Otherwise, I still need to watch the one hour one\n[01:09:07 - 01:09:12] and the deep dive documentation.\n[01:09:12 - 01:09:13] Julian?\n[01:09:13 - 01:09:17] Oh, I mean, I mean, my process of learning\n[01:09:17 - 01:09:19] is not a process I recommend.\n[01:09:19 - 01:09:22] I spend a lot of time at the documentation.\n[01:09:23 - 01:09:27] So it's essentially, my methods is extremely academic.\n[01:09:27 - 01:09:29] It is very much just making sure that I understand\n[01:09:29 - 01:09:31] like what each class, what each function is doing\n[01:09:31 - 01:09:34] to find the scenes and then making sure\n[01:09:34 - 01:09:35] I've put it into practice somehow.\n[01:09:35 - 01:09:37] It is time consuming.\n[01:09:38 - 01:09:42] So you know, the YouTube bit, like there are,\n[01:09:42 - 01:09:44] there are not a lot of good YouTube videos out there.\n[01:09:44 - 01:09:45] Yeah.\n[01:09:45 - 01:09:47] Like it is, like they're all at least 10 years old\n[01:09:47 - 01:09:51] and all of the methods have gotten like completely outdated.\n[01:09:53 - 01:09:57] So my current, my current tech,\n[01:09:57 - 01:10:03] like my current best recommendation is just exhaustive.\n[01:10:03 - 01:10:06] Yeah, I was going to go like one by line\n[01:10:06 - 01:10:09] through the implementation and like, what a soup strainer.\n[01:10:09 - 01:10:10] Okay, here's soup strainer.\n[01:10:10 - 01:10:12] It is, it is tedious.\n[01:10:13 - 01:10:18] And like I can't vouch by, I can't vouch to it's effectiveness\n[01:10:18 - 01:10:21] but it is like I read it once\n[01:10:21 - 01:10:23] and I know how to come back to it down the road.\n[01:10:24 - 01:10:26] Yeah, no, you're right that the resources are like this\n[01:10:26 - 01:10:30] like Smith is still changing so rapidly\n[01:10:30 - 01:10:33] that it's hard to find but Jonathan, what do you,\n[01:10:33 - 01:10:35] what do you, what have you found?\n[01:10:35 - 01:10:39] That video that, that's posted the hour long video\n[01:10:39 - 01:10:42] that came out four or five months ago,\n[01:10:42 - 01:10:45] that's the first video I would watch the hour long video.\n[01:10:45 - 01:10:50] It's the 10 minute video is, he goes over that same stuff\n[01:10:50 - 01:10:52] but he covers a lot more.\n[01:10:52 - 01:10:54] I watched that hour long video\n[01:10:54 - 01:10:57] and then my way of learning is to make,\n[01:10:57 - 01:11:00] sometimes I find myself lost in documents\n[01:11:00 - 01:11:02] and then I just like to start experimenting\n[01:11:02 - 01:11:05] and seeing what I can do with it.\n[01:11:05 - 01:11:09] And that's how I learned my, the one,\n[01:11:10 - 01:11:15] the one good video I would recommend that I've seen\n[01:11:15 - 01:11:17] is the one that I put up there for the hour\n[01:11:17 - 01:11:20] because you're not gonna spend half a day watching it\n[01:11:20 - 01:11:21] but it's a pretty good wrap up\n[01:11:21 - 01:11:23] and it's pretty up to date, it's only,\n[01:11:23 - 01:11:25] I'm looking at it now it's four,\n[01:11:25 - 01:11:27] came out four or four and a half months ago,\n[01:11:27 - 01:11:27] it looks like.\n[01:11:29 - 01:11:34] It goes through that and then just start messing\n[01:11:34 - 01:11:36] with the homework or messing with your own projects\n[01:11:36 - 01:11:41] or that's my way of learning.\n[01:11:41 - 01:11:44] Yeah, it makes sense, so.\n[01:11:44 - 01:11:47] I think I'm adapting to this course\n[01:11:47 - 01:11:48] because I like the deep dive\n[01:11:48 - 01:11:52] but it's like deep diving plus working with the full day\n[01:11:52 - 01:11:56] and finding that extra hour to get into one of these things.\n[01:11:56 - 01:11:57] Okay, I'll have a life.\n[01:11:57 - 01:12:01] Yeah, it's all good, I appreciate it.\n[01:12:04 - 01:12:08] But sure, so I do want to touch on that feedback\n[01:12:08 - 01:12:10] because that's good feedback to you.\n[01:12:10 - 01:12:13] It sounds to be like you wanted a deeper dive.\n[01:12:13 - 01:12:17] I think like we jumped into lane chain\n[01:12:22 - 01:12:24] and then started running queries\n[01:12:24 - 01:12:27] and kind of like digging into run feedback, metadata,\n[01:12:27 - 01:12:27] et cetera, et cetera.\n[01:12:27 - 01:12:31] And then you did the section with the documentation\n[01:12:31 - 01:12:34] where you walk through, let me go through it here.\n[01:12:34 - 01:12:37] Like the rag build out kind of step by step.\n[01:12:37 - 01:12:41] I think as I'm saying it out loud,\n[01:12:41 - 01:12:42] I think you actually explain it reasonably well.\n[01:12:42 - 01:12:45] Like the, like putting together the chain\n[01:12:45 - 01:12:46] essentially all that works.\n[01:12:46 - 01:12:49] It's just like you said, I just need to actually like\n[01:12:49 - 01:12:52] go in and say, okay, what is the retriever actually doing\n[01:12:52 - 01:12:54] diving into the format docs function,\n[01:12:54 - 01:12:58] diving into what runable pass through means, et cetera.\n[01:12:58 - 01:12:58] Oh, yeah.\n[01:12:58 - 01:13:02] And yeah, we're gonna, and yeah, as like with each class,\n[01:13:02 - 01:13:05] I think I'm spending a lot more time\n[01:13:05 - 01:13:09] defining each term, looking at like what's happening behind\n[01:13:09 - 01:13:10] the scenes with each term.\n[01:13:10 - 01:13:12] I think a little bit more next week\n[01:13:12 - 01:13:14] when we start looking at rag is because\n[01:13:17 - 01:13:18] despite the fact that the comments\n[01:13:18 - 01:13:21] are evolving like one of the things that I want to make sure\n[01:13:21 - 01:13:24] is that, you know, I believe there's,\n[01:13:24 - 01:13:25] I believe there's a wide,\n[01:13:25 - 01:13:27] but like a wide stretch of experience here.\n[01:13:27 - 01:13:30] There might be a few folks who are still very new\n[01:13:30 - 01:13:33] to Lang Smith, I need an open AI.\n[01:13:33 - 01:13:35] So like I want to try to make sure\n[01:13:35 - 01:13:36] that we're all on the same page.\n[01:13:36 - 01:13:38] Yeah, and that would be great.\n[01:13:38 - 01:13:41] And that category includes me other than using chat\n[01:13:41 - 01:13:42] to be like everyone else I guess.\n[01:13:42 - 01:13:43] Perfect.\n[01:13:43 - 01:13:44] Okay, so yeah, so I think what I,\n[01:13:44 - 01:13:46] like that's good feedback because what I can do\n[01:13:46 - 01:13:48] is actually make sure to have\n[01:13:50 - 01:13:53] quick column flashcards for each one of the\n[01:13:54 - 01:13:55] like a brand new.\n[01:13:55 - 01:13:56] Yeah, that would be excellent.\n[01:13:56 - 01:13:57] Actually,\n[01:13:58 - 01:14:01] other logistical question for homework.\n[01:14:01 - 01:14:04] Are we only submitting through the post that you're making,\n[01:14:04 - 01:14:08] Jonathan, or is there another route for that?\n[01:14:08 - 01:14:13] So, yeah, the homework, submitting it as optional,\n[01:14:16 - 01:14:19] the feedback a lot of times will be pretty minimal.\n[01:14:19 - 01:14:21] And if you've got a specific question,\n[01:14:21 - 01:14:23] would be glad to address that.\n[01:14:23 - 01:14:25] But yeah, I'm going to make a thread,\n[01:14:25 - 01:14:28] put the link into the thread,\n[01:14:28 - 01:14:31] and that now your guided projects will be different.\n[01:14:31 - 01:14:33] The guided projects will go into the,\n[01:14:33 - 01:14:36] the four guided projects will go into the portal\n[01:14:36 - 01:14:38] and there'll be a specific process for that\n[01:14:38 - 01:14:43] and that'll be more reviewed and more depth.\n[01:14:43 - 01:14:44] But yeah, for the homework,\n[01:14:44 - 01:14:45] if you want somebody to look over it,\n[01:14:45 - 01:14:46] if you've got any questions,\n[01:14:46 - 01:14:48] if you just want to throw it out there,\n[01:14:48 - 01:14:50] put it in that thread ideally because that,\n[01:14:50 - 01:14:53] I keep an eye on it and I'll see it there.\n[01:14:53 - 01:14:55] And something I was going to throw in\n[01:14:55 - 01:14:58] about what I think you'll find with this course.\n[01:14:58 - 01:15:00] So like for me, I've been an engineer for a while,\n[01:15:00 - 01:15:05] I got into AI and ML a while ago.\n[01:15:05 - 01:15:08] I come from mostly with my work,\n[01:15:08 - 01:15:13] an ML background and was working with OpenAI and Langchain\n[01:15:14 - 01:15:16] and a little bit of Langsmith.\n[01:15:16 - 01:15:19] I've done this course and I think that you'll find\n[01:15:19 - 01:15:22] a lot of the questions during the first weeks.\n[01:15:22 - 01:15:25] I'll build up and when we start getting into agents,\n[01:15:25 - 01:15:27] everything kind of falls together\n[01:15:27 - 01:15:30] and it's like, oh, okay, that makes sense\n[01:15:30 - 01:15:32] why we were doing that.\n[01:15:32 - 01:15:37] This has been, it'll, because I like the deep dive as well.\n[01:15:37 - 01:15:38] I mean, I can't even talk about the times\n[01:15:38 - 01:15:42] I've deep dove into the layers of neural nets\n[01:15:42 - 01:15:45] with pie torches and transformations\n[01:15:45 - 01:15:49] and everything imaginable under the sun,\n[01:15:49 - 01:15:52] just wasting hours and hours and hours doing it.\n[01:15:52 - 01:15:56] But with the course, I think you'll see\n[01:15:56 - 01:15:59] in a couple of weeks, everything's starting to come together\n[01:15:59 - 01:16:02] and by the time it gets done,\n[01:16:02 - 01:16:07] that you'll walk away with a good understanding\n[01:16:07 - 01:16:09] of all these technologies and the ability\n[01:16:09 - 01:16:13] to implement the agents and the multi-agent systems\n[01:16:13 - 01:16:14] confidently.\n[01:16:20 - 01:16:22] I appreciate the extra context.\n[01:16:22 - 01:16:24] I gotta drop, gotta go make dinner\n[01:16:24 - 01:16:25] but I hope you too have an idea.\n[01:16:25 - 01:16:26] Call.\n[01:16:26 - 01:16:27] Have a good time.\n[01:16:27 - 01:16:29] Thanks.\n[01:16:29 - 01:16:31] Thank you guys for everything.\n[01:16:31 - 01:16:32] See you.\n[01:16:32 - 01:16:33] Bye.\n[01:16:33 - 01:16:34] Bye.\n[01:16:34 - 01:16:35] Go ahead and pause for a while.\n[01:16:35 - 01:16:36] Man.",
  "transcript_segments": [
    {
      "start": 19.73,
      "end": 23.99,
      "text": "that recording, eight o'clock on the dots."
    },
    {
      "start": 23.99,
      "end": 26.91,
      "text": "All right, the waiting room thing is gonna,"
    },
    {
      "start": 26.91,
      "end": 30.46,
      "text": "gonna be tricky for me for a little bit."
    },
    {
      "start": 30.46,
      "end": 34.14,
      "text": "All right, folks, thank you for joining."
    },
    {
      "start": 34.14,
      "end": 35.14,
      "text": "Happy Thursday."
    },
    {
      "start": 37.46,
      "end": 40.38,
      "text": "Let's, we actually got quite a bit to go over."
    },
    {
      "start": 40.38,
      "end": 42.54,
      "text": "So it'll probably be a quick,"
    },
    {
      "start": 42.54,
      "end": 43.54,
      "text": "I'm gonna go ahead and assume"
    },
    {
      "start": 43.54,
      "end": 44.74,
      "text": "that most of them are comfortable"
    },
    {
      "start": 44.74,
      "end": 46.02,
      "text": "with getting the environment set up."
    },
    {
      "start": 46.02,
      "end": 49.18,
      "text": "So it might just be a kind of quick overflow over"
    },
    {
      "start": 50.42,
      "end": 51.9,
      "text": "how to get all those things down."
    },
    {
      "start": 52.18,
      "end": 53.58,
      "text": "First things first, I'd like to go ahead"
    },
    {
      "start": 53.58,
      "end": 56.94,
      "text": "and set a questions thread on the Slack channel."
    },
    {
      "start": 56.94,
      "end": 61.26,
      "text": "So if you have any questions that you don't feel like"
    },
    {
      "start": 61.26,
      "end": 64.22,
      "text": "you want to kind of announce"
    },
    {
      "start": 64.22,
      "end": 66.74,
      "text": "to the, you know, you don't want to use your voice,"
    },
    {
      "start": 66.74,
      "end": 69.62,
      "text": "that's totally okay, I highly recommend you"
    },
    {
      "start": 69.62,
      "end": 71.86,
      "text": "share your questions on the questions thread."
    },
    {
      "start": 71.86,
      "end": 74.3,
      "text": "I'll make sure to keep an eye on the Slack channel."
    },
    {
      "start": 75.58,
      "end": 77.06,
      "text": "But yeah, if I've missed something in writing,"
    },
    {
      "start": 77.06,
      "end": 78.9,
      "text": "by all means please give me a shout out."
    },
    {
      "start": 78.9,
      "end": 81.5,
      "text": "I do occasionally miss when messages"
    },
    {
      "start": 81.5,
      "end": 82.66,
      "text": "are coming either from the questions"
    },
    {
      "start": 82.66,
      "end": 84.18,
      "text": "that I had in the Zoom chat or things like that."
    },
    {
      "start": 84.18,
      "end": 86.14,
      "text": "So generally, I prefer Slack,"
    },
    {
      "start": 86.14,
      "end": 88.82,
      "text": "that's just my big heads amount of mountain."
    },
    {
      "start": 90.66,
      "end": 92.34,
      "text": "All right, happy Thursday."
    },
    {
      "start": 92.34,
      "end": 93.18,
      "text": "Welcome back."
    },
    {
      "start": 93.18,
      "end": 95.46,
      "text": "Let's share my screen."
    },
    {
      "start": 95.46,
      "end": 100.46,
      "text": "Let's get started and then yeah, that's our first page."
    },
    {
      "start": 102.02,
      "end": 105.74,
      "text": "All right, so folks, today we are diving into,"
    },
    {
      "start": 105.74,
      "end": 107.22,
      "text": "today's a little bit of a combination"
    },
    {
      "start": 107.22,
      "end": 109.74,
      "text": "of both kind of working and code in VS code"
    },
    {
      "start": 109.74,
      "end": 111.82,
      "text": "and working with a platform."
    },
    {
      "start": 112.34,
      "end": 114.74,
      "text": "LangSmith is essentially where we're going to be"
    },
    {
      "start": 114.74,
      "end": 115.78,
      "text": "not quite hosting our code,"
    },
    {
      "start": 115.78,
      "end": 118.82,
      "text": "but essentially comparing and letting our code operate"
    },
    {
      "start": 118.82,
      "end": 121.78,
      "text": "and allows to actually evaluate"
    },
    {
      "start": 121.78,
      "end": 123.9,
      "text": "whether our LLMs are operating in a way"
    },
    {
      "start": 123.9,
      "end": 125.06,
      "text": "that's beneficial for us."
    },
    {
      "start": 125.06,
      "end": 127.22,
      "text": "This is going to be a very introductory first session."
    },
    {
      "start": 127.22,
      "end": 130.18,
      "text": "The idea is being like introduce you to"
    },
    {
      "start": 130.18,
      "end": 134.1,
      "text": "what LangSmith is able to do behind the scenes"
    },
    {
      "start": 134.1,
      "end": 139.34,
      "text": "and what it can do for you as one of like,"
    },
    {
      "start": 139.34,
      "end": 141.14,
      "text": "as one of the tools that you're going to,"
    },
    {
      "start": 141.14,
      "end": 145.7,
      "text": "that we're going to be using for most of our LLM creation"
    },
    {
      "start": 145.7,
      "end": 148.46,
      "text": "fine tuning experimentation, all of that."
    },
    {
      "start": 149.9,
      "end": 153.5,
      "text": "Which is kind of, so I know with what speed"
    },
    {
      "start": 153.5,
      "end": 157.5,
      "text": "and what kind of cadence I should be talking about"
    },
    {
      "start": 157.5,
      "end": 158.34,
      "text": "our concepts today."
    },
    {
      "start": 158.34,
      "end": 159.58,
      "text": "Can I get a thumbs up from folks"
    },
    {
      "start": 159.58,
      "end": 166.64,
      "text": "if you've worked with LangSmith before?"
    },
    {
      "start": 166.64,
      "end": 168.96,
      "text": "And Lang, Lang, Lang, okay, okay."
    },
    {
      "start": 168.96,
      "end": 170.0,
      "text": "Cool, all right."
    },
    {
      "start": 170.0,
      "end": 171.88,
      "text": "I'll pick it slow then."
    },
    {
      "start": 171.88,
      "end": 176.2,
      "text": "With that said, I have all of our,"
    },
    {
      "start": 176.2,
      "end": 177.76,
      "text": "like all of our repo was already shared"
    },
    {
      "start": 177.76,
      "end": 180.28,
      "text": "on the Slack channel, so I'm going to go ahead and ask you"
    },
    {
      "start": 180.28,
      "end": 183.8,
      "text": "to go ahead and fork if you need to"
    },
    {
      "start": 183.8,
      "end": 187.84,
      "text": "or just clone this repository, whichever one you want it."
    },
    {
      "start": 187.84,
      "end": 189.16,
      "text": "If you don't fork it, it's fine by me."
    },
    {
      "start": 189.16,
      "end": 192.48,
      "text": "But if you want to go ahead and clone this repository"
    },
    {
      "start": 192.48,
      "end": 194.56,
      "text": "and you can go ahead and see the slides"
    },
    {
      "start": 194.56,
      "end": 195.84,
      "text": "that we're going to be using today"
    },
    {
      "start": 195.84,
      "end": 198.32,
      "text": "as part of the slides folder, there are only eight slides"
    },
    {
      "start": 198.32,
      "end": 199.88,
      "text": "and I'm not going to be doing a lot of swapping"
    },
    {
      "start": 199.88,
      "end": 200.72,
      "text": "between the slides."
    },
    {
      "start": 200.72,
      "end": 204.64,
      "text": "Just going to be a point where I hit the code element."
    },
    {
      "start": 204.64,
      "end": 206.16,
      "text": "And a lot of the rest of the classes"
    },
    {
      "start": 206.16,
      "end": 209.88,
      "text": "just going to be me navigating through the LangSmith"
    },
    {
      "start": 209.88,
      "end": 214.88,
      "text": "and my VS code environment and the LangSmith platform."
    },
    {
      "start": 216.52,
      "end": 220.96,
      "text": "So I won't be coming back too much to the slides itself,"
    },
    {
      "start": 220.96,
      "end": 224.2,
      "text": "but if you still want to recognize where we are"
    },
    {
      "start": 224.2,
      "end": 228.56,
      "text": "in at which portion of the class,"
    },
    {
      "start": 228.56,
      "end": 231.68,
      "text": "just think of the slides as chapters, for example."
    },
    {
      "start": 231.68,
      "end": 234.36,
      "text": "But I just want to kind of try to minimize"
    },
    {
      "start": 234.36,
      "end": 237.88,
      "text": "a lot of my screen swapping here."
    },
    {
      "start": 237.88,
      "end": 244.0,
      "text": "So with that said, good job on day one, welcome to day two."
    },
    {
      "start": 244.0,
      "end": 245.6,
      "text": "And great job on some of the assignments."
    },
    {
      "start": 245.6,
      "end": 248.4,
      "text": "I know Jonathan's been going over like overseeing"
    },
    {
      "start": 248.4,
      "end": 251.24,
      "text": "some of the home of some of the assignments"
    },
    {
      "start": 251.24,
      "end": 253.48,
      "text": "and some of the some of the submissions"
    },
    {
      "start": 253.48,
      "end": 254.16,
      "text": "you've been making."
    },
    {
      "start": 254.16,
      "end": 255.8,
      "text": "I've been hearing some really cool stories"
    },
    {
      "start": 255.8,
      "end": 257.04,
      "text": "on the little bit that I've been able to see"
    },
    {
      "start": 257.12,
      "end": 258.4,
      "text": "and we're seeing some really cool stuff."
    },
    {
      "start": 258.4,
      "end": 260.76,
      "text": "So keep up the wild squirrels."
    },
    {
      "start": 260.76,
      "end": 264.28,
      "text": "That is an inside jump between Jonathan and me"
    },
    {
      "start": 264.28,
      "end": 268.12,
      "text": "regarding some of the LLM tools that you've been turning in."
    },
    {
      "start": 268.12,
      "end": 269.4,
      "text": "So let's go ahead and get started."
    },
    {
      "start": 269.4,
      "end": 270.48,
      "text": "What are we going to be doing today?"
    },
    {
      "start": 270.48,
      "end": 271.32,
      "text": "Or what are we going?"
    },
    {
      "start": 271.32,
      "end": 274.36,
      "text": "What can we expect to be done with at the end of the day?"
    },
    {
      "start": 274.36,
      "end": 275.96,
      "text": "We're going to introduce you to LangSmith."
    },
    {
      "start": 275.96,
      "end": 277.96,
      "text": "You're going to have a chance to create an account."
    },
    {
      "start": 277.96,
      "end": 281.0,
      "text": "You're going to have a chance to create your own API key with them."
    },
    {
      "start": 281.0,
      "end": 283.84,
      "text": "We're going to talk a little bit about how to set it up,"
    },
    {
      "start": 283.84,
      "end": 287.72,
      "text": "how to kind of create your own free account with LangSmith."
    },
    {
      "start": 287.72,
      "end": 291.56,
      "text": "Now there are a number of tiers available in LangSmith."
    },
    {
      "start": 292.96,
      "end": 295.12,
      "text": "Kind of can get a little bit too,"
    },
    {
      "start": 295.12,
      "end": 298.96,
      "text": "it can be a little bit pricey after a certain amount of use."
    },
    {
      "start": 298.96,
      "end": 302.36,
      "text": "So we are also going to showcase and recommend"
    },
    {
      "start": 302.36,
      "end": 306.16,
      "text": "and potentially depending on how our comfort developers"
    },
    {
      "start": 306.16,
      "end": 307.76,
      "text": "operate and how comfortable we're feeling"
    },
    {
      "start": 307.76,
      "end": 308.88,
      "text": "with one tool versus the other."
    },
    {
      "start": 308.88,
      "end": 312.48,
      "text": "We may end up adopting some of a very similar product"
    },
    {
      "start": 312.48,
      "end": 314.08,
      "text": "called LangFuse."
    },
    {
      "start": 314.08,
      "end": 317.32,
      "text": "Think of it as an open source version of LangSmith."
    },
    {
      "start": 317.32,
      "end": 319.24,
      "text": "We're going to do a little bit of coding."
    },
    {
      "start": 319.24,
      "end": 325.28,
      "text": "We're going to send some LLM code up to the LangSmith platform"
    },
    {
      "start": 325.28,
      "end": 326.28,
      "text": "and we're going to be able to see"
    },
    {
      "start": 326.28,
      "end": 328.44,
      "text": "how those calls operate within LangSmith."
    },
    {
      "start": 328.44,
      "end": 330.92,
      "text": "And we're going to be able to really manually,"
    },
    {
      "start": 330.92,
      "end": 335.8,
      "text": "very manually access and create some data sets within LangSmith."
    },
    {
      "start": 335.8,
      "end": 337.28,
      "text": "And hopefully if we have time,"
    },
    {
      "start": 337.28,
      "end": 339.44,
      "text": "I do have a little bit of code, a little bit of the script"
    },
    {
      "start": 339.44,
      "end": 347.44,
      "text": "to use some of the generated content that GPT creates"
    },
    {
      "start": 347.44,
      "end": 353.17,
      "text": "to use as prompts in order to improve the,"
    },
    {
      "start": 353.17,
      "end": 357.77,
      "text": "use the prompts, use the code that GPT creates to prompt"
    },
    {
      "start": 357.77,
      "end": 359.65,
      "text": "and create and improve some of the code"
    },
    {
      "start": 359.65,
      "end": 362.17,
      "text": "we build down around all of this on LangSmith."
    },
    {
      "start": 362.17,
      "end": 363.57,
      "text": "But what is really like this meant?"
    },
    {
      "start": 363.57,
      "end": 367.05,
      "text": "So essentially a platform of tools and services"
    },
    {
      "start": 367.05,
      "end": 370.21,
      "text": "that is built into the link chain or built with link chain"
    },
    {
      "start": 370.21,
      "end": 374.53,
      "text": "to really help us build a debug and monitor some of the LLMs"
    },
    {
      "start": 374.53,
      "end": 378.69,
      "text": "that we're going to be creating and building applications for."
    },
    {
      "start": 378.69,
      "end": 380.41,
      "text": "This is a tool that sort of adds,"
    },
    {
      "start": 380.41,
      "end": 383.17,
      "text": "it creates a one stop, one stop place for all"
    },
    {
      "start": 383.17,
      "end": 386.25,
      "text": "of the different steps from tracking, debugging,"
    },
    {
      "start": 386.25,
      "end": 389.97,
      "text": "creating, looking at a history of all of the LLM calls"
    },
    {
      "start": 389.97,
      "end": 392.45,
      "text": "helps us build some insights into some of the systems"
    },
    {
      "start": 392.45,
      "end": 395.17,
      "text": "that are happening behind the scenes."
    },
    {
      "start": 395.17,
      "end": 398.49,
      "text": "It'll allow us to look at the monitor,"
    },
    {
      "start": 398.49,
      "end": 402.85,
      "text": "the performance of the LLM and really the debugging aspect"
    },
    {
      "start": 402.85,
      "end": 406.77,
      "text": "of LangSmith is actually really powerful."
    },
    {
      "start": 406.77,
      "end": 412.97,
      "text": "It's really interesting to be able to see every step of code."
    },
    {
      "start": 412.97,
      "end": 416.97,
      "text": "It's fun to see like it's not necessarily building"
    },
    {
      "start": 416.97,
      "end": 420.77,
      "text": "a kind of error prompting for every little block of code."
    },
    {
      "start": 420.77,
      "end": 422.41,
      "text": "But to a certain extent, it will tell you"
    },
    {
      "start": 422.41,
      "end": 423.93,
      "text": "where there might be limitations,"
    },
    {
      "start": 423.93,
      "end": 427.17,
      "text": "there were there might be blockers at which particular component."
    },
    {
      "start": 427.17,
      "end": 429.93,
      "text": "And that was something that I ended up working with today"
    },
    {
      "start": 429.93,
      "end": 432.77,
      "text": "because as we continue to improve some of the curriculum,"
    },
    {
      "start": 432.77,
      "end": 434.77,
      "text": "I was like building it into LangSmith,"
    },
    {
      "start": 434.77,
      "end": 440.25,
      "text": "we were able to see where some of the models were getting hung up."
    },
    {
      "start": 440.25,
      "end": 445.13,
      "text": "It's also really cool tool for user interaction"
    },
    {
      "start": 445.13,
      "end": 448.61,
      "text": "in the sense of how to score and how to evaluate your results."
    },
    {
      "start": 448.61,
      "end": 449.89,
      "text": "We're going to see Bob."
    },
    {
      "start": 449.89,
      "end": 455.73,
      "text": "I'm going to just show you some of the evaluation tools"
    },
    {
      "start": 455.73,
      "end": 456.93,
      "text": "that LangSmith has."
    },
    {
      "start": 456.93,
      "end": 459.37,
      "text": "We're not going to be spending too much time on that today."
    },
    {
      "start": 459.37,
      "end": 462.81,
      "text": "But I am going to show you how you can either through yourself"
    },
    {
      "start": 462.81,
      "end": 464.69,
      "text": "or through a fellow team member,"
    },
    {
      "start": 464.69,
      "end": 466.37,
      "text": "you can evaluate some of the responses"
    },
    {
      "start": 466.37,
      "end": 469.45,
      "text": "that your GPT creates."
    },
    {
      "start": 469.45,
      "end": 472.29,
      "text": "And of course, it's always good for an environment"
    },
    {
      "start": 472.29,
      "end": 475.92,
      "text": "to store your LLM responses."
    },
    {
      "start": 475.92,
      "end": 479.6,
      "text": "So with that said, any questions before I move forward?"
    },
    {
      "start": 480.76,
      "end": 484.48,
      "text": "So this is pretty much about all we're going to do with the slides."
    },
    {
      "start": 484.48,
      "end": 486.64,
      "text": "I'm going to go ahead and just start us off"
    },
    {
      "start": 486.64,
      "end": 490.2,
      "text": "by navigating over to the repository."
    },
    {
      "start": 490.2,
      "end": 494.28,
      "text": "While I was talking, I'm hoping you've had a chance to fork"
    },
    {
      "start": 494.28,
      "end": 495.84,
      "text": "and clone this repository."
    },
    {
      "start": 495.84,
      "end": 497.48,
      "text": "We're going to go through very similar steps"
    },
    {
      "start": 497.48,
      "end": 500.16,
      "text": "to what we did yesterday."
    },
    {
      "start": 500.16,
      "end": 504.24,
      "text": "My advice at this point is for the most part,"
    },
    {
      "start": 504.24,
      "end": 508.24,
      "text": "a lot of our packages are going to be very similar."
    },
    {
      "start": 508.24,
      "end": 510.4,
      "text": "So we are adding a couple of extra requirements"
    },
    {
      "start": 510.4,
      "end": 511.72,
      "text": "to our TXT file."
    },
    {
      "start": 511.72,
      "end": 516.04,
      "text": "So in this case, we are including both LangSmith and LangFuse."
    },
    {
      "start": 516.04,
      "end": 518.84,
      "text": "I'm actually going to be incorporating python.end"
    },
    {
      "start": 518.84,
      "end": 521.04,
      "text": "and the LangShave Hub."
    },
    {
      "start": 521.04,
      "end": 524.64,
      "text": "This, the beautiful suit for, I do recommend"
    },
    {
      "start": 524.64,
      "end": 527.6,
      "text": "you have your own environment set up for that"
    },
    {
      "start": 527.6,
      "end": 530.12,
      "text": "because it can be a little bit tricky sometimes"
    },
    {
      "start": 530.12,
      "end": 533.32,
      "text": "to depending on your versions of a beautiful suit"
    },
    {
      "start": 533.32,
      "end": 536.16,
      "text": "to access with one of these tools."
    },
    {
      "start": 536.16,
      "end": 542.43,
      "text": "So I just want to make sure, if I need to go through this step,"
    },
    {
      "start": 542.43,
      "end": 545.59,
      "text": "is there anyone who reads through this list of steps"
    },
    {
      "start": 545.59,
      "end": 551.05,
      "text": "and is a little like, I'm not super comfortable with this?"
    },
    {
      "start": 551.05,
      "end": 553.05,
      "text": "You can go ahead and give me a thumbs up."
    },
    {
      "start": 553.05,
      "end": 553.93,
      "text": "Like no harm, no fault."
    },
    {
      "start": 553.93,
      "end": 555.61,
      "text": "Otherwise, I'm just going to go straight"
    },
    {
      "start": 555.61,
      "end": 557.45,
      "text": "into assuming that your environment is set up"
    },
    {
      "start": 557.45,
      "end": 559.48,
      "text": "and you're good to go."
    },
    {
      "start": 559.48,
      "end": 562.9,
      "text": "I see one on, which is a good thing."
    },
    {
      "start": 562.9,
      "end": 565.27,
      "text": "I'm OK with that."
    },
    {
      "start": 565.27,
      "end": 566.71,
      "text": "And if you're having trouble with this,"
    },
    {
      "start": 566.71,
      "end": 569.35,
      "text": "OK, you're welcome to go back to class number one."
    },
    {
      "start": 569.39,
      "end": 571.23,
      "text": "We had a walkthrough of this session."
    },
    {
      "start": 571.23,
      "end": 572.55,
      "text": "These instructions are super clear."
    },
    {
      "start": 572.55,
      "end": 574.63,
      "text": "So if you have any trouble with that,"
    },
    {
      "start": 574.63,
      "end": 576.27,
      "text": "give me a call out, give me a shout out."
    },
    {
      "start": 576.27,
      "end": 579.07,
      "text": "And sorry, I didn't mean to call anyone out specifically there."
    },
    {
      "start": 579.07,
      "end": 581.35,
      "text": "I actually, that really helps me in terms of feedback."
    },
    {
      "start": 581.35,
      "end": 583.03,
      "text": "That means like, cool, we can get going."
    },
    {
      "start": 583.03,
      "end": 584.83,
      "text": "We can get ahead and get moving."
    },
    {
      "start": 584.83,
      "end": 589.79,
      "text": "So yeah, if you have your environment set up,"
    },
    {
      "start": 589.79,
      "end": 595.43,
      "text": "I'm going to be doing my first initial bit of code in VSCount."
    },
    {
      "start": 595.43,
      "end": 597.55,
      "text": "I like to use its terminal there in that environment."
    },
    {
      "start": 597.55,
      "end": 600.11,
      "text": "And I'm going to go ahead and ask you,"
    },
    {
      "start": 600.11,
      "end": 602.51,
      "text": "give you a couple of minutes to kind of settle in."
    },
    {
      "start": 602.51,
      "end": 605.2,
      "text": "You have any questions?"
    },
    {
      "start": 605.2,
      "end": 606.0,
      "text": "Good."
    },
    {
      "start": 606.0,
      "end": 607.12,
      "text": "Yeah, no, I get it."
    },
    {
      "start": 607.12,
      "end": 608.88,
      "text": "No harm, no foul."
    },
    {
      "start": 608.88,
      "end": 611.4,
      "text": "It is, like I said, I want to know,"
    },
    {
      "start": 611.4,
      "end": 614.48,
      "text": "I want to keep up to the pace that works for you."
    },
    {
      "start": 614.48,
      "end": 616.24,
      "text": "But here's what I'm going to do first."
    },
    {
      "start": 616.24,
      "end": 618.12,
      "text": "We're essentially going to start this lecture off"
    },
    {
      "start": 618.12,
      "end": 624.66,
      "text": "with a little bit of a demo of the session itself."
    },
    {
      "start": 624.66,
      "end": 629.06,
      "text": "And in this case, we actually are calling the,"
    },
    {
      "start": 629.06,
      "end": 630.42,
      "text": "because this is, I think, some of the code"
    },
    {
      "start": 630.42,
      "end": 631.98,
      "text": "from the documentation directly,"
    },
    {
      "start": 631.98,
      "end": 640.46,
      "text": "we're actually calling OpenAI directly from the OpenAI API"
    },
    {
      "start": 640.46,
      "end": 643.38,
      "text": "from its own API instead of, like, directly from Langston."
    },
    {
      "start": 643.38,
      "end": 644.7,
      "text": "And the reason for that is I do want"
    },
    {
      "start": 644.7,
      "end": 647.02,
      "text": "to be able to just kind of loss over a little bit"
    },
    {
      "start": 647.02,
      "end": 649.78,
      "text": "about what these tools are doing."
    },
    {
      "start": 649.78,
      "end": 652.26,
      "text": "So the OpenAI is coming directly from OpenAI."
    },
    {
      "start": 652.26,
      "end": 655.02,
      "text": "I think this is the only instance where we use that."
    },
    {
      "start": 655.02,
      "end": 658.82,
      "text": "But Langston and Langshane offer a couple of different wrappers"
    },
    {
      "start": 658.82,
      "end": 662.06,
      "text": "and decorators that we're going to be using in our code."
    },
    {
      "start": 662.06,
      "end": 666.5,
      "text": "Again, this is intended to be able to fit the packages"
    },
    {
      "start": 666.5,
      "end": 671.94,
      "text": "that we're using within the Langshane framework."
    },
    {
      "start": 671.94,
      "end": 675.18,
      "text": "This is also a lecture, we'll talk a little bit about how"
    },
    {
      "start": 675.18,
      "end": 678.9,
      "text": "the chains actually operate in the Python code."
    },
    {
      "start": 678.9,
      "end": 681.54,
      "text": "So wrap OpenAI is going to be a wrapper"
    },
    {
      "start": 681.54,
      "end": 684.78,
      "text": "that we're going to be using for accessing the OpenAI"
    },
    {
      "start": 684.78,
      "end": 687.26,
      "text": "within the Langshane framework."
    },
    {
      "start": 687.26,
      "end": 688.74,
      "text": "Traceable is going to be a decorator"
    },
    {
      "start": 688.74,
      "end": 691.46,
      "text": "that we're going to be using for some of the code"
    },
    {
      "start": 691.46,
      "end": 692.62,
      "text": "in order to commute."
    },
    {
      "start": 692.62,
      "end": 697.34,
      "text": "Essentially, think of it as a way to aim to Langshanith"
    },
    {
      "start": 697.34,
      "end": 702.58,
      "text": "that an operation is being performed with Langshanith."
    },
    {
      "start": 702.58,
      "end": 704.7,
      "text": "And we'll be able to see the code that we're running"
    },
    {
      "start": 704.7,
      "end": 711.01,
      "text": "in our local environment on the Langshanith framework."
    },
    {
      "start": 711.01,
      "end": 712.69,
      "text": "With that said, the code behind this"
    },
    {
      "start": 712.69,
      "end": 715.77,
      "text": "is essentially just going to be creating a decorator"
    },
    {
      "start": 715.77,
      "end": 716.73,
      "text": "over the pipeline."
    },
    {
      "start": 716.73,
      "end": 720.01,
      "text": "We're just going to create a very simple hello world"
    },
    {
      "start": 720.01,
      "end": 726.81,
      "text": "just going to be asking our LLM to communicate just"
    },
    {
      "start": 726.81,
      "end": 728.73,
      "text": "a very simple prompt."
    },
    {
      "start": 728.73,
      "end": 732.09,
      "text": "Before we run this command, I do want"
    },
    {
      "start": 732.09,
      "end": 734.81,
      "text": "to make sure that we talk a little bit about making"
    },
    {
      "start": 734.81,
      "end": 738.9,
      "text": "sure that you have your OpenAI keys set up."
    },
    {
      "start": 739.02,
      "end": 742.18,
      "text": "One more thing to make sure we're set here."
    },
    {
      "start": 747.26,
      "end": 751.26,
      "text": "And then we'll make sure to create an account in Langshanith"
    },
    {
      "start": 751.26,
      "end": 753.54,
      "text": "after that."
    },
    {
      "start": 753.54,
      "end": 760.9,
      "text": "So hang on there."
    },
    {
      "start": 760.9,
      "end": 766.16,
      "text": "So this is PT, which we'll post."
    },
    {
      "start": 766.16,
      "end": 771.66,
      "text": "And then this is AI school."
    },
    {
      "start": 771.66,
      "end": 775.34,
      "text": "Let's go to Langshanith, let's do that up."
    },
    {
      "start": 775.46,
      "end": 779.34,
      "text": "And what am I doing here?"
    },
    {
      "start": 779.34,
      "end": 779.86,
      "text": "Yeah."
    },
    {
      "start": 779.86,
      "end": 790.91,
      "text": "So what I want to showcase is the environment here."
    },
    {
      "start": 790.91,
      "end": 793.43,
      "text": "All right, so showcasing a little bit of my keys,"
    },
    {
      "start": 793.43,
      "end": 794.99,
      "text": "these are going to be deleted after today."
    },
    {
      "start": 794.99,
      "end": 798.43,
      "text": "So if you do just add to showcase those, that's fine."
    },
    {
      "start": 798.43,
      "end": 801.56,
      "text": "But what are we going to need for today?"
    },
    {
      "start": 801.56,
      "end": 803.8,
      "text": "Is I'm going to need you to have access to the API key"
    },
    {
      "start": 803.8,
      "end": 805.0,
      "text": "for OpenAI."
    },
    {
      "start": 805.0,
      "end": 808.44,
      "text": "We're going to go to Langshanith and Langshanith"
    },
    {
      "start": 808.72,
      "end": 811.56,
      "text": "to access both the API keys from them."
    },
    {
      "start": 811.56,
      "end": 814.6,
      "text": "And we're also going to be accessing Langshanith"
    },
    {
      "start": 814.6,
      "end": 816.8,
      "text": "just as a demo process."
    },
    {
      "start": 816.8,
      "end": 821.36,
      "text": "So once you have that built into your.environment file,"
    },
    {
      "start": 821.36,
      "end": 824.0,
      "text": "you're either welcome to use that in your.environment file."
    },
    {
      "start": 824.0,
      "end": 828.4,
      "text": "Or you can also use the code from that load environment,"
    },
    {
      "start": 828.4,
      "end": 831.8,
      "text": "or from load.environment to include that"
    },
    {
      "start": 831.8,
      "end": 835.16,
      "text": "in the environment you created."
    },
    {
      "start": 835.16,
      "end": 837.72,
      "text": "I'm still using, where I should still be using."
    },
    {
      "start": 841.98,
      "end": 845.33,
      "text": "Second, there."
    },
    {
      "start": 845.33,
      "end": 847.49,
      "text": "Okay, I'm not actually operating in my environment,"
    },
    {
      "start": 847.49,
      "end": 850.49,
      "text": "so I'll fix that in just a moment."
    },
    {
      "start": 850.49,
      "end": 854.51,
      "text": "But what we're going to be doing first from here"
    },
    {
      "start": 854.51,
      "end": 859.51,
      "text": "is actually just opening up an instance of Langshanith."
    },
    {
      "start": 860.77,
      "end": 866.34,
      "text": "So Langshanith is pretty straightforward to open up."
    },
    {
      "start": 866.54,
      "end": 871.34,
      "text": "Just go over to the, just do a quick search for it."
    },
    {
      "start": 871.34,
      "end": 873.34,
      "text": "You actually can go into the sign-up session."
    },
    {
      "start": 873.34,
      "end": 875.98,
      "text": "I've already created an account with BloomTech,"
    },
    {
      "start": 875.98,
      "end": 880.14,
      "text": "but I want you to get first through this section here."
    },
    {
      "start": 880.14,
      "end": 890.24,
      "text": "This is the first part where we're going to be calling out information."
    },
    {
      "start": 890.36,
      "end": 891.88,
      "text": "And once you've created an account,"
    },
    {
      "start": 891.88,
      "end": 895.36,
      "text": "usually there's a little bit of a series of prompts."
    },
    {
      "start": 895.36,
      "end": 897.36,
      "text": "Because your dashboard have got zero projects"
    },
    {
      "start": 897.36,
      "end": 899.48,
      "text": "I've essentially been deleting everything"
    },
    {
      "start": 899.48,
      "end": 921.1,
      "text": "as I've been creating it, but that was there for a second."
    },
    {
      "start": 921.1,
      "end": 924.3,
      "text": "And from here, you can actually create your own API keys"
    },
    {
      "start": 924.3,
      "end": 926.94,
      "text": "from going over to the settings,"
    },
    {
      "start": 926.94,
      "end": 929.85,
      "text": "and simply create an API key."
    },
    {
      "start": 929.85,
      "end": 932.93,
      "text": "Now, hopefully you selected your free billing."
    },
    {
      "start": 932.93,
      "end": 935.05,
      "text": "The cut, we're not really going to be paying"
    },
    {
      "start": 935.05,
      "end": 936.89,
      "text": "for the $39 per month."
    },
    {
      "start": 939.45,
      "end": 942.53,
      "text": "We've been going hard on Langshanith all month,"
    },
    {
      "start": 942.53,
      "end": 946.17,
      "text": "and I still haven't gotten close to the 5,000 free traces."
    },
    {
      "start": 946.17,
      "end": 951.01,
      "text": "So we should be able to use this for a significant run"
    },
    {
      "start": 951.01,
      "end": 953.21,
      "text": "of the lectures and class."
    },
    {
      "start": 953.21,
      "end": 957.65,
      "text": "But if you don't end up having trouble with that,"
    },
    {
      "start": 957.65,
      "end": 960.41,
      "text": "I do want to go ahead and also recommend"
    },
    {
      "start": 960.41,
      "end": 963.34,
      "text": "the Langfuse environment."
    },
    {
      "start": 963.34,
      "end": 968.34,
      "text": "So Langfuse is a very similar project to Langsmith."
    },
    {
      "start": 969.06,
      "end": 972.22,
      "text": "It's just intended to be much more open-sourced."
    },
    {
      "start": 972.22,
      "end": 974.22,
      "text": "You can access the tool by logging in."
    },
    {
      "start": 974.22,
      "end": 975.82,
      "text": "It's very similar."
    },
    {
      "start": 975.82,
      "end": 978.14,
      "text": "You can see we played around with this just a little bit"
    },
    {
      "start": 978.14,
      "end": 980.82,
      "text": "on this today, but a lot of the framework"
    },
    {
      "start": 980.82,
      "end": 982.14,
      "text": "is going to be very similar."
    },
    {
      "start": 982.14,
      "end": 983.94,
      "text": "And a lot of the things you can do here"
    },
    {
      "start": 983.94,
      "end": 987.06,
      "text": "are going to follow a lot of the same processes."
    },
    {
      "start": 987.06,
      "end": 990.46,
      "text": "It allows you to kind of create that evaluation process."
    },
    {
      "start": 990.46,
      "end": 994.34,
      "text": "I don't expect it to necessarily seem like no, what's going on."
    },
    {
      "start": 994.34,
      "end": 998.9,
      "text": "But we'll have a much more in-depth tour in just a moment."
    },
    {
      "start": 998.9,
      "end": 1001.9,
      "text": "But I just wanted to highlight that between these two tools"
    },
    {
      "start": 1001.9,
      "end": 1005.03,
      "text": "we've got a very similar framework"
    },
    {
      "start": 1005.03,
      "end": 1008.15,
      "text": "or a similar user experience."
    },
    {
      "start": 1008.15,
      "end": 1010.75,
      "text": "So you can go from here to the settings."
    },
    {
      "start": 1010.75,
      "end": 1013.03,
      "text": "At this point, it's a little bit different"
    },
    {
      "start": 1013.03,
      "end": 1017.03,
      "text": "in the sense that for Langfuse, you're actually creating"
    },
    {
      "start": 1017.03,
      "end": 1019.67,
      "text": "and you're actually going to need both a secret key"
    },
    {
      "start": 1019.67,
      "end": 1021.74,
      "text": "and a public key."
    },
    {
      "start": 1021.74,
      "end": 1025.9,
      "text": "So make sure you have both of those elements set up."
    },
    {
      "start": 1025.9,
      "end": 1031.38,
      "text": "Once you've had a chance to do that,"
    },
    {
      "start": 1031.38,
      "end": 1038.33,
      "text": "your environment should hopefully look a little bit like this."
    },
    {
      "start": 1038.33,
      "end": 1050.3,
      "text": "That's not where we're at."
    },
    {
      "start": 1050.3,
      "end": 1052.42,
      "text": "But your environment should look something like this."
    },
    {
      "start": 1052.42,
      "end": 1054.18,
      "text": "And the only parts that you need to include"
    },
    {
      "start": 1054.18,
      "end": 1057.82,
      "text": "are the your super secret key elements for OpenAI."
    },
    {
      "start": 1057.82,
      "end": 1062.02,
      "text": "That's the one that BloomTech is sharing with you."
    },
    {
      "start": 1062.02,
      "end": 1064.58,
      "text": "So that's on Slack, Langshane API key."
    },
    {
      "start": 1064.58,
      "end": 1067.22,
      "text": "That's going to be the same one you can use for Langsmith."
    },
    {
      "start": 1067.22,
      "end": 1070.22,
      "text": "And your super secret key for Langfuse"
    },
    {
      "start": 1070.22,
      "end": 1072.62,
      "text": "just make sure to include that in your secret key."
    },
    {
      "start": 1072.62,
      "end": 1076.67,
      "text": "But also make sure that your public key is also included there."
    },
    {
      "start": 1076.67,
      "end": 1080.85,
      "text": "And I'll give you a minute to get that set up."
    },
    {
      "start": 1080.85,
      "end": 1084.85,
      "text": "Really, when it comes to setting up Langfuse Langshane,"
    },
    {
      "start": 1084.85,
      "end": 1086.79,
      "text": "that's it."
    },
    {
      "start": 1086.79,
      "end": 1094.62,
      "text": "It's not easy."
    },
    {
      "start": 1094.62,
      "end": 1098.42,
      "text": "So again, not trying to rush there."
    },
    {
      "start": 1098.42,
      "end": 1100.06,
      "text": "We're just trying to go over a couple"
    },
    {
      "start": 1100.06,
      "end": 1101.18,
      "text": "like quite a bit of things"
    },
    {
      "start": 1101.18,
      "end": 1102.82,
      "text": "and I want to make sure that you're set up."
    },
    {
      "start": 1102.82,
      "end": 1105.86,
      "text": "But I'm going to do a quick check-in."
    },
    {
      "start": 1105.86,
      "end": 1107.14,
      "text": "You're feeling okay."
    },
    {
      "start": 1107.14,
      "end": 1111.23,
      "text": "Let's keep it going."
    },
    {
      "start": 1111.23,
      "end": 1113.42,
      "text": "Okay."
    },
    {
      "start": 1113.46,
      "end": 1114.94,
      "text": "So with that said,"
    },
    {
      "start": 1114.94,
      "end": 1118.18,
      "text": "really all that I'm doing with this demonstration"
    },
    {
      "start": 1118.18,
      "end": 1120.98,
      "text": "is essentially just showcasing what,"
    },
    {
      "start": 1120.98,
      "end": 1122.94,
      "text": "like how to connect our local computer"
    },
    {
      "start": 1122.94,
      "end": 1124.9,
      "text": "to the Langsmith framework."
    },
    {
      "start": 1124.9,
      "end": 1127.46,
      "text": "So what happens here is that all I'm really doing"
    },
    {
      "start": 1127.46,
      "end": 1132.1,
      "text": "is essentially creating a decorator"
    },
    {
      "start": 1132.1,
      "end": 1133.9,
      "text": "that's going to take this function."
    },
    {
      "start": 1133.9,
      "end": 1136.7,
      "text": "It's going to create essentially"
    },
    {
      "start": 1136.7,
      "end": 1141.7,
      "text": "invoke a specific invoke in Langsmith,"
    },
    {
      "start": 1142.3,
      "end": 1144.3,
      "text": "I'm sorry, the language for me is still stuck"
    },
    {
      "start": 1144.3,
      "end": 1146.18,
      "text": "on the Langsmith language."
    },
    {
      "start": 1146.18,
      "end": 1151.18,
      "text": "But with the base open AI tool,"
    },
    {
      "start": 1151.18,
      "end": 1153.22,
      "text": "we're simply just creating a chat objects"
    },
    {
      "start": 1153.22,
      "end": 1155.34,
      "text": "to create a series of messages."
    },
    {
      "start": 1155.34,
      "end": 1157.58,
      "text": "Again, this is the role that we created earlier."
    },
    {
      "start": 1157.58,
      "end": 1161.82,
      "text": "We're creating a user-based message."
    },
    {
      "start": 1161.82,
      "end": 1165.86,
      "text": "The content's going to come from us here."
    },
    {
      "start": 1165.86,
      "end": 1168.74,
      "text": "We're going to be using the 3.5 to do the turbo."
    },
    {
      "start": 1168.74,
      "end": 1171.18,
      "text": "And then simply put all I'm going to have it do is"
    },
    {
      "start": 1171.18,
      "end": 1174.3,
      "text": "just do a standard call out world."
    },
    {
      "start": 1174.3,
      "end": 1179.1,
      "text": "Let me run a terminal right here in this environment, perfect."
    },
    {
      "start": 1179.1,
      "end": 1186.34,
      "text": "And it's going to be Python 3 in class."
    },
    {
      "start": 1186.34,
      "end": 1189.14,
      "text": "You get down one level there so that I'm"
    },
    {
      "start": 1189.14,
      "end": 1191.86,
      "text": "not typing back for much."
    },
    {
      "start": 1191.86,
      "end": 1193.54,
      "text": "Yeah, perfect."
    },
    {
      "start": 1193.54,
      "end": 1198.03,
      "text": "So Python 3 for me in class,"
    },
    {
      "start": 1198.03,
      "end": 1204.92,
      "text": "and this one's the Langsmith demo."
    },
    {
      "start": 1204.92,
      "end": 1208.17,
      "text": "Come on, I can type."
    },
    {
      "start": 1208.17,
      "end": 1209.73,
      "text": "All right, so pretty straightforward."
    },
    {
      "start": 1209.73,
      "end": 1212.41,
      "text": "That's how that works, or really all I'm doing is"
    },
    {
      "start": 1212.41,
      "end": 1214.85,
      "text": "is having it print out the hello world in my environment."
    },
    {
      "start": 1214.85,
      "end": 1219.05,
      "text": "But what I want to actually notice,"
    },
    {
      "start": 1219.05,
      "end": 1221.29,
      "text": "is that if we go now to our Langsmith,"
    },
    {
      "start": 1221.29,
      "end": 1222.73,
      "text": "we'll see that our project's popped up"
    },
    {
      "start": 1222.73,
      "end": 1227.3,
      "text": "on my local computer, or on my Langsmith platform."
    },
    {
      "start": 1227.3,
      "end": 1229.1,
      "text": "That Langsmith platform, essentially,"
    },
    {
      "start": 1229.1,
      "end": 1231.42,
      "text": "you can see that I just created a moment ago."
    },
    {
      "start": 1231.42,
      "end": 1233.86,
      "text": "We've got a lot of information about the tool"
    },
    {
      "start": 1233.86,
      "end": 1234.94,
      "text": "that I've just created."
    },
    {
      "start": 1234.94,
      "end": 1236.5,
      "text": "I've only run this once."
    },
    {
      "start": 1236.5,
      "end": 1238.46,
      "text": "No errors."
    },
    {
      "start": 1238.46,
      "end": 1241.62,
      "text": "Pretty standard number of tokens, a little bit of information."
    },
    {
      "start": 1241.62,
      "end": 1245.46,
      "text": "This is so inexpensive on my side, but it's essentially"
    },
    {
      "start": 1245.46,
      "end": 1249.3,
      "text": "calling the pipeline that I've created."
    },
    {
      "start": 1249.3,
      "end": 1251.18,
      "text": "Again, this is under the trace pipeline"
    },
    {
      "start": 1251.18,
      "end": 1253.7,
      "text": "that we built a second ago."
    },
    {
      "start": 1253.7,
      "end": 1255.54,
      "text": "Let me close this up as I'm not going to."
    },
    {
      "start": 1255.54,
      "end": 1257.5,
      "text": "I might not, I may need that again in a second."
    },
    {
      "start": 1257.5,
      "end": 1259.34,
      "text": "But all we're doing is essentially"
    },
    {
      "start": 1259.34,
      "end": 1262.94,
      "text": "telling that we ran this code within this environment."
    },
    {
      "start": 1262.94,
      "end": 1266.02,
      "text": "And there's a lot of information that we can get from it."
    },
    {
      "start": 1266.02,
      "end": 1268.5,
      "text": "It can essentially tell us what the input was,"
    },
    {
      "start": 1268.5,
      "end": 1273.5,
      "text": "what the output from the GBT framework returned."
    },
    {
      "start": 1273.5,
      "end": 1274.82,
      "text": "You click on this."
    },
    {
      "start": 1274.82,
      "end": 1276.94,
      "text": "It's essentially just a little bit more"
    },
    {
      "start": 1276.94,
      "end": 1278.82,
      "text": "additional data, including metadata"
    },
    {
      "start": 1278.82,
      "end": 1284.34,
      "text": "about the call and the output itself."
    },
    {
      "start": 1284.34,
      "end": 1285.54,
      "text": "Pretty straightforward, right?"
    },
    {
      "start": 1285.54,
      "end": 1287.78,
      "text": "Nothing too complex from that."
    },
    {
      "start": 1287.78,
      "end": 1290.7,
      "text": "But this is where things start."
    },
    {
      "start": 1290.7,
      "end": 1293.94,
      "text": "If we know that our LLMs are being recorded somewhere,"
    },
    {
      "start": 1293.94,
      "end": 1296.22,
      "text": "it means that we can now do a lot more with this."
    },
    {
      "start": 1296.22,
      "end": 1299.34,
      "text": "We can essentially take a look at how we can add this"
    },
    {
      "start": 1299.34,
      "end": 1300.14,
      "text": "to a data set."
    },
    {
      "start": 1300.14,
      "end": 1302.46,
      "text": "We'll talk a little bit more about the annotation queue."
    },
    {
      "start": 1302.46,
      "end": 1304.06,
      "text": "But the information behind this is"
    },
    {
      "start": 1304.06,
      "end": 1306.46,
      "text": "that we are now starting to create a framework"
    },
    {
      "start": 1306.46,
      "end": 1311.38,
      "text": "where we can either run it again, perhaps"
    },
    {
      "start": 1311.38,
      "end": 1313.02,
      "text": "with a different message."
    },
    {
      "start": 1313.02,
      "end": 1314.54,
      "text": "Hello folks."
    },
    {
      "start": 1314.54,
      "end": 1317.14,
      "text": "I don't know, we'll do that if we wanted to."
    },
    {
      "start": 1317.14,
      "end": 1318.22,
      "text": "Pretty straightforward."
    },
    {
      "start": 1318.22,
      "end": 1323.11,
      "text": "And it's going to be recorded inside the call"
    },
    {
      "start": 1323.11,
      "end": 1324.27,
      "text": "as its own separate call."
    },
    {
      "start": 1324.27,
      "end": 1326.99,
      "text": "But it's still going to be part of the same project."
    },
    {
      "start": 1326.99,
      "end": 1331.55,
      "text": "Because we traced this, this particular script"
    },
    {
      "start": 1331.55,
      "end": 1333.83,
      "text": "as part of this default, this project"
    },
    {
      "start": 1333.83,
      "end": 1336.86,
      "text": "that we just happened to name the fault."
    },
    {
      "start": 1336.86,
      "end": 1339.98,
      "text": "And there's additional metadata about that."
    },
    {
      "start": 1339.98,
      "end": 1344.49,
      "text": "So the same thing will happen with Langfews."
    },
    {
      "start": 1344.49,
      "end": 1349.49,
      "text": "So in this case, we're using again, a very similar operator"
    },
    {
      "start": 1349.49,
      "end": 1354.21,
      "text": "or excuse me, decorator to the traceable decorator"
    },
    {
      "start": 1354.29,
      "end": 1356.05,
      "text": "that exists within LangSmith."
    },
    {
      "start": 1356.05,
      "end": 1358.25,
      "text": "But the observer decorator is essentially"
    },
    {
      "start": 1358.25,
      "end": 1360.01,
      "text": "going to be built about around this function"
    },
    {
      "start": 1360.01,
      "end": 1364.61,
      "text": "that's going to be using the OpenAI chat create framework."
    },
    {
      "start": 1364.61,
      "end": 1367.73,
      "text": "Again, this is all exactly the same thing"
    },
    {
      "start": 1367.73,
      "end": 1373.21,
      "text": "as we did with the LangSmith code."
    },
    {
      "start": 1373.21,
      "end": 1375.33,
      "text": "We're just going to pull the content directly."
    },
    {
      "start": 1375.33,
      "end": 1377.69,
      "text": "The decorator is going to look at the function itself,"
    },
    {
      "start": 1377.69,
      "end": 1379.81,
      "text": "and it's going to return that main story"
    },
    {
      "start": 1379.81,
      "end": 1381.69,
      "text": "or the main story function that we created here."
    },
    {
      "start": 1381.69,
      "end": 1383.45,
      "text": "And again, we're just asking it's"
    },
    {
      "start": 1383.45,
      "end": 1385.97,
      "text": "OK, you're a great storyteller."
    },
    {
      "start": 1385.97,
      "end": 1389.93,
      "text": "Fill out the rest of the content here"
    },
    {
      "start": 1389.93,
      "end": 1390.89,
      "text": "and what would that look like?"
    },
    {
      "start": 1390.89,
      "end": 1395.28,
      "text": "So if I were to run this code instead of LangSmith,"
    },
    {
      "start": 1395.28,
      "end": 1400.66,
      "text": "just going to take Langfews demo."
    },
    {
      "start": 1400.66,
      "end": 1401.82,
      "text": "It's got a second."
    },
    {
      "start": 1401.82,
      "end": 1403.34,
      "text": "Looks like it ran."
    },
    {
      "start": 1403.34,
      "end": 1413.14,
      "text": "If I go over to Langfews, I should have projects."
    },
    {
      "start": 1413.14,
      "end": 1417.21,
      "text": "Yeah."
    },
    {
      "start": 1417.21,
      "end": 1419.26,
      "text": "Could you do?"
    },
    {
      "start": 1419.26,
      "end": 1422.49,
      "text": "Let's see."
    },
    {
      "start": 1422.49,
      "end": 1423.49,
      "text": "OK."
    },
    {
      "start": 1423.49,
      "end": 1425.85,
      "text": "So this is my full of the trace."
    },
    {
      "start": 1425.89,
      "end": 1426.69,
      "text": "There you go."
    },
    {
      "start": 1426.69,
      "end": 1427.45,
      "text": "Let's look it up."
    },
    {
      "start": 1427.45,
      "end": 1430.06,
      "text": "Here we go."
    },
    {
      "start": 1430.06,
      "end": 1430.74,
      "text": "Yep."
    },
    {
      "start": 1430.74,
      "end": 1432.56,
      "text": "So here's that."
    },
    {
      "start": 1432.56,
      "end": 1434.92,
      "text": "I can click on the trace detail."
    },
    {
      "start": 1434.92,
      "end": 1438.02,
      "text": "And it's all essentially very similar."
    },
    {
      "start": 1438.02,
      "end": 1439.62,
      "text": "Except this one's open source."
    },
    {
      "start": 1439.62,
      "end": 1442.74,
      "text": "It's a little bit less expensive than LangSmith."
    },
    {
      "start": 1442.74,
      "end": 1446.42,
      "text": "So everything's just kind of organized a little bit different."
    },
    {
      "start": 1446.42,
      "end": 1448.18,
      "text": "So we just wanted to introduce both tools"
    },
    {
      "start": 1448.18,
      "end": 1453.26,
      "text": "to give you the chance to select your preferred path to work with."
    },
    {
      "start": 1453.26,
      "end": 1456.3,
      "text": "And from there, you can essentially"
    },
    {
      "start": 1456.3,
      "end": 1460.93,
      "text": "operate from that environment."
    },
    {
      "start": 1460.93,
      "end": 1462.21,
      "text": "Any questions in this case?"
    },
    {
      "start": 1462.21,
      "end": 1463.33,
      "text": "You don't need to use both."
    },
    {
      "start": 1463.33,
      "end": 1464.77,
      "text": "You're not going to be expected to use both."
    },
    {
      "start": 1464.77,
      "end": 1466.49,
      "text": "Most of the material as it's built so far"
    },
    {
      "start": 1466.49,
      "end": 1467.89,
      "text": "is built using LangSmith."
    },
    {
      "start": 1467.89,
      "end": 1470.05,
      "text": "So it's up to you if you have a preference."
    },
    {
      "start": 1470.05,
      "end": 1471.97,
      "text": "But if you're going to be putting your own credit card down,"
    },
    {
      "start": 1471.97,
      "end": 1473.61,
      "text": "and that's a budget as a concern,"
    },
    {
      "start": 1473.61,
      "end": 1478.38,
      "text": "Langfews is another option."
    },
    {
      "start": 1478.38,
      "end": 1484.25,
      "text": "Moment there to see if any questions have come through."
    },
    {
      "start": 1484.25,
      "end": 1485.29,
      "text": "OK, wait, one question."
    },
    {
      "start": 1485.29,
      "end": 1486.49,
      "text": "Oh, hang on."
    },
    {
      "start": 1486.49,
      "end": 1487.65,
      "text": "Next session, small nifty."
    },
    {
      "start": 1487.65,
      "end": 1488.77,
      "text": "Irish is quite craft."
    },
    {
      "start": 1488.77,
      "end": 1490.73,
      "text": "Ooh, thank you."
    },
    {
      "start": 1490.73,
      "end": 1494.49,
      "text": "Up the resolution, Luke, are we talking about?"
    },
    {
      "start": 1494.49,
      "end": 1495.81,
      "text": "Alex, thank you for that feedback."
    },
    {
      "start": 1495.81,
      "end": 1500.37,
      "text": "Sorry that I took me a second to actually look at it."
    },
    {
      "start": 1500.37,
      "end": 1501.61,
      "text": "It's no rush."
    },
    {
      "start": 1501.61,
      "end": 1503.13,
      "text": "It's fine for this session."
    },
    {
      "start": 1503.13,
      "end": 1504.13,
      "text": "Oh, OK."
    },
    {
      "start": 1504.13,
      "end": 1505.29,
      "text": "Or better?"
    },
    {
      "start": 1505.29,
      "end": 1506.49,
      "text": "Yeah, perfect."
    },
    {
      "start": 1506.49,
      "end": 1508.97,
      "text": "Yeah, man, I can see it."
    },
    {
      "start": 1508.97,
      "end": 1510.57,
      "text": "Yeah, and again, if I miss a message,"
    },
    {
      "start": 1510.57,
      "end": 1513.69,
      "text": "which is a thing that happens, please call me out."
    },
    {
      "start": 1513.69,
      "end": 1516.19,
      "text": "That happens sometimes."
    },
    {
      "start": 1516.19,
      "end": 1519.72,
      "text": "I'm not shy."
    },
    {
      "start": 1519.72,
      "end": 1524.95,
      "text": "OK."
    },
    {
      "start": 1524.95,
      "end": 1527.75,
      "text": "Cool, all right, so no questions about Langfews."
    },
    {
      "start": 1527.75,
      "end": 1529.83,
      "text": "Let's go ahead and I'm going to go ahead for myself."
    },
    {
      "start": 1529.83,
      "end": 1531.71,
      "text": "I'm going to close up Langfews because most of the rest"
    },
    {
      "start": 1531.71,
      "end": 1538.55,
      "text": "of the content is going to be built on top of Langfews' tool."
    },
    {
      "start": 1538.55,
      "end": 1541.63,
      "text": "And that was for later."
    },
    {
      "start": 1541.63,
      "end": 1544.03,
      "text": "I'm going to skip the prompting demo for right now"
    },
    {
      "start": 1544.03,
      "end": 1547.07,
      "text": "because that's going to make sense in a little bit"
    },
    {
      "start": 1547.07,
      "end": 1550.71,
      "text": "in a little bit for the next bit."
    },
    {
      "start": 1550.71,
      "end": 1554.86,
      "text": "So I'm going to pull up the slides once more."
    },
    {
      "start": 1554.86,
      "end": 1557.02,
      "text": "The slides I've managed to actually close up."
    },
    {
      "start": 1557.02,
      "end": 1561.67,
      "text": "Sorry about that."
    },
    {
      "start": 1561.67,
      "end": 1563.23,
      "text": "Yeah."
    },
    {
      "start": 1563.23,
      "end": 1566.51,
      "text": "Because we've tested both of these tools."
    },
    {
      "start": 1566.51,
      "end": 1567.39,
      "text": "This is Langfews."
    },
    {
      "start": 1567.39,
      "end": 1569.67,
      "text": "We actually did it through this."
    },
    {
      "start": 1569.67,
      "end": 1571.27,
      "text": "We're going to be spending more time next week"
    },
    {
      "start": 1571.27,
      "end": 1572.83,
      "text": "talking about Rags in general."
    },
    {
      "start": 1572.83,
      "end": 1575.75,
      "text": "But I do want to essentially address a little bit"
    },
    {
      "start": 1575.75,
      "end": 1579.07,
      "text": "about how you can use Rags within Langsmiths environment"
    },
    {
      "start": 1579.07,
      "end": 1583.35,
      "text": "to kind of see the different steps that we've just talked about."
    },
    {
      "start": 1583.35,
      "end": 1586.43,
      "text": "How do you evaluate the multiple steps"
    },
    {
      "start": 1586.43,
      "end": 1588.87,
      "text": "that kind of go through?"
    },
    {
      "start": 1588.87,
      "end": 1592.15,
      "text": "How you can eventually evaluate the individual costs"
    },
    {
      "start": 1592.15,
      "end": 1593.27,
      "text": "of a particular process."
    },
    {
      "start": 1593.27,
      "end": 1596.59,
      "text": "Like you could actually monitor where a specific element"
    },
    {
      "start": 1596.59,
      "end": 1598.03,
      "text": "is potentially created."
    },
    {
      "start": 1598.03,
      "end": 1600.79,
      "text": "So I'm going to be guiding the next part"
    },
    {
      "start": 1600.79,
      "end": 1603.35,
      "text": "of this lecture with these questions in mind."
    },
    {
      "start": 1603.35,
      "end": 1606.63,
      "text": "But I don't want to have necessarily the slides open"
    },
    {
      "start": 1606.63,
      "end": 1608.87,
      "text": "for this whole time."
    },
    {
      "start": 1608.87,
      "end": 1612.67,
      "text": "But I am going to ask that if you want to follow along,"
    },
    {
      "start": 1612.67,
      "end": 1614.67,
      "text": "if you want to see for yourself what this looks like"
    },
    {
      "start": 1614.67,
      "end": 1619.95,
      "text": "in the Langsmith environment, check out the notebook format."
    },
    {
      "start": 1619.95,
      "end": 1621.71,
      "text": "And I created this in a notebook format simply"
    },
    {
      "start": 1621.71,
      "end": 1624.67,
      "text": "because I want to be able to talk a little bit about the couple"
    },
    {
      "start": 1624.67,
      "end": 1628.51,
      "text": "of different parts of the code here."
    },
    {
      "start": 1628.51,
      "end": 1634.95,
      "text": "So again, some of this we'll talk more about next week."
    },
    {
      "start": 1634.95,
      "end": 1640.99,
      "text": "A lot of our tools are going to be saved into the vector databases"
    },
    {
      "start": 1640.99,
      "end": 1643.03,
      "text": "that we're going to be using as a local database called"
    },
    {
      "start": 1643.03,
      "end": 1644.99,
      "text": "Chroma, more on that later on."
    },
    {
      "start": 1644.99,
      "end": 1647.91,
      "text": "But essentially all of these come from the Langchain package,"
    },
    {
      "start": 1647.91,
      "end": 1649.27,
      "text": "including the Langchain community."
    },
    {
      "start": 1649.27,
      "end": 1651.83,
      "text": "Again, Langchain community is essentially"
    },
    {
      "start": 1651.83,
      "end": 1654.19,
      "text": "where users can submit their own tools"
    },
    {
      "start": 1654.19,
      "end": 1656.63,
      "text": "or their own frameworks, models, things like that"
    },
    {
      "start": 1656.63,
      "end": 1661.95,
      "text": "in order to create different scrapers, web loaders,"
    },
    {
      "start": 1661.95,
      "end": 1665.95,
      "text": "interpreters of like beautiful text, for example,"
    },
    {
      "start": 1665.95,
      "end": 1668.95,
      "text": "which is web-based loader, like I don't know about you,"
    },
    {
      "start": 1668.95,
      "end": 1670.99,
      "text": "but once I started using this, like BS4,"
    },
    {
      "start": 1671.51,
      "end": 1677.9,
      "text": "it just doesn't, it works so well."
    },
    {
      "start": 1677.9,
      "end": 1680.54,
      "text": "If you remember in the last class, we were adding dot content"
    },
    {
      "start": 1680.54,
      "end": 1683.9,
      "text": "at the end of all of our LLM calls."
    },
    {
      "start": 1683.9,
      "end": 1686.74,
      "text": "String out parser is essentially Langchain's alternative"
    },
    {
      "start": 1686.74,
      "end": 1687.34,
      "text": "to that."
    },
    {
      "start": 1687.34,
      "end": 1689.66,
      "text": "And again, this will be more about it next week."
    },
    {
      "start": 1689.66,
      "end": 1692.54,
      "text": "But I do want to be familiar with that what this does"
    },
    {
      "start": 1692.54,
      "end": 1694.5,
      "text": "or what String out parser does essentially just"
    },
    {
      "start": 1694.5,
      "end": 1699.46,
      "text": "takes the output or the text-based output of the code itself."
    },
    {
      "start": 1699.54,
      "end": 1702.62,
      "text": "We'll be embedding all of these tools, again,"
    },
    {
      "start": 1702.62,
      "end": 1705.14,
      "text": "that's going to be getting back into Chrome itself."
    },
    {
      "start": 1705.14,
      "end": 1707.14,
      "text": "The other tool that you may have heard for,"
    },
    {
      "start": 1707.14,
      "end": 1709.86,
      "text": "you may have been familiar with this Python gun,"
    },
    {
      "start": 1709.86,
      "end": 1712.06,
      "text": "but that's what we're going to be working with here."
    },
    {
      "start": 1712.06,
      "end": 1714.74,
      "text": "And again, recursive character text"
    },
    {
      "start": 1714.74,
      "end": 1718.22,
      "text": "litter, all of this are just cleaning tools."
    },
    {
      "start": 1718.22,
      "end": 1719.3,
      "text": "Make sure that works."
    },
    {
      "start": 1719.3,
      "end": 1721.66,
      "text": "So what I'm going to be taking is I'm"
    },
    {
      "start": 1721.66,
      "end": 1727.79,
      "text": "going to be accessing a specific document"
    },
    {
      "start": 1727.79,
      "end": 1731.59,
      "text": "from Lillian Wang from this particular GitHub,"
    },
    {
      "start": 1731.59,
      "end": 1735.31,
      "text": "just to showcase where we're getting our notes from."
    },
    {
      "start": 1735.31,
      "end": 1740.62,
      "text": "This is a blog that's going to have pretty much instructions"
    },
    {
      "start": 1740.62,
      "end": 1744.54,
      "text": "on how to create autonomous agents or LLM-powered autonomous"
    },
    {
      "start": 1744.54,
      "end": 1746.06,
      "text": "agents."
    },
    {
      "start": 1746.06,
      "end": 1748.1,
      "text": "We'll talk, feel free to read through this,"
    },
    {
      "start": 1748.1,
      "end": 1749.94,
      "text": "but we're not actually going to be spending too much time"
    },
    {
      "start": 1749.94,
      "end": 1750.42,
      "text": "on the blog."
    },
    {
      "start": 1750.42,
      "end": 1753.74,
      "text": "We're actually just going to have our LLM take all of this"
    },
    {
      "start": 1753.74,
      "end": 1759.54,
      "text": "and summarize it for us and create it in a framework"
    },
    {
      "start": 1759.54,
      "end": 1765.14,
      "text": "that I can then build an agent or a mini LLM that's"
    },
    {
      "start": 1765.14,
      "end": 1768.18,
      "text": "going to take the data that it learned from looking"
    },
    {
      "start": 1768.18,
      "end": 1772.82,
      "text": "through this document to return its own answers for us."
    },
    {
      "start": 1772.82,
      "end": 1776.3,
      "text": "So there's a lot of text here, again, not really worth our"
    },
    {
      "start": 1776.3,
      "end": 1781.9,
      "text": "time to read through it, but we can actually use some"
    },
    {
      "start": 1781.9,
      "end": 1786.46,
      "text": "of the LLM-chain properties, in this case, GBT3.5,"
    },
    {
      "start": 1786.46,
      "end": 1792.66,
      "text": "to access that website, load it, essentially re-graded into"
    },
    {
      "start": 1792.66,
      "end": 1796.3,
      "text": "a SUP object from beautiful SUP, which is going to take"
    },
    {
      "start": 1796.3,
      "end": 1798.34,
      "text": "some of the contents of none of the images,"
    },
    {
      "start": 1798.34,
      "end": 1801.22,
      "text": "and I want to load it into a document."
    },
    {
      "start": 1801.22,
      "end": 1804.58,
      "text": "I'm going to take all of the text from that document,"
    },
    {
      "start": 1804.58,
      "end": 1807.22,
      "text": "and I want to split it into individual documents that's"
    },
    {
      "start": 1807.22,
      "end": 1809.18,
      "text": "essentially going to be what I'm going to be embedding"
    },
    {
      "start": 1809.26,
      "end": 1813.02,
      "text": "into the, essentially, I'm going to be embedding all of that text"
    },
    {
      "start": 1813.02,
      "end": 1815.06,
      "text": "into that interpretable format."
    },
    {
      "start": 1815.06,
      "end": 1817.66,
      "text": "So this is doing it for me."
    },
    {
      "start": 1817.66,
      "end": 1819.38,
      "text": "The code is pretty straightforward."
    },
    {
      "start": 1819.38,
      "end": 1823.06,
      "text": "And then I'm going to be taking from the Community Hub,"
    },
    {
      "start": 1823.06,
      "end": 1826.74,
      "text": "essentially the same network where you can look at different"
    },
    {
      "start": 1826.74,
      "end": 1829.14,
      "text": "models, and I want to essentially be able to create a"
    },
    {
      "start": 1829.14,
      "end": 1836.02,
      "text": "prompt based off of that document."
    },
    {
      "start": 1836.02,
      "end": 1838.1,
      "text": "This last function is essentially going to take all of that"
    },
    {
      "start": 1838.1,
      "end": 1840.78,
      "text": "content formatted into a document."
    },
    {
      "start": 1840.78,
      "end": 1844.58,
      "text": "And I'm like, this might be some syntax that you may not"
    },
    {
      "start": 1844.58,
      "end": 1847.38,
      "text": "have seen, even if you've been working with Python for a while."
    },
    {
      "start": 1847.38,
      "end": 1851.86,
      "text": "This is usually the like, and signifier, if you're trying"
    },
    {
      "start": 1851.86,
      "end": 1856.34,
      "text": "to compare two values, in LLM-chain, what this tool does is"
    },
    {
      "start": 1856.34,
      "end": 1859.7,
      "text": "essentially creates that step-by-step process in the chain."
    },
    {
      "start": 1859.7,
      "end": 1862.78,
      "text": "And I'll showcase another example in just a moment so that"
    },
    {
      "start": 1862.78,
      "end": 1864.54,
      "text": "we can kind of take it slow."
    },
    {
      "start": 1864.54,
      "end": 1867.46,
      "text": "But what our tool is going to be doing is essentially going to"
    },
    {
      "start": 1867.46,
      "end": 1870.74,
      "text": "be taking the retriever within the context that we created"
    },
    {
      "start": 1870.74,
      "end": 1874.26,
      "text": "above, along with the documents as we formatted."
    },
    {
      "start": 1874.26,
      "end": 1876.86,
      "text": "And that the question is going to be processed through a"
    },
    {
      "start": 1876.86,
      "end": 1878.78,
      "text": "multiple pass through, essentially going to be"
    },
    {
      "start": 1878.78,
      "end": 1882.9,
      "text": "interpreting all of the content on all the embedded contents."
    },
    {
      "start": 1882.9,
      "end": 1886.86,
      "text": "Finally, like after we created the prompt object, this is"
    },
    {
      "start": 1886.86,
      "end": 1892.06,
      "text": "as it was pulled from one of the like, the prompt that"
    },
    {
      "start": 1892.06,
      "end": 1896.05,
      "text": "we're creating early on, I can actually showcase what"
    },
    {
      "start": 1896.05,
      "end": 1900.94,
      "text": "that looks like for us."
    },
    {
      "start": 1900.94,
      "end": 1909.15,
      "text": "And that prompt, as it was built out, is simply a chat"
    },
    {
      "start": 1909.15,
      "end": 1913.17,
      "text": "prompt template, essentially the prompt that we, like, if"
    },
    {
      "start": 1913.17,
      "end": 1915.57,
      "text": "you remember from last last, when we talked about like, hey,"
    },
    {
      "start": 1915.57,
      "end": 1917.21,
      "text": "I want you to structure my answer."
    },
    {
      "start": 1917.21,
      "end": 1920.21,
      "text": "I want your answers to sort of look like this."
    },
    {
      "start": 1920.21,
      "end": 1924.57,
      "text": "So the prompt itself is going to look like, let me just scroll"
    },
    {
      "start": 1924.57,
      "end": 1924.97,
      "text": "through this."
    },
    {
      "start": 1924.97,
      "end": 1927.29,
      "text": "You're an assistant for question answering tasks."
    },
    {
      "start": 1927.29,
      "end": 1930.45,
      "text": "Use the following pieces of retrieved context to answer"
    },
    {
      "start": 1930.45,
      "end": 1931.05,
      "text": "the question."
    },
    {
      "start": 1931.05,
      "end": 1933.37,
      "text": "If you don't know the answer, just say you don't know, but"
    },
    {
      "start": 1933.37,
      "end": 1935.85,
      "text": "three cents and maximum keep the answer concise."
    },
    {
      "start": 1935.85,
      "end": 1939.0,
      "text": "This is something that a different user has built."
    },
    {
      "start": 1939.0,
      "end": 1943.23,
      "text": "And again, this is all essentially going to be what it"
    },
    {
      "start": 1943.23,
      "end": 1946.03,
      "text": "returns for the document that we created or that we move"
    },
    {
      "start": 1946.03,
      "end": 1948.63,
      "text": "from online."
    },
    {
      "start": 1948.63,
      "end": 1952.87,
      "text": "So when we created that prompt, we're"
    },
    {
      "start": 1952.87,
      "end": 1955.99,
      "text": "accessing, we're telling the prompt to, we're"
    },
    {
      "start": 1956.07,
      "end": 1961.35,
      "text": "telling our LLM to build answers using that prompt."
    },
    {
      "start": 1961.35,
      "end": 1965.11,
      "text": "And finally, the last step is going to be to, like, to"
    },
    {
      "start": 1965.11,
      "end": 1971.47,
      "text": "output the answer or the answer that the LLM invoked as"
    },
    {
      "start": 1971.47,
      "end": 1973.75,
      "text": "essentially a string text."
    },
    {
      "start": 1973.75,
      "end": 1977.51,
      "text": "So this case, what I'm trying to do is take all of the"
    },
    {
      "start": 1977.51,
      "end": 1984.22,
      "text": "information from this document and tell me what is task"
    },
    {
      "start": 1984.22,
      "end": 1988.4,
      "text": "to composition for the record."
    },
    {
      "start": 1988.4,
      "end": 1991.52,
      "text": "This is something that I technically advise with folks"
    },
    {
      "start": 1991.52,
      "end": 1995.84,
      "text": "when I've been working for them like longer class sessions."
    },
    {
      "start": 1995.84,
      "end": 1997.88,
      "text": "I grew up in Puerto Rico, English is actually my second"
    },
    {
      "start": 1997.88,
      "end": 1998.48,
      "text": "language."
    },
    {
      "start": 1998.48,
      "end": 2001.68,
      "text": "So there's a B words that occasionally like, I don't"
    },
    {
      "start": 2001.68,
      "end": 2002.96,
      "text": "pronounce correctly."
    },
    {
      "start": 2002.96,
      "end": 2003.84,
      "text": "You'll free to call me out."
    },
    {
      "start": 2003.84,
      "end": 2007.0,
      "text": "It's always a fun time."
    },
    {
      "start": 2007.0,
      "end": 2008.56,
      "text": "But there are some words that I'm going to look at"
    },
    {
      "start": 2008.56,
      "end": 2010.84,
      "text": "and I'm like, to composition, the composition never"
    },
    {
      "start": 2010.84,
      "end": 2012.28,
      "text": "quite sure how it's pronounced."
    },
    {
      "start": 2012.28,
      "end": 2013.96,
      "text": "But yeah, so the answer we get from this is tasked"
    },
    {
      "start": 2013.96,
      "end": 2016.0,
      "text": "composition together like, OK, we're familiar with that"
    },
    {
      "start": 2016.0,
      "end": 2016.32,
      "text": "part."
    },
    {
      "start": 2016.32,
      "end": 2017.92,
      "text": "We understand what happens."
    },
    {
      "start": 2017.92,
      "end": 2021.28,
      "text": "We can expect that the answer from that is going to be"
    },
    {
      "start": 2021.28,
      "end": 2026.7,
      "text": "built from the, is going to be built in their summer from"
    },
    {
      "start": 2026.7,
      "end": 2028.66,
      "text": "from the document that it returned."
    },
    {
      "start": 2028.66,
      "end": 2030.5,
      "text": "That's not the point of what we're trying to do."
    },
    {
      "start": 2030.5,
      "end": 2035.02,
      "text": "We're trying to see how this worked within the framework"
    },
    {
      "start": 2035.02,
      "end": 2037.62,
      "text": "of our LLAMG Smith environment."
    },
    {
      "start": 2037.62,
      "end": 2040.93,
      "text": "So that ran properly."
    },
    {
      "start": 2040.93,
      "end": 2048.42,
      "text": "We should have built, let's see where that put."
    },
    {
      "start": 2048.42,
      "end": 2049.58,
      "text": "Yep, there we go."
    },
    {
      "start": 2049.58,
      "end": 2052.66,
      "text": "Inside our default, inside our default process, you'll see"
    },
    {
      "start": 2052.66,
      "end": 2056.51,
      "text": "this runable sequence object."
    },
    {
      "start": 2056.51,
      "end": 2059.58,
      "text": "And here, we do a dropdown."
    },
    {
      "start": 2059.58,
      "end": 2061.66,
      "text": "We're actually beginning to see all of the different"
    },
    {
      "start": 2061.66,
      "end": 2065.18,
      "text": "tasks that we just created, including that final answer,"
    },
    {
      "start": 2065.18,
      "end": 2069.22,
      "text": "like that final answer, what is tasked composition."
    },
    {
      "start": 2069.22,
      "end": 2070.98,
      "text": "And we can start to see that there are all of the"
    },
    {
      "start": 2070.98,
      "end": 2074.64,
      "text": "different steps are listed for us, including but not"
    },
    {
      "start": 2074.64,
      "end": 2079.8,
      "text": "limited the input that the model essentially decided to"
    },
    {
      "start": 2079.8,
      "end": 2083.2,
      "text": "incorporate what is tasked composition and the context of"
    },
    {
      "start": 2083.2,
      "end": 2087.27,
      "text": "what it built, the, like, what context it actually used to"
    },
    {
      "start": 2087.27,
      "end": 2089.2,
      "text": "create the answer."
    },
    {
      "start": 2089.2,
      "end": 2091.84,
      "text": "The prompt template, remember what we said earlier, is"
    },
    {
      "start": 2091.84,
      "end": 2099.7,
      "text": "essentially, how to create, where is that?"
    },
    {
      "start": 2099.7,
      "end": 2102.98,
      "text": "Yeah, how to create what the, like, what, like, what that"
    },
    {
      "start": 2102.98,
      "end": 2104.74,
      "text": "content would look like."
    },
    {
      "start": 2104.74,
      "end": 2107.62,
      "text": "And the chat, like, the chat, the, the, the, the year we got."
    },
    {
      "start": 2107.62,
      "end": 2108.86,
      "text": "This is what it was looking for."
    },
    {
      "start": 2108.86,
      "end": 2111.46,
      "text": "So this is what it would look like if we were answering this"
    },
    {
      "start": 2111.46,
      "end": 2113.82,
      "text": "within a chat, open AI framework."
    },
    {
      "start": 2113.82,
      "end": 2115.62,
      "text": "This was us answering the question."
    },
    {
      "start": 2115.62,
      "end": 2120.86,
      "text": "There is the prompt that we hold from the community light"
    },
    {
      "start": 2120.86,
      "end": 2122.9,
      "text": "from the length and community hub."
    },
    {
      "start": 2122.9,
      "end": 2125.66,
      "text": "And it essentially was able to create and output that"
    },
    {
      "start": 2125.66,
      "end": 2128.7,
      "text": "within that specific, within that specific prompt"
    },
    {
      "start": 2128.7,
      "end": 2129.78,
      "text": "structure."
    },
    {
      "start": 2129.78,
      "end": 2133.74,
      "text": "At the string out parser, like we discussed earlier,"
    },
    {
      "start": 2133.74,
      "end": 2136.1,
      "text": "was essentially being able to take all of that information and"
    },
    {
      "start": 2136.1,
      "end": 2140.3,
      "text": "remove all of the additional data that metadata and call"
    },
    {
      "start": 2140.3,
      "end": 2142.7,
      "text": "that information as a string."
    },
    {
      "start": 2142.7,
      "end": 2145.34,
      "text": "So what I like about this is that it's already beginning to"
    },
    {
      "start": 2145.34,
      "end": 2147.82,
      "text": "tell you and create, give you a lot of additional information"
    },
    {
      "start": 2147.82,
      "end": 2149.34,
      "text": "about the tool itself."
    },
    {
      "start": 2149.34,
      "end": 2154.02,
      "text": "We can look at how long it took 1.54 seconds to run from"
    },
    {
      "start": 2154.02,
      "end": 2155.26,
      "text": "beginning to end."
    },
    {
      "start": 2155.26,
      "end": 2159.86,
      "text": "We can look at other elements, including how much did"
    },
    {
      "start": 2159.86,
      "end": 2165.54,
      "text": "each particular step where we had to invoke the open AI"
    },
    {
      "start": 2165.54,
      "end": 2168.58,
      "text": "processes or the, like the parts that cost money, we can"
    },
    {
      "start": 2168.58,
      "end": 2171.14,
      "text": "actually begin to incorporate that."
    },
    {
      "start": 2171.14,
      "end": 2174.42,
      "text": "So this guy's not, you know, negligibly expensive."
    },
    {
      "start": 2174.42,
      "end": 2176.06,
      "text": "But of course, it's going to be much more expensive than"
    },
    {
      "start": 2176.06,
      "end": 2179.62,
      "text": "we're incorporating additional information."
    },
    {
      "start": 2179.62,
      "end": 2184.38,
      "text": "The documents that we pulled again were pulled from the,"
    },
    {
      "start": 2184.38,
      "end": 2186.02,
      "text": "from the Lillian Wing website."
    },
    {
      "start": 2186.02,
      "end": 2190.98,
      "text": "And that can be determined based off of the,"
    },
    {
      "start": 2190.98,
      "end": 2192.46,
      "text": "based off of this tool."
    },
    {
      "start": 2192.46,
      "end": 2196.02,
      "text": "So we can see that as part of our chat prompt template."
    },
    {
      "start": 2196.02,
      "end": 2199.75,
      "text": "We can see that from where we got the information itself."
    },
    {
      "start": 2199.75,
      "end": 2202.39,
      "text": "So it's essentially seeing that it is built to follow the"
    },
    {
      "start": 2202.39,
      "end": 2206.74,
      "text": "same steps that we built in our local environment."
    },
    {
      "start": 2206.74,
      "end": 2210.3,
      "text": "And that context essentially is created here in our code"
    },
    {
      "start": 2210.3,
      "end": 2214.18,
      "text": "from the very beginning."
    },
    {
      "start": 2214.18,
      "end": 2217.86,
      "text": "So these components are essentially intended for us to then"
    },
    {
      "start": 2217.86,
      "end": 2220.26,
      "text": "make certain choices as to what we want to do with it."
    },
    {
      "start": 2220.26,
      "end": 2222.26,
      "text": "Like, is there a specific test?"
    },
    {
      "start": 2222.26,
      "end": 2224.46,
      "text": "Is there a specific output that we're interested in working"
    },
    {
      "start": 2224.46,
      "end": 2228.66,
      "text": "with a little bit more, a little bit more fully?"
    },
    {
      "start": 2228.66,
      "end": 2231.7,
      "text": "Perhaps that's going to be the next thing we're going to be"
    },
    {
      "start": 2231.7,
      "end": 2233.82,
      "text": "talking about in just a moment."
    },
    {
      "start": 2233.82,
      "end": 2237.78,
      "text": "So if I'm the last question is, this is a question I'm going"
    },
    {
      "start": 2237.78,
      "end": 2241.5,
      "text": "to pose for you, given your ability to kind of explore this"
    },
    {
      "start": 2241.5,
      "end": 2245.06,
      "text": "or your, like, from what we're seeing here,"
    },
    {
      "start": 2245.06,
      "end": 2247.54,
      "text": "do you get the sense that you're able to, can you determine"
    },
    {
      "start": 2247.54,
      "end": 2253.16,
      "text": "what the response should I put this question?"
    },
    {
      "start": 2253.16,
      "end": 2257.44,
      "text": "How do I find this question?"
    },
    {
      "start": 2257.44,
      "end": 2259.0,
      "text": "What are some of the methods?"
    },
    {
      "start": 2259.0,
      "end": 2261.14,
      "text": "What are some of the methods?"
    },
    {
      "start": 2261.14,
      "end": 2263.7,
      "text": "What comes to mind as far as usefulness for something"
    },
    {
      "start": 2263.7,
      "end": 2266.34,
      "text": "like this, particularly if you're working"
    },
    {
      "start": 2266.34,
      "end": 2280.13,
      "text": "within a team dynamic?"
    },
    {
      "start": 2280.13,
      "end": 2294.62,
      "text": "This is a leading question to some extent."
    },
    {
      "start": 2294.62,
      "end": 2296.26,
      "text": "I don't have a good sense of this tool yet."
    },
    {
      "start": 2296.26,
      "end": 2299.94,
      "text": "But if I had to make an assumption, if different parts of the"
    },
    {
      "start": 2299.94,
      "end": 2303.94,
      "text": "team are working on different parts of the overall process,"
    },
    {
      "start": 2303.94,
      "end": 2307.06,
      "text": "this gives you that granularity to see what exactly each"
    },
    {
      "start": 2307.06,
      "end": 2309.74,
      "text": "piece is doing, how it's configured, how it's performing,"
    },
    {
      "start": 2309.74,
      "end": 2311.7,
      "text": "how much it costs, et cetera, et cetera."
    },
    {
      "start": 2311.7,
      "end": 2314.74,
      "text": "So I guess it gives you a better cross functional visibility."
    },
    {
      "start": 2314.74,
      "end": 2316.66,
      "text": "But again, that's for that a lot of context."
    },
    {
      "start": 2316.66,
      "end": 2317.5,
      "text": "For sure."
    },
    {
      "start": 2317.5,
      "end": 2319.74,
      "text": "And what happens if, you know, for another example,"
    },
    {
      "start": 2319.74,
      "end": 2321.9,
      "text": "perhaps one day if you're not a fan of like,"
    },
    {
      "start": 2321.9,
      "end": 2324.42,
      "text": "what if you have someone who's suggesting that open AI maybe"
    },
    {
      "start": 2324.42,
      "end": 2326.54,
      "text": "that that enthropic may be a better model"
    },
    {
      "start": 2326.54,
      "end": 2329.39,
      "text": "to use in a specific scenario?"
    },
    {
      "start": 2329.39,
      "end": 2330.31,
      "text": "What is this useful for?"
    },
    {
      "start": 2330.31,
      "end": 2332.75,
      "text": "Well, like you can actually come up with like a particular,"
    },
    {
      "start": 2332.75,
      "end": 2335.99,
      "text": "you can create different projects that actually compare,"
    },
    {
      "start": 2335.99,
      "end": 2338.87,
      "text": "like that you can actually compare the different models"
    },
    {
      "start": 2338.87,
      "end": 2341.43,
      "text": "at the different steps the model is taking."
    },
    {
      "start": 2341.43,
      "end": 2342.83,
      "text": "So you can actually monitor speed."
    },
    {
      "start": 2342.83,
      "end": 2344.59,
      "text": "You can actually monitor price."
    },
    {
      "start": 2344.59,
      "end": 2348.15,
      "text": "You can actually monitor a lot of like back granularity"
    },
    {
      "start": 2348.15,
      "end": 2350.55,
      "text": "that you're talking about Ryan can essentially be incorporated"
    },
    {
      "start": 2350.55,
      "end": 2353.35,
      "text": "with tools like this to then compare what's the best tool"
    },
    {
      "start": 2353.35,
      "end": 2354.92,
      "text": "for the job?"
    },
    {
      "start": 2354.92,
      "end": 2358.46,
      "text": "Any other comments or thoughts to face?"
    },
    {
      "start": 2358.46,
      "end": 2360.54,
      "text": "I'm guessing that also really helps you"
    },
    {
      "start": 2360.54,
      "end": 2362.38,
      "text": "understand if different pieces are built"
    },
    {
      "start": 2362.38,
      "end": 2364.62,
      "text": "by different team members, the place and where they touch"
    },
    {
      "start": 2364.62,
      "end": 2366.94,
      "text": "and how they may be interacting incorrectly there?"
    },
    {
      "start": 2366.94,
      "end": 2368.58,
      "text": "For sure."
    },
    {
      "start": 2368.58,
      "end": 2370.98,
      "text": "And yeah, with essentially being a part of a team"
    },
    {
      "start": 2370.98,
      "end": 2372.54,
      "text": "just kind of sharing that language,"
    },
    {
      "start": 2372.54,
      "end": 2375.02,
      "text": "like that language, like that language key,"
    },
    {
      "start": 2375.02,
      "end": 2377.7,
      "text": "you can essentially begin to create a specific set,"
    },
    {
      "start": 2377.7,
      "end": 2380.86,
      "text": "like you can essentially begin to really dive"
    },
    {
      "start": 2380.86,
      "end": 2383.7,
      "text": "into the nitty gritty of like what your model is doing."
    },
    {
      "start": 2383.7,
      "end": 2385.02,
      "text": "And this is essentially how you begin"
    },
    {
      "start": 2385.02,
      "end": 2386.74,
      "text": "to build a successful model."
    },
    {
      "start": 2386.74,
      "end": 2388.7,
      "text": "And this is essentially step one."
    },
    {
      "start": 2388.7,
      "end": 2389.74,
      "text": "Of course, we're going to be diving,"
    },
    {
      "start": 2389.74,
      "end": 2391.1,
      "text": "we're going to be spending a lot of time here,"
    },
    {
      "start": 2391.18,
      "end": 2394.46,
      "text": "but I just want you to kind of take this class,"
    },
    {
      "start": 2394.46,
      "end": 2397.98,
      "text": "start kind of flicking around."
    },
    {
      "start": 2397.98,
      "end": 2399.46,
      "text": "There's not a whole lot to click around."
    },
    {
      "start": 2399.46,
      "end": 2401.94,
      "text": "The next bit that we're going to be talking about right now"
    },
    {
      "start": 2401.94,
      "end": 2405.54,
      "text": "is going to be a little bit more in depth."
    },
    {
      "start": 2405.54,
      "end": 2407.1,
      "text": "But yeah, that's about it."
    },
    {
      "start": 2407.1,
      "end": 2409.02,
      "text": "And again, next week we'll talk a little bit more"
    },
    {
      "start": 2409.02,
      "end": 2411.78,
      "text": "about Rags in detail so that we can kind of talk"
    },
    {
      "start": 2411.78,
      "end": 2415.18,
      "text": "a little bit about how those documents get embedded,"
    },
    {
      "start": 2415.18,
      "end": 2417.5,
      "text": "how those documents work behind the scenes."
    },
    {
      "start": 2417.5,
      "end": 2420.9,
      "text": "So, that doesn't quite yet."
    },
    {
      "start": 2420.9,
      "end": 2424.18,
      "text": "Let's talk a little bit, not that."
    },
    {
      "start": 2424.18,
      "end": 2427.06,
      "text": "Let's talk about one more thing here."
    },
    {
      "start": 2427.06,
      "end": 2430.94,
      "text": "As in order for you to do that your specific homework,"
    },
    {
      "start": 2430.94,
      "end": 2433.34,
      "text": "there's one of the elements that I started the class"
    },
    {
      "start": 2433.34,
      "end": 2435.82,
      "text": "talking about, and one of the comments"
    },
    {
      "start": 2435.82,
      "end": 2439.42,
      "text": "that really usually comes up with this sort of conversation."
    },
    {
      "start": 2439.42,
      "end": 2444.5,
      "text": "It's like, hey, how do I know if my LLM is working?"
    },
    {
      "start": 2444.5,
      "end": 2449.74,
      "text": "How do I know for a fact that my output"
    },
    {
      "start": 2449.74,
      "end": 2451.86,
      "text": "is providing the right answer for my customers,"
    },
    {
      "start": 2451.86,
      "end": 2454.38,
      "text": "for my clients, for my team?"
    },
    {
      "start": 2454.38,
      "end": 2461.43,
      "text": "Really, how do you evaluate those specific responses?"
    },
    {
      "start": 2461.43,
      "end": 2463.51,
      "text": "And so, there's a couple of different answers to that."
    },
    {
      "start": 2463.51,
      "end": 2466.07,
      "text": "One, you have both automated methods"
    },
    {
      "start": 2466.07,
      "end": 2471.52,
      "text": "and where you can essentially determine whether the model"
    },
    {
      "start": 2471.52,
      "end": 2475.04,
      "text": "seems to be correctly identifying a particular value."
    },
    {
      "start": 2475.04,
      "end": 2477.04,
      "text": "If it's correctly identifying a specific label,"
    },
    {
      "start": 2477.04,
      "end": 2479.68,
      "text": "that's specifically if you're working with labeled data set."
    },
    {
      "start": 2479.72,
      "end": 2484.0,
      "text": "But what if your data is necessarily"
    },
    {
      "start": 2484.0,
      "end": 2488.68,
      "text": "like a value that can be easily labeled?"
    },
    {
      "start": 2488.68,
      "end": 2492.32,
      "text": "What if it's something like, for example, a terrible joke"
    },
    {
      "start": 2492.32,
      "end": 2494.72,
      "text": "or what if it's something like a specific assessment"
    },
    {
      "start": 2494.72,
      "end": 2498.72,
      "text": "or a particular think of it as maybe a creative opinion"
    },
    {
      "start": 2498.72,
      "end": 2501.98,
      "text": "or even like, I don't know, a lot of the work I do,"
    },
    {
      "start": 2501.98,
      "end": 2505.1,
      "text": "I've been doing recently has been like trying to create"
    },
    {
      "start": 2505.1,
      "end": 2510.02,
      "text": "tools that work best with posting on social media in a way"
    },
    {
      "start": 2510.06,
      "end": 2514.54,
      "text": "that includes variety, creativity and different values."
    },
    {
      "start": 2514.54,
      "end": 2518.5,
      "text": "So, how do you evaluate what makes a good social media post?"
    },
    {
      "start": 2518.5,
      "end": 2520.7,
      "text": "For example, the answer to that's often"
    },
    {
      "start": 2520.7,
      "end": 2522.7,
      "text": "similar complicated, there's some few metrics"
    },
    {
      "start": 2522.7,
      "end": 2525.14,
      "text": "you can evaluate from there, but beyond that,"
    },
    {
      "start": 2525.14,
      "end": 2526.82,
      "text": "let's kind of assess this within the context"
    },
    {
      "start": 2526.82,
      "end": 2531.34,
      "text": "of what makes a good dad joke for our purposes right now."
    },
    {
      "start": 2531.34,
      "end": 2536.14,
      "text": "Well, it's whether your kids like you enough"
    },
    {
      "start": 2536.14,
      "end": 2538.02,
      "text": "to laugh at your jokes, I don't know."
    },
    {
      "start": 2538.02,
      "end": 2540.54,
      "text": "What's the metric we want to use there?"
    },
    {
      "start": 2540.54,
      "end": 2542.54,
      "text": "Well, right now, the answer or the short answer"
    },
    {
      "start": 2542.54,
      "end": 2544.82,
      "text": "that I'm sort of like jumping around to is that"
    },
    {
      "start": 2544.82,
      "end": 2547.54,
      "text": "we can actually incorporate our own opinion"
    },
    {
      "start": 2547.54,
      "end": 2550.82,
      "text": "or our own evaluation with lagsmith."
    },
    {
      "start": 2550.82,
      "end": 2553.18,
      "text": "And if we want to do that manual evaluation,"
    },
    {
      "start": 2553.18,
      "end": 2555.78,
      "text": "lagsmith allows us the chance to do that."
    },
    {
      "start": 2555.78,
      "end": 2559.06,
      "text": "It also allows us the chance to create some automated processes"
    },
    {
      "start": 2559.06,
      "end": 2561.78,
      "text": "to evaluate those specific tools."
    },
    {
      "start": 2561.78,
      "end": 2565.14,
      "text": "And we're talking more about that automated evaluation"
    },
    {
      "start": 2565.14,
      "end": 2566.3,
      "text": "a little bit down the line right now."
    },
    {
      "start": 2566.3,
      "end": 2569.14,
      "text": "I just want to showcase, how do you incorporate"
    },
    {
      "start": 2569.14,
      "end": 2573.82,
      "text": "a specific output from an LLM into data value"
    },
    {
      "start": 2573.82,
      "end": 2575.5,
      "text": "or a data set that you can store?"
    },
    {
      "start": 2575.5,
      "end": 2578.58,
      "text": "And then you can create that evaluation"
    },
    {
      "start": 2578.58,
      "end": 2580.3,
      "text": "within lagsmiths framework."
    },
    {
      "start": 2580.3,
      "end": 2585.3,
      "text": "So I'm going to go over to the lagsmith.jokes.py tool,"
    },
    {
      "start": 2585.58,
      "end": 2587.98,
      "text": "going back to the chat-open AI tool"
    },
    {
      "start": 2587.98,
      "end": 2590.34,
      "text": "from lag chain itself."
    },
    {
      "start": 2590.34,
      "end": 2593.58,
      "text": "This is these other packages should be fairly familiar."
    },
    {
      "start": 2593.58,
      "end": 2595.22,
      "text": "I don't actually need this,"
    },
    {
      "start": 2595.22,
      "end": 2597.26,
      "text": "but if you want to incorporate your code"
    },
    {
      "start": 2597.26,
      "end": 2601.62,
      "text": "into your environment, that's absolutely fine."
    },
    {
      "start": 2601.62,
      "end": 2605.46,
      "text": "But all I'm doing here is asking open AI"
    },
    {
      "start": 2605.46,
      "end": 2608.18,
      "text": "to create five dad jokes."
    },
    {
      "start": 2608.18,
      "end": 2611.46,
      "text": "And I want those dad jokes to be in story format."
    },
    {
      "start": 2611.46,
      "end": 2612.88,
      "text": "Excuse me."
    },
    {
      "start": 2612.88,
      "end": 2616.56,
      "text": "And I'm just going to have that run behind the scenes"
    },
    {
      "start": 2616.56,
      "end": 2621.5,
      "text": "in class examples that is lagsmith dad joke."
    },
    {
      "start": 2621.5,
      "end": 2624.94,
      "text": "So we run that on its own."
    },
    {
      "start": 2624.94,
      "end": 2628.0,
      "text": "And that'll take a second or two."
    },
    {
      "start": 2628.0,
      "end": 2631.62,
      "text": "It's running in the lagsmith environment."
    },
    {
      "start": 2631.62,
      "end": 2635.19,
      "text": "I'm going to close that up here and close this up."
    },
    {
      "start": 2635.19,
      "end": 2637.31,
      "text": "Not going to need that."
    },
    {
      "start": 2637.31,
      "end": 2639.23,
      "text": "That should be done running."
    },
    {
      "start": 2639.23,
      "end": 2647.94,
      "text": "All right, so I took about 10 seconds."
    },
    {
      "start": 2647.94,
      "end": 2649.98,
      "text": "Took about 589 tokens."
    },
    {
      "start": 2649.98,
      "end": 2653.5,
      "text": "Each joke took about 2.27 seconds to run."
    },
    {
      "start": 2653.5,
      "end": 2656.5,
      "text": "And we can actually start to evaluate the jokes"
    },
    {
      "start": 2656.5,
      "end": 2657.34,
      "text": "directly from here."
    },
    {
      "start": 2657.34,
      "end": 2659.14,
      "text": "If you click on each or particular object,"
    },
    {
      "start": 2659.14,
      "end": 2660.3,
      "text": "we have one joke."
    },
    {
      "start": 2660.3,
      "end": 2661.3,
      "text": "Jokes should be in story format."
    },
    {
      "start": 2661.3,
      "end": 2663.5,
      "text": "That's about a time of dad to send tickets into the zoo, blah, blah, blah."
    },
    {
      "start": 2663.5,
      "end": 2665.58,
      "text": "OK, it's probably a terrible joke."
    },
    {
      "start": 2665.58,
      "end": 2666.66,
      "text": "Let's look at this next joke."
    },
    {
      "start": 2666.66,
      "end": 2667.9,
      "text": "It's a little bit long when it's about 10."
    },
    {
      "start": 2667.9,
      "end": 2670.9,
      "text": "So there's like three paragraphs out about the not actually"
    },
    {
      "start": 2670.9,
      "end": 2671.82,
      "text": "reading through those jokes."
    },
    {
      "start": 2671.82,
      "end": 2672.82,
      "text": "They're probably terrible."
    },
    {
      "start": 2672.82,
      "end": 2675.99,
      "text": "But this one's a little bit longer."
    },
    {
      "start": 2675.99,
      "end": 2678.15,
      "text": "OK, this was a waste of time."
    },
    {
      "start": 2678.15,
      "end": 2678.87,
      "text": "World their eyes."
    },
    {
      "start": 2678.87,
      "end": 2682.62,
      "text": "OK, and this one's a lot shorter."
    },
    {
      "start": 2682.62,
      "end": 2686.5,
      "text": "So I'm going to ask you to kind of help me out a little bit"
    },
    {
      "start": 2686.5,
      "end": 2688.54,
      "text": "for this next step, because I'm going"
    },
    {
      "start": 2688.54,
      "end": 2691.42,
      "text": "to go ahead and try to evaluate these jokes by commending."
    },
    {
      "start": 2691.42,
      "end": 2693.38,
      "text": "We're not going to do any specific metric."
    },
    {
      "start": 2693.38,
      "end": 2698.1,
      "text": "But the way you can begin to create and create that manual evaluation,"
    },
    {
      "start": 2698.1,
      "end": 2700.39,
      "text": "there's three tools up here."
    },
    {
      "start": 2700.39,
      "end": 2702.59,
      "text": "There's the annotate tool."
    },
    {
      "start": 2702.59,
      "end": 2705.23,
      "text": "Essentially means that you can make some create."
    },
    {
      "start": 2705.23,
      "end": 2708.31,
      "text": "You can essentially make some adjustments to the input"
    },
    {
      "start": 2708.31,
      "end": 2711.67,
      "text": "and the output of the LLM responses themselves."
    },
    {
      "start": 2711.67,
      "end": 2715.47,
      "text": "We have the ability to incorporate these objects into a data set."
    },
    {
      "start": 2715.47,
      "end": 2717.55,
      "text": "We'll get to that in just a moment."
    },
    {
      "start": 2717.55,
      "end": 2719.83,
      "text": "But I want to be able to add each one of these jokes"
    },
    {
      "start": 2719.83,
      "end": 2721.91,
      "text": "to an annotation queue."
    },
    {
      "start": 2721.91,
      "end": 2724.61,
      "text": "So I can just show you guys what we're going to do here."
    },
    {
      "start": 2724.61,
      "end": 2727.13,
      "text": "So I'm going to go ahead and select that."
    },
    {
      "start": 2727.13,
      "end": 2729.01,
      "text": "I haven't created any particular queue yet."
    },
    {
      "start": 2729.01,
      "end": 2732.29,
      "text": "So let's go ahead and just to show you what that looked like."
    },
    {
      "start": 2732.29,
      "end": 2734.17,
      "text": "I'm going to click on annotation queue."
    },
    {
      "start": 2734.17,
      "end": 2737.25,
      "text": "I'm going to click on new to create a new queue."
    },
    {
      "start": 2737.25,
      "end": 2745.8,
      "text": "And I'm going to name this, see if it's not letting me detect."
    },
    {
      "start": 2745.8,
      "end": 2746.84,
      "text": "Here we go."
    },
    {
      "start": 2746.84,
      "end": 2748.36,
      "text": "OK, here we go."
    },
    {
      "start": 2748.36,
      "end": 2753.55,
      "text": "Yeah, perfect."
    },
    {
      "start": 2753.83,
      "end": 2759.75,
      "text": "I'm going to name it here again, add annotation queue, new."
    },
    {
      "start": 2759.75,
      "end": 2765.52,
      "text": "A list, a list of terrible jokes."
    },
    {
      "start": 2765.52,
      "end": 2766.56,
      "text": "And I need a name."
    },
    {
      "start": 2766.56,
      "end": 2773.03,
      "text": "So let's call this an annotation joke judgment."
    },
    {
      "start": 2773.03,
      "end": 2776.3,
      "text": "I don't know, doing a little spicy there."
    },
    {
      "start": 2776.3,
      "end": 2778.38,
      "text": "That's all we need."
    },
    {
      "start": 2778.38,
      "end": 2779.9,
      "text": "I can also create a data set that I'm"
    },
    {
      "start": 2779.9,
      "end": 2783.06,
      "text": "going to be adding these tools if I feel like the joke actually"
    },
    {
      "start": 2783.06,
      "end": 2789.18,
      "text": "fits the standard of what I want to fill in my particular"
    },
    {
      "start": 2789.18,
      "end": 2792.06,
      "text": "to fill in to create essentially a model that"
    },
    {
      "start": 2792.06,
      "end": 2795.62,
      "text": "makes the best dad jokes that we as a group"
    },
    {
      "start": 2795.62,
      "end": 2797.18,
      "text": "are potentially like working with."
    },
    {
      "start": 2797.18,
      "end": 2801.34,
      "text": "So this is going to be my selection for joke judgment."
    },
    {
      "start": 2801.34,
      "end": 2803.42,
      "text": "I'm going to create a new data set."
    },
    {
      "start": 2803.42,
      "end": 2806.18,
      "text": "We can actually upload already built in data sets."
    },
    {
      "start": 2806.18,
      "end": 2806.94,
      "text": "We can name this."
    },
    {
      "start": 2806.94,
      "end": 2814.86,
      "text": "This is going to be my selected jokes, the jokes,"
    },
    {
      "start": 2814.86,
      "end": 2817.42,
      "text": "and for the description, I'm just adding some description for here."
    },
    {
      "start": 2817.42,
      "end": 2823.66,
      "text": "And this is just the jokes that made the cut."
    },
    {
      "start": 2823.66,
      "end": 2826.3,
      "text": "And we have three different data set times."
    },
    {
      "start": 2826.3,
      "end": 2830.94,
      "text": "We have key value pairs, essentially, the input output type objects."
    },
    {
      "start": 2830.94,
      "end": 2834.74,
      "text": "We can actually also include different types of frameworks"
    },
    {
      "start": 2834.74,
      "end": 2838.9,
      "text": "for this type of, for this type of the value."
    },
    {
      "start": 2838.9,
      "end": 2841.38,
      "text": "They're essentially, they're similar in structure."
    },
    {
      "start": 2841.38,
      "end": 2843.62,
      "text": "But for all I'm trying to do here"
    },
    {
      "start": 2843.62,
      "end": 2848.78,
      "text": "is essentially create a chat-based dictionary type object."
    },
    {
      "start": 2848.78,
      "end": 2852.02,
      "text": "So the input is going to be the joke that we're"
    },
    {
      "start": 2852.02,
      "end": 2856.06,
      "text": "asked or the prompt that we're asking the AI to create."
    },
    {
      "start": 2856.06,
      "end": 2858.82,
      "text": "And the joke will be whatever the output is."
    },
    {
      "start": 2858.82,
      "end": 2861.74,
      "text": "So in this case, it's just kind of a chat-based conversation."
    },
    {
      "start": 2861.74,
      "end": 2863.22,
      "text": "So that's what I'm going to be creating."
    },
    {
      "start": 2863.22,
      "end": 2865.94,
      "text": "This is going to be my default data set."
    },
    {
      "start": 2865.94,
      "end": 2869.54,
      "text": "Joke judgment, and I'm going to create an evaluator."
    },
    {
      "start": 2869.54,
      "end": 2873.99,
      "text": "So that's going to be, we've added one object to the annotation tool."
    },
    {
      "start": 2874.03,
      "end": 2877.67,
      "text": "I'm just going to go ahead and do that for the rest here."
    },
    {
      "start": 2877.67,
      "end": 2879.23,
      "text": "And this is a little bit manual."
    },
    {
      "start": 2879.23,
      "end": 2881.03,
      "text": "There's easier ways to do this."
    },
    {
      "start": 2881.03,
      "end": 2884.43,
      "text": "But I do just want to showcase those individual steps."
    },
    {
      "start": 2884.43,
      "end": 2887.23,
      "text": "Just kind of click and click."
    },
    {
      "start": 2887.23,
      "end": 2889.83,
      "text": "And then I can then go to the annotation tool."
    },
    {
      "start": 2889.83,
      "end": 2891.15,
      "text": "I'm going to get right there for a second."
    },
    {
      "start": 2891.15,
      "end": 2892.11,
      "text": "Sorry."
    },
    {
      "start": 2892.11,
      "end": 2897.14,
      "text": "And as you can see here, this is our joke judgment evaluator tool."
    },
    {
      "start": 2897.14,
      "end": 2900.26,
      "text": "And the way that this is going to be evaluated in our case,"
    },
    {
      "start": 2900.26,
      "end": 2903.9,
      "text": "because we're creating this in a kind of manual user"
    },
    {
      "start": 2903.9,
      "end": 2905.86,
      "text": "like the human is going to be the person who's evaluated,"
    },
    {
      "start": 2905.86,
      "end": 2908.7,
      "text": "whether this prompt makes sense to use."
    },
    {
      "start": 2908.7,
      "end": 2912.47,
      "text": "We can then have a certain set of tools"
    },
    {
      "start": 2912.47,
      "end": 2917.67,
      "text": "to determine whether I want this to be part of my data set object."
    },
    {
      "start": 2917.67,
      "end": 2921.94,
      "text": "So we can either add this back to our data set."
    },
    {
      "start": 2921.94,
      "end": 2927.96,
      "text": "We can evaluate this as saying like this joke is super proper."
    },
    {
      "start": 2927.96,
      "end": 2929.8,
      "text": "And then we can actually make an evaluation"
    },
    {
      "start": 2929.8,
      "end": 2932.4,
      "text": "as to whether this input seems correct."
    },
    {
      "start": 2932.4,
      "end": 2935.92,
      "text": "So if I said, tell me a dad joke of joke should be its story format."
    },
    {
      "start": 2935.92,
      "end": 2938.24,
      "text": "What's fun of time with dad to say so?"
    },
    {
      "start": 2938.24,
      "end": 2939.72,
      "text": "They were walking around."
    },
    {
      "start": 2939.72,
      "end": 2942.16,
      "text": "So I'm sure they're curious about this as a primate."
    },
    {
      "start": 2942.16,
      "end": 2943.4,
      "text": "OK, run."
    },
    {
      "start": 2943.4,
      "end": 2945.48,
      "text": "Does this look like it met the prompt?"
    },
    {
      "start": 2945.48,
      "end": 2946.72,
      "text": "Let's go ahead and say, yeah, sure."
    },
    {
      "start": 2946.72,
      "end": 2947.56,
      "text": "It looks like a story."
    },
    {
      "start": 2947.56,
      "end": 2948.64,
      "text": "It looks like a joke."
    },
    {
      "start": 2948.64,
      "end": 2953.08,
      "text": "I didn't laugh, but we're going to go ahead and just call that."
    },
    {
      "start": 2953.08,
      "end": 2954.76,
      "text": "And we're just going to evaluate that as done."
    },
    {
      "start": 2954.76,
      "end": 2955.92,
      "text": "Let's go to the next one."
    },
    {
      "start": 2955.92,
      "end": 2957.36,
      "text": "This is another joke."
    },
    {
      "start": 2957.36,
      "end": 2958.28,
      "text": "Another story."
    },
    {
      "start": 2958.28,
      "end": 2960.08,
      "text": "This one's a little bit longer."
    },
    {
      "start": 2960.08,
      "end": 2962.2,
      "text": "Dad laughed and said, well, I guess you could say that"
    },
    {
      "start": 2962.2,
      "end": 2963.44,
      "text": "deal was half day."
    },
    {
      "start": 2963.44,
      "end": 2964.72,
      "text": "It does start with once upon a time."
    },
    {
      "start": 2964.72,
      "end": 2966.12,
      "text": "So it does sort of look like a story."
    },
    {
      "start": 2966.12,
      "end": 2970.28,
      "text": "OK, let's go ahead and say, maybe that's correct too."
    },
    {
      "start": 2970.28,
      "end": 2973.65,
      "text": "Let's go ahead and do finish that up."
    },
    {
      "start": 2973.65,
      "end": 2975.61,
      "text": "Let's say that for whatever reason,"
    },
    {
      "start": 2975.61,
      "end": 2977.53,
      "text": "we think that the joke doesn't quite match."
    },
    {
      "start": 2977.53,
      "end": 2980.33,
      "text": "Maybe it's not actually funny for us."
    },
    {
      "start": 2980.33,
      "end": 2981.65,
      "text": "Maybe we're not just a fan of it."
    },
    {
      "start": 2981.65,
      "end": 2983.97,
      "text": "And maybe we're tired of seeing this repetitive."
    },
    {
      "start": 2983.97,
      "end": 2986.13,
      "text": "Like we're kind of starting to see a pattern here"
    },
    {
      "start": 2986.13,
      "end": 2988.25,
      "text": "for whatever reason."
    },
    {
      "start": 2988.25,
      "end": 2990.41,
      "text": "Let's say that for what some arbitrary reason,"
    },
    {
      "start": 2990.41,
      "end": 2991.33,
      "text": "I don't like this joke."
    },
    {
      "start": 2991.33,
      "end": 2995.13,
      "text": "I'm going to go ahead and label that as incorrect."
    },
    {
      "start": 2995.13,
      "end": 2996.37,
      "text": "I'm not interested in using that."
    },
    {
      "start": 2996.37,
      "end": 2999.54,
      "text": "I'm going to go ahead and click Done."
    },
    {
      "start": 2999.54,
      "end": 3004.73,
      "text": "And I want to make sure that I'm adding about the data set."
    },
    {
      "start": 3004.73,
      "end": 3007.69,
      "text": "Let's say this one's correct too."
    },
    {
      "start": 3007.69,
      "end": 3009.61,
      "text": "I'm going to go ahead and click Done with that one."
    },
    {
      "start": 3009.61,
      "end": 3011.09,
      "text": "And this one isn't so much of a story,"
    },
    {
      "start": 3011.09,
      "end": 3013.93,
      "text": "so I'm just going to go ahead and click that as incorrect."
    },
    {
      "start": 3013.93,
      "end": 3015.52,
      "text": "Label that done."
    },
    {
      "start": 3015.52,
      "end": 3018.18,
      "text": "So that should be good."
    },
    {
      "start": 3018.18,
      "end": 3021.82,
      "text": "Let's see if I added this to my data sets automatically."
    },
    {
      "start": 3021.82,
      "end": 3022.98,
      "text": "Yes."
    },
    {
      "start": 3022.98,
      "end": 3026.14,
      "text": "So as part of my data sets, how I did that,"
    },
    {
      "start": 3026.14,
      "end": 3027.7,
      "text": "I'm directly to it by that."
    },
    {
      "start": 3027.7,
      "end": 3030.9,
      "text": "I forgot to be adding these tools to the keys themselves."
    },
    {
      "start": 3030.9,
      "end": 3033.83,
      "text": "So the other thing is as part of the annotation key,"
    },
    {
      "start": 3033.83,
      "end": 3037.75,
      "text": "you can also add those tools to the data set itself."
    },
    {
      "start": 3037.75,
      "end": 3039.67,
      "text": "But if you just like I just did now,"
    },
    {
      "start": 3039.67,
      "end": 3043.33,
      "text": "forgot to add it to the tool itself."
    },
    {
      "start": 3043.33,
      "end": 3045.85,
      "text": "Let's go back to the run sequence."
    },
    {
      "start": 3045.85,
      "end": 3048.17,
      "text": "Just going to go ahead and take all of these objects"
    },
    {
      "start": 3048.17,
      "end": 3052.96,
      "text": "added to the data set."
    },
    {
      "start": 3052.96,
      "end": 3054.92,
      "text": "You just submit that as part of the data set."
    },
    {
      "start": 3054.92,
      "end": 3058.94,
      "text": "And I think I said that one was correct."
    },
    {
      "start": 3058.94,
      "end": 3060.46,
      "text": "This one was correct."
    },
    {
      "start": 3060.46,
      "end": 3068.77,
      "text": "And I think I decided that last one was correct."
    },
    {
      "start": 3068.77,
      "end": 3072.42,
      "text": "So we're going to add that to the data set itself."
    },
    {
      "start": 3072.42,
      "end": 3074.02,
      "text": "Submit that in."
    },
    {
      "start": 3074.02,
      "end": 3075.14,
      "text": "And when I look at the data set,"
    },
    {
      "start": 3075.14,
      "end": 3078.18,
      "text": "I now have an input output based information"
    },
    {
      "start": 3078.18,
      "end": 3081.42,
      "text": "that gives me both information about the output,"
    },
    {
      "start": 3081.42,
      "end": 3085.83,
      "text": "what it was created, and how that information worked."
    },
    {
      "start": 3085.83,
      "end": 3087.19,
      "text": "Excuse me."
    },
    {
      "start": 3087.19,
      "end": 3090.69,
      "text": "So this is essentially where we are"
    },
    {
      "start": 3090.69,
      "end": 3092.85,
      "text": "beginning to like create a data set of the prompts"
    },
    {
      "start": 3092.85,
      "end": 3095.13,
      "text": "that worked for us."
    },
    {
      "start": 3095.13,
      "end": 3099.53,
      "text": "These were the elements where as part of that framework"
    },
    {
      "start": 3099.53,
      "end": 3101.37,
      "text": "or as part of that team dynamic,"
    },
    {
      "start": 3101.37,
      "end": 3103.09,
      "text": "we checked in with our other users"
    },
    {
      "start": 3103.09,
      "end": 3104.49,
      "text": "and the other users in our environment"
    },
    {
      "start": 3104.49,
      "end": 3107.61,
      "text": "and essentially said, hey, this joke worked."
    },
    {
      "start": 3107.61,
      "end": 3109.61,
      "text": "Open AI did a good job here."
    },
    {
      "start": 3109.61,
      "end": 3110.85,
      "text": "The other two that we've decided"
    },
    {
      "start": 3110.85,
      "end": 3112.61,
      "text": "to keep out of the data set that now works."
    },
    {
      "start": 3112.61,
      "end": 3115.25,
      "text": "So we implied those values as an evaluation"
    },
    {
      "start": 3115.25,
      "end": 3119.57,
      "text": "of zero, not correct outputs for the prompts we created."
    },
    {
      "start": 3119.65,
      "end": 3123.17,
      "text": "There's a few other things that we can also look at."
    },
    {
      "start": 3123.17,
      "end": 3125.93,
      "text": "Like, if we're not feeling like going through every single joke"
    },
    {
      "start": 3125.93,
      "end": 3127.57,
      "text": "and determining whether it's correct,"
    },
    {
      "start": 3127.57,
      "end": 3130.01,
      "text": "open AI and some of the other packages"
    },
    {
      "start": 3130.01,
      "end": 3131.93,
      "text": "have evaluators that essentially create"
    },
    {
      "start": 3131.93,
      "end": 3133.81,
      "text": "this in an automatic environment."
    },
    {
      "start": 3133.81,
      "end": 3137.05,
      "text": "So all you need to do is just select the new experiment"
    },
    {
      "start": 3137.05,
      "end": 3139.13,
      "text": "and you can see that it's pretty much the same code"
    },
    {
      "start": 3139.13,
      "end": 3140.25,
      "text": "over and over again."
    },
    {
      "start": 3140.25,
      "end": 3143.89,
      "text": "All you're really doing is just adding a line of code"
    },
    {
      "start": 3143.89,
      "end": 3145.89,
      "text": "to the evaluators at the end."
    },
    {
      "start": 3145.89,
      "end": 3148.53,
      "text": "So you can evaluate each output"
    },
    {
      "start": 3148.53,
      "end": 3151.25,
      "text": "or if you wish to include that information"
    },
    {
      "start": 3151.25,
      "end": 3153.85,
      "text": "for correctness, relevance, and helpfulness."
    },
    {
      "start": 3153.85,
      "end": 3158.17,
      "text": "And each one of these terms has its own specific definition."
    },
    {
      "start": 3158.17,
      "end": 3159.97,
      "text": "A lot of these definitions, these evaluators"
    },
    {
      "start": 3159.97,
      "end": 3161.13,
      "text": "are essentially built to look"
    },
    {
      "start": 3161.13,
      "end": 3164.05,
      "text": "or specifically keywords or specific embeddings"
    },
    {
      "start": 3164.05,
      "end": 3169.05,
      "text": "that would follow or fit that specific evaluation."
    },
    {
      "start": 3170.49,
      "end": 3174.05,
      "text": "But again, this is if you wanna automate that process,"
    },
    {
      "start": 3174.05,
      "end": 3176.05,
      "text": "that's an option that you have."
    },
    {
      "start": 3176.05,
      "end": 3179.45,
      "text": "And this is simply something that you code through,"
    },
    {
      "start": 3179.45,
      "end": 3181.98,
      "text": "apply into the model itself"
    },
    {
      "start": 3181.98,
      "end": 3186.98,
      "text": "and build it into your particular platform."
    },
    {
      "start": 3186.98,
      "end": 3190.72,
      "text": "But that is step one,"
    },
    {
      "start": 3190.72,
      "end": 3192.52,
      "text": "and that is essentially one of the advantages"
    },
    {
      "start": 3192.52,
      "end": 3197.52,
      "text": "of using LancsNet as part of your evaluation process."
    },
    {
      "start": 3198.44,
      "end": 3200.52,
      "text": "Okay, I've got maybe about seven minutes ago,"
    },
    {
      "start": 3200.52,
      "end": 3202.96,
      "text": "so I might go a little bit above time."
    },
    {
      "start": 3202.96,
      "end": 3204.56,
      "text": "But let's talk about this."
    },
    {
      "start": 3204.56,
      "end": 3207.4,
      "text": "I've now got three jokes that I decided"
    },
    {
      "start": 3207.4,
      "end": 3211.04,
      "text": "arbitrarily or that we decided as part of the class"
    },
    {
      "start": 3211.04,
      "end": 3211.96,
      "text": "kind of worked."
    },
    {
      "start": 3213.81,
      "end": 3216.77,
      "text": "So what I want is, I wanna bring this back in."
    },
    {
      "start": 3221.86,
      "end": 3224.42,
      "text": "And I'm going to take them back to my prompting panel."
    },
    {
      "start": 3224.42,
      "end": 3229.41,
      "text": "So I'm going to open up another tool here."
    },
    {
      "start": 3229.41,
      "end": 3233.88,
      "text": "And what I want to showcase is how do we use"
    },
    {
      "start": 3233.88,
      "end": 3237.17,
      "text": "Lancchains tool, I might have to bounce"
    },
    {
      "start": 3237.17,
      "end": 3242.39,
      "text": "a little bit between, but just to be able to let us see this."
    },
    {
      "start": 3242.39,
      "end": 3244.19,
      "text": "This is a, this is pretty much,"
    },
    {
      "start": 3244.19,
      "end": 3248.87,
      "text": "this is similar to what we can create within LancsNet."
    },
    {
      "start": 3248.87,
      "end": 3251.83,
      "text": "But let's say that we've already done the evaluation."
    },
    {
      "start": 3251.83,
      "end": 3253.19,
      "text": "We've determined that those three jokes"
    },
    {
      "start": 3253.19,
      "end": 3254.55,
      "text": "are the best dad jokes ever."
    },
    {
      "start": 3254.55,
      "end": 3255.95,
      "text": "They're not, I read them,"
    },
    {
      "start": 3255.95,
      "end": 3257.95,
      "text": "just skimming through them, they look terrible."
    },
    {
      "start": 3257.95,
      "end": 3261.23,
      "text": "But let's say we want our LLM to start creating dad jokes"
    },
    {
      "start": 3261.23,
      "end": 3263.51,
      "text": "that follow that same framework."
    },
    {
      "start": 3263.51,
      "end": 3266.07,
      "text": "Well, there's a bit, like the bit of code"
    },
    {
      "start": 3266.07,
      "end": 3268.83,
      "text": "just requires us to create"
    },
    {
      "start": 3268.83,
      "end": 3273.83,
      "text": "and create, use those jokes that we used as the prompts"
    },
    {
      "start": 3274.43,
      "end": 3278.51,
      "text": "for our model to create the next set of jokes,"
    },
    {
      "start": 3278.51,
      "end": 3281.35,
      "text": "following what it learned from reading"
    },
    {
      "start": 3281.35,
      "end": 3284.11,
      "text": "those prompts that we created earlier."
    },
    {
      "start": 3284.11,
      "end": 3288.65,
      "text": "So I'm going to use two tools, the chat prompt template"
    },
    {
      "start": 3288.65,
      "end": 3291.53,
      "text": "and the few shot chat message prompt template."
    },
    {
      "start": 3291.53,
      "end": 3294.98,
      "text": "And this is where the few shot prompting comes into play."
    },
    {
      "start": 3294.98,
      "end": 3297.18,
      "text": "And the way this works, and again,"
    },
    {
      "start": 3297.66,
      "end": 3299.02,
      "text": "otherwise everything else is the same."
    },
    {
      "start": 3299.02,
      "end": 3301.22,
      "text": "I'm using the low dot environment to call the environment."
    },
    {
      "start": 3301.22,
      "end": 3303.3,
      "text": "I'm accessing, not actually accessing"
    },
    {
      "start": 3303.3,
      "end": 3305.86,
      "text": "LLM at this point, I'm just doing this"
    },
    {
      "start": 3305.86,
      "end": 3309.26,
      "text": "from the joke itself,"
    },
    {
      "start": 3309.26,
      "end": 3311.94,
      "text": "from like, from the jokes themselves."
    },
    {
      "start": 3311.94,
      "end": 3315.18,
      "text": "So I'm just going to go ahead and take these jokes."
    },
    {
      "start": 3315.18,
      "end": 3318.18,
      "text": "And it's going to be a little bit manual."
    },
    {
      "start": 3318.18,
      "end": 3322.58,
      "text": "But what I'm going to do is I'm going to add to these jokes,"
    },
    {
      "start": 3322.58,
      "end": 3329.96,
      "text": "the output that you would for that specific tool."
    },
    {
      "start": 3329.96,
      "end": 3331.16,
      "text": "Let me just go ahead and add,"
    },
    {
      "start": 3331.16,
      "end": 3334.99,
      "text": "because I decided to use three jokes here."
    },
    {
      "start": 3334.99,
      "end": 3335.83,
      "text": "Let's leave that."
    },
    {
      "start": 3335.83,
      "end": 3340.5,
      "text": "So my input is tell me the joke should be in story format."
    },
    {
      "start": 3340.5,
      "end": 3343.42,
      "text": "So I'm just going to update the output I got"
    },
    {
      "start": 3343.42,
      "end": 3344.54,
      "text": "from those three jokes."
    },
    {
      "start": 3344.54,
      "end": 3348.11,
      "text": "So bear with me, this is going to be a little bit manual."
    },
    {
      "start": 3348.11,
      "end": 3352.08,
      "text": "I'm going to copy that output, put that there."
    },
    {
      "start": 3352.08,
      "end": 3355.0,
      "text": "So that was a messier than I wanted that to be."
    },
    {
      "start": 3355.0,
      "end": 3362.73,
      "text": "But sorry, bear with me for five seconds."
    },
    {
      "start": 3362.73,
      "end": 3372.55,
      "text": "Right, too many, too much of that."
    },
    {
      "start": 3372.55,
      "end": 3375.07,
      "text": "Much of that, I might limit myself to two,"
    },
    {
      "start": 3375.07,
      "end": 3380.54,
      "text": "because this is this might get tedious."
    },
    {
      "start": 3380.54,
      "end": 3383.62,
      "text": "And the other joke I'm creating is the same thing."
    },
    {
      "start": 3383.62,
      "end": 3385.86,
      "text": "Both of these jokes, actually that's a pretty good example."
    },
    {
      "start": 3385.86,
      "end": 3389.1,
      "text": "Once upon a time there's that, but it starts the same way."
    },
    {
      "start": 3389.1,
      "end": 3390.89,
      "text": "Let's do that."
    },
    {
      "start": 3390.89,
      "end": 3392.29,
      "text": "Let's do that."
    },
    {
      "start": 3392.29,
      "end": 3395.33,
      "text": "Let's do that."
    },
    {
      "start": 3396.05,
      "end": 3412.99,
      "text": "That is a lot of dialogue here."
    },
    {
      "start": 3412.99,
      "end": 3414.47,
      "text": "OK, let's see."
    },
    {
      "start": 3414.47,
      "end": 3416.51,
      "text": "I'll put this that look right."
    },
    {
      "start": 3416.51,
      "end": 3418.75,
      "text": "All right, so let's clean this up a little bit."
    },
    {
      "start": 3418.75,
      "end": 3420.43,
      "text": "All right, so I have two sets of inputs."
    },
    {
      "start": 3420.43,
      "end": 3421.95,
      "text": "So I'm just going to use two prompts."
    },
    {
      "start": 3421.95,
      "end": 3423.99,
      "text": "Those are my few shots here."
    },
    {
      "start": 3423.99,
      "end": 3425.92,
      "text": "That works."
    },
    {
      "start": 3425.92,
      "end": 3428.6,
      "text": "All right, so from here, my example prompt"
    },
    {
      "start": 3428.6,
      "end": 3431.52,
      "text": "is taking the chat prompt template from these messages,"
    },
    {
      "start": 3431.52,
      "end": 3433.68,
      "text": "from these examples that I just created."
    },
    {
      "start": 3433.68,
      "end": 3435.4,
      "text": "Both of these jokes start with once upon a time."
    },
    {
      "start": 3435.4,
      "end": 3438.14,
      "text": "There was a dad or a dad."
    },
    {
      "start": 3438.14,
      "end": 3440.78,
      "text": "So both of these jokes are going to start out the way."
    },
    {
      "start": 3440.78,
      "end": 3443.62,
      "text": "And the human message is essentially always going to be,"
    },
    {
      "start": 3443.62,
      "end": 3445.98,
      "text": "or you would presume that the input,"
    },
    {
      "start": 3445.98,
      "end": 3448.02,
      "text": "when you get an input, that looks like,"
    },
    {
      "start": 3448.02,
      "end": 3448.98,
      "text": "tell me a dad joke."
    },
    {
      "start": 3448.98,
      "end": 3450.26,
      "text": "The joke should be in story format."
    },
    {
      "start": 3450.26,
      "end": 3453.1,
      "text": "The output should look something like this."
    },
    {
      "start": 3453.1,
      "end": 3455.46,
      "text": "And this few shot prompt is essentially"
    },
    {
      "start": 3455.46,
      "end": 3458.46,
      "text": "going to be taking that prompt template"
    },
    {
      "start": 3458.46,
      "end": 3460.9,
      "text": "from the example prompts that we created above."
    },
    {
      "start": 3460.9,
      "end": 3463.62,
      "text": "And it's going to be taking a case from the examples"
    },
    {
      "start": 3463.62,
      "end": 3469.46,
      "text": "that we used in our prompts from earlier."
    },
    {
      "start": 3469.46,
      "end": 3473.54,
      "text": "And format those jokes so that they potentially"
    },
    {
      "start": 3473.54,
      "end": 3475.06,
      "text": "look a little bit alike this."
    },
    {
      "start": 3475.06,
      "end": 3477.86,
      "text": "So any time the human asks something about a dad joke,"
    },
    {
      "start": 3477.86,
      "end": 3480.42,
      "text": "the joke should be in story format,"
    },
    {
      "start": 3480.42,
      "end": 3485.32,
      "text": "we can expect the AI to respond something like this."
    },
    {
      "start": 3485.32,
      "end": 3486.4,
      "text": "Let's try that out."
    },
    {
      "start": 3486.4,
      "end": 3489.08,
      "text": "We've trained our model quote unquote"
    },
    {
      "start": 3489.08,
      "end": 3491.04,
      "text": "with the framework or the prompts"
    },
    {
      "start": 3491.04,
      "end": 3493.89,
      "text": "that we created earlier."
    },
    {
      "start": 3493.89,
      "end": 3496.61,
      "text": "And I want to add one final prompt, which"
    },
    {
      "start": 3496.61,
      "end": 3499.45,
      "text": "is I'm telling the system we're adding a system message"
    },
    {
      "start": 3499.45,
      "end": 3501.61,
      "text": "just to make sure that this is working"
    },
    {
      "start": 3501.61,
      "end": 3504.05,
      "text": "or that the model has learned from both the prompts"
    },
    {
      "start": 3504.05,
      "end": 3505.89,
      "text": "and the information that I've created."
    },
    {
      "start": 3505.89,
      "end": 3507.81,
      "text": "I want all of these jokes and with the phrase"
    },
    {
      "start": 3507.81,
      "end": 3511.69,
      "text": "visinga, because I'm terrible like that sometimes."
    },
    {
      "start": 3511.69,
      "end": 3514.13,
      "text": "Still going to follow the few shot prompts"
    },
    {
      "start": 3514.13,
      "end": 3517.01,
      "text": "and still going to require that human input."
    },
    {
      "start": 3517.01,
      "end": 3519.65,
      "text": "So if I have this run on its own,"
    },
    {
      "start": 3519.65,
      "end": 3523.61,
      "text": "I'm going to use the Langshan chat open AI, just importing that."
    },
    {
      "start": 3523.61,
      "end": 3525.49,
      "text": "And I'm going to call that final prompt."
    },
    {
      "start": 3525.49,
      "end": 3527.61,
      "text": "And again, essentially just informing the chain"
    },
    {
      "start": 3527.61,
      "end": 3530.37,
      "text": "that I'm going to be using as part of open AI."
    },
    {
      "start": 3530.37,
      "end": 3533.85,
      "text": "Remember that with chat open AI on Monday,"
    },
    {
      "start": 3533.85,
      "end": 3537.81,
      "text": "we created a chat open AI tool that invoked the information"
    },
    {
      "start": 3537.81,
      "end": 3539.65,
      "text": "or the call."
    },
    {
      "start": 3539.65,
      "end": 3541.69,
      "text": "In this case, the difference is that I'm"
    },
    {
      "start": 3541.69,
      "end": 3544.01,
      "text": "calling the final prompt first so that it actually,"
    },
    {
      "start": 3544.01,
      "end": 3546.09,
      "text": "the chain actually learns from the information"
    },
    {
      "start": 3546.09,
      "end": 3548.09,
      "text": "I shared in that final prompt, the examples"
    },
    {
      "start": 3548.09,
      "end": 3550.25,
      "text": "I created earlier."
    },
    {
      "start": 3550.25,
      "end": 3554.85,
      "text": "And again, the few shot prompts are already built into that final"
    },
    {
      "start": 3554.85,
      "end": 3555.89,
      "text": "prompt."
    },
    {
      "start": 3555.89,
      "end": 3557.85,
      "text": "I've got it set to a temperature of 7."
    },
    {
      "start": 3557.85,
      "end": 3560.77,
      "text": "And I'm actually asking the joke so that it follows"
    },
    {
      "start": 3560.77,
      "end": 3564.05,
      "text": "the joke to be in that story format."
    },
    {
      "start": 3564.05,
      "end": 3566.01,
      "text": "And I should probably include and string up parts of what"
    },
    {
      "start": 3566.01,
      "end": 3568.05,
      "text": "I'm not going to do that."
    },
    {
      "start": 3568.05,
      "end": 3568.65,
      "text": "So all right."
    },
    {
      "start": 3568.65,
      "end": 3572.09,
      "text": "And now, when I've run the package,"
    },
    {
      "start": 3572.09,
      "end": 3574.25,
      "text": "I've added somewhat quite a bit amount of creativity."
    },
    {
      "start": 3574.25,
      "end": 3577.59,
      "text": "Let me just go ahead and add a little bit more creativity."
    },
    {
      "start": 3577.59,
      "end": 3579.63,
      "text": "And I'm just going to run this a few times."
    },
    {
      "start": 3579.63,
      "end": 3581.23,
      "text": "But once upon a time, my dad was helping"
    },
    {
      "start": 3581.23,
      "end": 3584.11,
      "text": "his son with his math homework, a terrible joke."
    },
    {
      "start": 3584.11,
      "end": 3586.35,
      "text": "And even though he was still frustrating with the math,"
    },
    {
      "start": 3586.35,
      "end": 3588.23,
      "text": "oh, didn't he mount and clean with a single?"
    },
    {
      "start": 3588.23,
      "end": 3589.63,
      "text": "Did I miss that mark?"
    },
    {
      "start": 3589.63,
      "end": 3596.44,
      "text": "Run that, run that, let's see."
    },
    {
      "start": 3596.44,
      "end": 3596.92,
      "text": "Oh, there he is."
    },
    {
      "start": 3596.92,
      "end": 3597.44,
      "text": "All right."
    },
    {
      "start": 3597.44,
      "end": 3598.48,
      "text": "So there's the busy end beyond."
    },
    {
      "start": 3598.48,
      "end": 3599.52,
      "text": "So that's correct."
    },
    {
      "start": 3599.52,
      "end": 3600.88,
      "text": "Once upon a time, there was a daddy while he's"
    },
    {
      "start": 3600.88,
      "end": 3602.8,
      "text": "dreamed of being a comedic great."
    },
    {
      "start": 3602.8,
      "end": 3603.88,
      "text": "So let's try this again."
    },
    {
      "start": 3603.88,
      "end": 3605.48,
      "text": "This is three times."
    },
    {
      "start": 3605.48,
      "end": 3607.36,
      "text": "Once upon a time, my dad decided to use that."
    },
    {
      "start": 3607.36,
      "end": 3609.48,
      "text": "So now we're seeing that all of the jokes that"
    },
    {
      "start": 3609.48,
      "end": 3612.28,
      "text": "we're starting to come out have the information"
    },
    {
      "start": 3612.28,
      "end": 3613.92,
      "text": "from the prompts that we created earlier."
    },
    {
      "start": 3613.92,
      "end": 3615.24,
      "text": "And again, that's because we, as a group,"
    },
    {
      "start": 3615.24,
      "end": 3618.4,
      "text": "decided that the prompts or a good dad joke"
    },
    {
      "start": 3618.4,
      "end": 3621.28,
      "text": "must start with once upon a time,"
    },
    {
      "start": 3621.28,
      "end": 3623.72,
      "text": "and or at least the two prompts that we use all"
    },
    {
      "start": 3623.72,
      "end": 3627.05,
      "text": "had to start with once upon a time."
    },
    {
      "start": 3627.05,
      "end": 3628.61,
      "text": "And this is essentially where you start to,"
    },
    {
      "start": 3628.61,
      "end": 3631.89,
      "text": "even with a temperature of high as 0.09,"
    },
    {
      "start": 3631.89,
      "end": 3634.01,
      "text": "like that framework, that structure,"
    },
    {
      "start": 3634.01,
      "end": 3641.46,
      "text": "that those elements of those elements"
    },
    {
      "start": 3641.46,
      "end": 3645.26,
      "text": "of the model of the prompts are essentially helping us"
    },
    {
      "start": 3645.26,
      "end": 3650.75,
      "text": "inform what we want our model to return and look like."
    },
    {
      "start": 3650.75,
      "end": 3651.82,
      "text": "All right."
    },
    {
      "start": 3651.82,
      "end": 3653.63,
      "text": "So what does that mean?"
    },
    {
      "start": 3653.63,
      "end": 3656.03,
      "text": "This is something that we can essentially"
    },
    {
      "start": 3656.03,
      "end": 3659.84,
      "text": "help determine using a tool like Lancement."
    },
    {
      "start": 3659.84,
      "end": 3661.96,
      "text": "We can essentially do all of this in Python JavaScript,"
    },
    {
      "start": 3661.96,
      "end": 3664.44,
      "text": "whatever tool you want to use, and essentially build"
    },
    {
      "start": 3664.44,
      "end": 3666.8,
      "text": "and manually create what prompts seems to work for you"
    },
    {
      "start": 3666.8,
      "end": 3671.4,
      "text": "and add that into like a future LLM"
    },
    {
      "start": 3671.4,
      "end": 3673.28,
      "text": "that you would build on your own."
    },
    {
      "start": 3673.28,
      "end": 3675.8,
      "text": "Or you could essentially use a tool that essentially keeps"
    },
    {
      "start": 3675.8,
      "end": 3680.6,
      "text": "all of the calls you've made in a nice organized fashion."
    },
    {
      "start": 3680.6,
      "end": 3683.16,
      "text": "So Lancement, on top of a couple of other different features"
    },
    {
      "start": 3683.16,
      "end": 3684.48,
      "text": "that we're going to be working with,"
    },
    {
      "start": 3684.48,
      "end": 3687.28,
      "text": "has a method and certain set love sets of tools"
    },
    {
      "start": 3687.28,
      "end": 3693.26,
      "text": "that allow you to kind of annotate, evaluate,"
    },
    {
      "start": 3693.26,
      "end": 3696.62,
      "text": "and determine whether a specific step is worthwhile"
    },
    {
      "start": 3696.62,
      "end": 3698.46,
      "text": "for you to use."
    },
    {
      "start": 3698.46,
      "end": 3701.26,
      "text": "One thing I didn't mention as part of the annotation tool,"
    },
    {
      "start": 3701.3,
      "end": 3704.02,
      "text": "let me just go ahead and showcase that one more time."
    },
    {
      "start": 3704.02,
      "end": 3709.38,
      "text": "We go back to this dad and show a tool basis."
    },
    {
      "start": 3712.34,
      "end": 3713.7,
      "text": "There it is, there's the run."
    },
    {
      "start": 3713.7,
      "end": 3717.38,
      "text": "Let me just go ahead and add that back to the annotation queue."
    },
    {
      "start": 3717.38,
      "end": 3720.85,
      "text": "Okay, I'm gonna go back to the judgment."
    },
    {
      "start": 3720.85,
      "end": 3723.84,
      "text": "You can actually modify your tools"
    },
    {
      "start": 3723.84,
      "end": 3725.56,
      "text": "as like your evaluations as well."
    },
    {
      "start": 3725.56,
      "end": 3728.04,
      "text": "So this is where like a human or a team member"
    },
    {
      "start": 3728.04,
      "end": 3729.84,
      "text": "can essentially all sit down and be like,"
    },
    {
      "start": 3729.84,
      "end": 3733.2,
      "text": "I don't like how open AI is like building out these prompts."
    },
    {
      "start": 3733.2,
      "end": 3737.56,
      "text": "Maybe a human can like help create a better joke,"
    },
    {
      "start": 3737.56,
      "end": 3740.36,
      "text": "for example, to like structure this in a better way."
    },
    {
      "start": 3740.36,
      "end": 3741.2,
      "text": "And once you've done that,"
    },
    {
      "start": 3741.2,
      "end": 3742.88,
      "text": "you can then add that back into the data set."
    },
    {
      "start": 3742.88,
      "end": 3744.56,
      "text": "That was the stuff that I wasn't doing"
    },
    {
      "start": 3744.56,
      "end": 3751.76,
      "text": "as I was going through the annotation tool."
    },
    {
      "start": 3751.76,
      "end": 3755.64,
      "text": "Fun stuff, thank you, we'll use it."
    },
    {
      "start": 3755.64,
      "end": 3757.66,
      "text": "Maybe, I don't know."
    },
    {
      "start": 3757.66,
      "end": 3759.14,
      "text": "Well, if you don't use that, we also again,"
    },
    {
      "start": 3759.14,
      "end": 3760.98,
      "text": "like I said, Langfuse is another option."
    },
    {
      "start": 3760.98,
      "end": 3763.34,
      "text": "A lot of the same things work very similarly."
    },
    {
      "start": 3765.14,
      "end": 3767.66,
      "text": "I haven't used, to be honest, I haven't used Langfuse"
    },
    {
      "start": 3767.66,
      "end": 3769.42,
      "text": "a whole lot, it is Jonathan."
    },
    {
      "start": 3769.7,
      "end": 3773.38,
      "text": "Do we know how old Langfuse is currently,"
    },
    {
      "start": 3773.38,
      "end": 3777.81,
      "text": "or how long have it's been around town?"
    },
    {
      "start": 3777.81,
      "end": 3779.73,
      "text": "I'm not exactly sure."
    },
    {
      "start": 3779.73,
      "end": 3781.45,
      "text": "I heard of it a while back,"
    },
    {
      "start": 3781.45,
      "end": 3783.33,
      "text": "but the first time I've messed with it"
    },
    {
      "start": 3783.33,
      "end": 3785.93,
      "text": "was a few days ago when it got brought up."
    },
    {
      "start": 3785.93,
      "end": 3787.94,
      "text": "Say, no."
    },
    {
      "start": 3787.94,
      "end": 3788.94,
      "text": "No, but it looks really cool."
    },
    {
      "start": 3788.94,
      "end": 3791.94,
      "text": "I mean, if it's your dime on it,"
    },
    {
      "start": 3791.94,
      "end": 3795.02,
      "text": "I'm not a bit like I would recommend it."
    },
    {
      "start": 3799.39,
      "end": 3801.15,
      "text": "Let me just check my notes here."
    },
    {
      "start": 3801.15,
      "end": 3804.63,
      "text": "Yeah, but that is about it."
    },
    {
      "start": 3804.63,
      "end": 3807.07,
      "text": "We are showcasing here how to use Langsmith"
    },
    {
      "start": 3807.07,
      "end": 3808.87,
      "text": "and essentially showcasing a place"
    },
    {
      "start": 3808.87,
      "end": 3811.35,
      "text": "where you can now build like the code that you built,"
    },
    {
      "start": 3811.35,
      "end": 3813.35,
      "text": "the things that your model's evaluated."
    },
    {
      "start": 3813.35,
      "end": 3815.79,
      "text": "You now have a place where you can look and study"
    },
    {
      "start": 3815.79,
      "end": 3817.75,
      "text": "and analyze and think about whether"
    },
    {
      "start": 3818.79,
      "end": 3821.19,
      "text": "those tools work for you behind the scenes"
    },
    {
      "start": 3822.95,
      "end": 3826.39,
      "text": "and the next step is up to you to practice with this"
    },
    {
      "start": 3826.39,
      "end": 3828.91,
      "text": "and literally like laying around with us"
    },
    {
      "start": 3828.91,
      "end": 3831.19,
      "text": "it's a very easy user interface."
    },
    {
      "start": 3831.19,
      "end": 3832.91,
      "text": "You won't get too hung up on this,"
    },
    {
      "start": 3832.91,
      "end": 3834.95,
      "text": "like you'll find everything that you need to do"
    },
    {
      "start": 3834.95,
      "end": 3835.79,
      "text": "fairly quickly."
    },
    {
      "start": 3835.79,
      "end": 3837.87,
      "text": "But one of the things we're going to recommend"
    },
    {
      "start": 3837.87,
      "end": 3839.47,
      "text": "for you to practice with one of their homeworks"
    },
    {
      "start": 3839.47,
      "end": 3843.07,
      "text": "is to take a look at all of these different reviews,"
    },
    {
      "start": 3844.03,
      "end": 3847.15,
      "text": "build them into like think of them as customer feedback"
    },
    {
      "start": 3847.15,
      "end": 3852.15,
      "text": "from a particular company and just determine"
    },
    {
      "start": 3852.59,
      "end": 3855.83,
      "text": "what the results would look like in Langsmith."
    },
    {
      "start": 3855.83,
      "end": 3858.07,
      "text": "So you determine what is a good response,"
    },
    {
      "start": 3858.07,
      "end": 3860.83,
      "text": "what is a good review"
    },
    {
      "start": 3860.83,
      "end": 3865.84,
      "text": "and determine from there, assign it to a data set."
    },
    {
      "start": 3865.84,
      "end": 3868.68,
      "text": "You want to prompt it so that you can now create"
    },
    {
      "start": 3868.68,
      "end": 3871.28,
      "text": "for the person who I think there was one person in the class,"
    },
    {
      "start": 3871.28,
      "end": 3874.52,
      "text": "wanted to like start creating a Twitter bots"
    },
    {
      "start": 3874.52,
      "end": 3876.39,
      "text": "or something like that."
    },
    {
      "start": 3876.39,
      "end": 3878.75,
      "text": "This is how you can begin to determine"
    },
    {
      "start": 3878.75,
      "end": 3880.51,
      "text": "what kind of tweet, Twitter bot message"
    },
    {
      "start": 3880.51,
      "end": 3885.9,
      "text": "you want to start creating."
    },
    {
      "start": 3885.9,
      "end": 3887.3,
      "text": "That's it."
    },
    {
      "start": 3887.3,
      "end": 3889.86,
      "text": "That's all I have for you today."
    },
    {
      "start": 3889.86,
      "end": 3893.14,
      "text": "So you are released unless you have any questions"
    },
    {
      "start": 3893.14,
      "end": 3895.7,
      "text": "you'd like to take a look at something"
    },
    {
      "start": 3895.7,
      "end": 3897.26,
      "text": "a little bit more deeply."
    },
    {
      "start": 3897.26,
      "end": 3899.42,
      "text": "Feel free to stick around."
    },
    {
      "start": 3899.42,
      "end": 3903.22,
      "text": "Both Jonathan and I are here for the next few moments."
    },
    {
      "start": 3903.22,
      "end": 3909.88,
      "text": "Thank you."
    },
    {
      "start": 3909.88,
      "end": 3911.04,
      "text": "Hopefully you'll have some fun with this."
    },
    {
      "start": 3911.04,
      "end": 3944.5,
      "text": "Have a wonderful evening otherwise."
    },
    {
      "start": 3944.5,
      "end": 3947.9,
      "text": "Projects."
    },
    {
      "start": 3947.9,
      "end": 3948.9,
      "text": "Yeah, all right."
    },
    {
      "start": 3948.9,
      "end": 3949.74,
      "text": "Oh, wow."
    },
    {
      "start": 3949.74,
      "end": 3950.98,
      "text": "Oh, my gosh, I just looked at myself"
    },
    {
      "start": 3950.98,
      "end": 3952.82,
      "text": "and I am sitting in darkness."
    },
    {
      "start": 3952.82,
      "end": 3954.74,
      "text": "That."
    },
    {
      "start": 3954.74,
      "end": 3975.97,
      "text": "Ah."
    },
    {
      "start": 3975.97,
      "end": 3979.78,
      "text": "It's up to Julian that I've lied."
    },
    {
      "start": 3979.78,
      "end": 3982.86,
      "text": "Lang came for and you mentioned it a little bit"
    },
    {
      "start": 3982.86,
      "end": 3986.74,
      "text": "of playground is just going straight from the trace"
    },
    {
      "start": 3986.74,
      "end": 3989.14,
      "text": "into the playground you were talking about"
    },
    {
      "start": 3989.14,
      "end": 3990.78,
      "text": "trying to decide models."
    },
    {
      "start": 3990.78,
      "end": 3993.9,
      "text": "Most of them you have to use put an API key in there."
    },
    {
      "start": 3993.9,
      "end": 3997.14,
      "text": "I've got some API keys in mind and they have a couple"
    },
    {
      "start": 3997.14,
      "end": 3999.34,
      "text": "free options like chat fireworks,"
    },
    {
      "start": 3999.34,
      "end": 4001.22,
      "text": "but you can actually experiment around"
    },
    {
      "start": 4001.22,
      "end": 4003.78,
      "text": "with the different models and see the same response"
    },
    {
      "start": 4003.78,
      "end": 4006.82,
      "text": "based on the prompt and change the parameters"
    },
    {
      "start": 4006.82,
      "end": 4008.14,
      "text": "and it logs all of that."
    },
    {
      "start": 4008.14,
      "end": 4010.26,
      "text": "So I actually use that at work"
    },
    {
      "start": 4010.26,
      "end": 4012.77,
      "text": "when we were arguing."
    },
    {
      "start": 4012.77,
      "end": 4016.25,
      "text": "Professionally arguing about what model we were going"
    },
    {
      "start": 4016.25,
      "end": 4017.65,
      "text": "to use for something."
    },
    {
      "start": 4017.65,
      "end": 4020.45,
      "text": "And it was the first time I had seen it use."
    },
    {
      "start": 4020.45,
      "end": 4023.57,
      "text": "This was a couple months ago, I guess."
    },
    {
      "start": 4023.57,
      "end": 4026.25,
      "text": "The actual playground that we were messing around"
    },
    {
      "start": 4026.25,
      "end": 4028.41,
      "text": "in the playground and saving all the outputs in."
    },
    {
      "start": 4028.41,
      "end": 4032.13,
      "text": "And it's pretty handy for a tool"
    },
    {
      "start": 4032.13,
      "end": 4037.29,
      "text": "that we all picked up on using within an hour or so."
    },
    {
      "start": 4037.29,
      "end": 4038.29,
      "text": "Yeah."
    },
    {
      "start": 4038.29,
      "end": 4039.97,
      "text": "From what I saw from the curriculum,"
    },
    {
      "start": 4039.97,
      "end": 4043.01,
      "text": "it looks like the playground comes into the vogue a lot"
    },
    {
      "start": 4043.01,
      "end": 4045.37,
      "text": "in what we started talking about the valuation"
    },
    {
      "start": 4045.37,
      "end": 4048.49,
      "text": "of the fine tuning, but it could be meant,"
    },
    {
      "start": 4048.49,
      "end": 4051.69,
      "text": "but yeah, no, I feel like if that's something I missed,"
    },
    {
      "start": 4051.69,
      "end": 4054.77,
      "text": "I'm happy to like go deeper into it"
    },
    {
      "start": 4054.77,
      "end": 4058.64,
      "text": "on connecting the next session for sure."
    },
    {
      "start": 4058.64,
      "end": 4060.08,
      "text": "Yeah, when you're in it, all you gotta,"
    },
    {
      "start": 4060.08,
      "end": 4061.88,
      "text": "when you're on a specific trace,"
    },
    {
      "start": 4061.88,
      "end": 4066.0,
      "text": "if you just hit the playground, the playground opens up"
    },
    {
      "start": 4066.0,
      "end": 4069.96,
      "text": "and it'll bring the input and output into the playground"
    },
    {
      "start": 4069.96,
      "end": 4072.48,
      "text": "and you can just on the side, there's a side bar"
    },
    {
      "start": 4072.48,
      "end": 4075.44,
      "text": "where you can start choosing providers and models,"
    },
    {
      "start": 4075.44,
      "end": 4078.36,
      "text": "set temperatures and tokens and whatnot."
    },
    {
      "start": 4078.36,
      "end": 4080.84,
      "text": "Now it's, I just went into it now"
    },
    {
      "start": 4080.84,
      "end": 4084.76,
      "text": "because with that 3.5, my results were less than stellar"
    },
    {
      "start": 4084.76,
      "end": 4087.2,
      "text": "and funny enough, one of their free models"
    },
    {
      "start": 4087.2,
      "end": 4089.52,
      "text": "was giving me incredibly better results"
    },
    {
      "start": 4089.52,
      "end": 4092.76,
      "text": "with the cat fireworks without even using tokens on"
    },
    {
      "start": 4092.76,
      "end": 4096.61,
      "text": "that I'm paying for."
    },
    {
      "start": 4096.61,
      "end": 4100.18,
      "text": "Yeah, I guess I didn't touch on that."
    },
    {
      "start": 4101.27,
      "end": 4105.22,
      "text": "That's good."
    },
    {
      "start": 4105.22,
      "end": 4107.1,
      "text": "No, yeah, I didn't really, really,"
    },
    {
      "start": 4107.1,
      "end": 4110.34,
      "text": "let me just go over that."
    },
    {
      "start": 4110.34,
      "end": 4115.81,
      "text": "Yeah, there's a lot to Lang Smith."
    },
    {
      "start": 4115.81,
      "end": 4121.29,
      "text": "I'm hoping to the end of the second on Tuesday."
    },
    {
      "start": 4121.29,
      "end": 4125.66,
      "text": "Are there, I was trying to think about my question is,"
    },
    {
      "start": 4125.66,
      "end": 4128.34,
      "text": "today's lesson felt to me a little like the 10 minute"
    },
    {
      "start": 4128.34,
      "end": 4131.06,
      "text": "video that you all sent, like there's a huge amount"
    },
    {
      "start": 4131.06,
      "end": 4132.9,
      "text": "of information and there's a huge amount of like"
    },
    {
      "start": 4132.9,
      "end": 4134.42,
      "text": "capability in the platform."
    },
    {
      "start": 4134.5,
      "end": 4138.62,
      "text": "I still don't necessarily feel clarity, I suppose."
    },
    {
      "start": 4138.62,
      "end": 4142.34,
      "text": "And that's also just because obviously it's only been an hour."
    },
    {
      "start": 4142.34,
      "end": 4144.3,
      "text": "I'm curious if there's any resources you recommend"
    },
    {
      "start": 4144.3,
      "end": 4145.5,
      "text": "outside the ones that you've already posted."
    },
    {
      "start": 4145.5,
      "end": 4147.66,
      "text": "Otherwise, I still need to watch the one hour one"
    },
    {
      "start": 4147.66,
      "end": 4152.3,
      "text": "and the deep dive documentation."
    },
    {
      "start": 4152.3,
      "end": 4153.3,
      "text": "Julian?"
    },
    {
      "start": 4153.3,
      "end": 4157.29,
      "text": "Oh, I mean, I mean, my process of learning"
    },
    {
      "start": 4157.29,
      "end": 4159.65,
      "text": "is not a process I recommend."
    },
    {
      "start": 4159.65,
      "end": 4162.93,
      "text": "I spend a lot of time at the documentation."
    },
    {
      "start": 4163.05,
      "end": 4167.17,
      "text": "So it's essentially, my methods is extremely academic."
    },
    {
      "start": 4167.17,
      "end": 4169.49,
      "text": "It is very much just making sure that I understand"
    },
    {
      "start": 4169.49,
      "end": 4171.61,
      "text": "like what each class, what each function is doing"
    },
    {
      "start": 4171.61,
      "end": 4174.01,
      "text": "to find the scenes and then making sure"
    },
    {
      "start": 4174.01,
      "end": 4175.49,
      "text": "I've put it into practice somehow."
    },
    {
      "start": 4175.49,
      "end": 4177.05,
      "text": "It is time consuming."
    },
    {
      "start": 4178.29,
      "end": 4182.69,
      "text": "So you know, the YouTube bit, like there are,"
    },
    {
      "start": 4182.69,
      "end": 4184.93,
      "text": "there are not a lot of good YouTube videos out there."
    },
    {
      "start": 4184.93,
      "end": 4185.77,
      "text": "Yeah."
    },
    {
      "start": 4185.77,
      "end": 4187.73,
      "text": "Like it is, like they're all at least 10 years old"
    },
    {
      "start": 4187.73,
      "end": 4191.49,
      "text": "and all of the methods have gotten like completely outdated."
    },
    {
      "start": 4193.12,
      "end": 4197.74,
      "text": "So my current, my current tech,"
    },
    {
      "start": 4197.74,
      "end": 4203.38,
      "text": "like my current best recommendation is just exhaustive."
    },
    {
      "start": 4203.9,
      "end": 4206.54,
      "text": "Yeah, I was going to go like one by line"
    },
    {
      "start": 4206.54,
      "end": 4209.22,
      "text": "through the implementation and like, what a soup strainer."
    },
    {
      "start": 4209.22,
      "end": 4210.7,
      "text": "Okay, here's soup strainer."
    },
    {
      "start": 4210.7,
      "end": 4212.38,
      "text": "It is, it is tedious."
    },
    {
      "start": 4213.86,
      "end": 4218.7,
      "text": "And like I can't vouch by, I can't vouch to it's effectiveness"
    },
    {
      "start": 4218.98,
      "end": 4221.3,
      "text": "but it is like I read it once"
    },
    {
      "start": 4221.3,
      "end": 4223.54,
      "text": "and I know how to come back to it down the road."
    },
    {
      "start": 4224.14,
      "end": 4226.42,
      "text": "Yeah, no, you're right that the resources are like this"
    },
    {
      "start": 4226.42,
      "end": 4230.74,
      "text": "like Smith is still changing so rapidly"
    },
    {
      "start": 4230.74,
      "end": 4233.02,
      "text": "that it's hard to find but Jonathan, what do you,"
    },
    {
      "start": 4233.02,
      "end": 4235.43,
      "text": "what do you, what have you found?"
    },
    {
      "start": 4235.43,
      "end": 4239.95,
      "text": "That video that, that's posted the hour long video"
    },
    {
      "start": 4239.95,
      "end": 4242.19,
      "text": "that came out four or five months ago,"
    },
    {
      "start": 4242.19,
      "end": 4245.71,
      "text": "that's the first video I would watch the hour long video."
    },
    {
      "start": 4245.71,
      "end": 4250.71,
      "text": "It's the 10 minute video is, he goes over that same stuff"
    },
    {
      "start": 4250.71,
      "end": 4252.67,
      "text": "but he covers a lot more."
    },
    {
      "start": 4252.75,
      "end": 4254.67,
      "text": "I watched that hour long video"
    },
    {
      "start": 4254.67,
      "end": 4257.39,
      "text": "and then my way of learning is to make,"
    },
    {
      "start": 4257.39,
      "end": 4260.11,
      "text": "sometimes I find myself lost in documents"
    },
    {
      "start": 4260.11,
      "end": 4262.47,
      "text": "and then I just like to start experimenting"
    },
    {
      "start": 4262.47,
      "end": 4265.39,
      "text": "and seeing what I can do with it."
    },
    {
      "start": 4265.39,
      "end": 4269.07,
      "text": "And that's how I learned my, the one,"
    },
    {
      "start": 4270.27,
      "end": 4275.27,
      "text": "the one good video I would recommend that I've seen"
    },
    {
      "start": 4275.31,
      "end": 4277.27,
      "text": "is the one that I put up there for the hour"
    },
    {
      "start": 4277.27,
      "end": 4280.03,
      "text": "because you're not gonna spend half a day watching it"
    },
    {
      "start": 4280.03,
      "end": 4281.87,
      "text": "but it's a pretty good wrap up"
    },
    {
      "start": 4281.91,
      "end": 4283.79,
      "text": "and it's pretty up to date, it's only,"
    },
    {
      "start": 4283.79,
      "end": 4285.27,
      "text": "I'm looking at it now it's four,"
    },
    {
      "start": 4285.27,
      "end": 4287.03,
      "text": "came out four or four and a half months ago,"
    },
    {
      "start": 4287.03,
      "end": 4287.87,
      "text": "it looks like."
    },
    {
      "start": 4289.87,
      "end": 4294.07,
      "text": "It goes through that and then just start messing"
    },
    {
      "start": 4294.07,
      "end": 4296.47,
      "text": "with the homework or messing with your own projects"
    },
    {
      "start": 4296.47,
      "end": 4301.12,
      "text": "or that's my way of learning."
    },
    {
      "start": 4301.12,
      "end": 4304.39,
      "text": "Yeah, it makes sense, so."
    },
    {
      "start": 4304.39,
      "end": 4307.15,
      "text": "I think I'm adapting to this course"
    },
    {
      "start": 4307.15,
      "end": 4308.63,
      "text": "because I like the deep dive"
    },
    {
      "start": 4308.63,
      "end": 4312.23,
      "text": "but it's like deep diving plus working with the full day"
    },
    {
      "start": 4312.83,
      "end": 4316.23,
      "text": "and finding that extra hour to get into one of these things."
    },
    {
      "start": 4316.23,
      "end": 4317.43,
      "text": "Okay, I'll have a life."
    },
    {
      "start": 4317.43,
      "end": 4321.83,
      "text": "Yeah, it's all good, I appreciate it."
    },
    {
      "start": 4324.19,
      "end": 4328.43,
      "text": "But sure, so I do want to touch on that feedback"
    },
    {
      "start": 4328.43,
      "end": 4330.47,
      "text": "because that's good feedback to you."
    },
    {
      "start": 4330.47,
      "end": 4333.62,
      "text": "It sounds to be like you wanted a deeper dive."
    },
    {
      "start": 4333.62,
      "end": 4337.62,
      "text": "I think like we jumped into lane chain"
    },
    {
      "start": 4342.53,
      "end": 4344.05,
      "text": "and then started running queries"
    },
    {
      "start": 4344.05,
      "end": 4347.01,
      "text": "and kind of like digging into run feedback, metadata,"
    },
    {
      "start": 4347.01,
      "end": 4347.97,
      "text": "et cetera, et cetera."
    },
    {
      "start": 4347.97,
      "end": 4351.53,
      "text": "And then you did the section with the documentation"
    },
    {
      "start": 4351.53,
      "end": 4354.97,
      "text": "where you walk through, let me go through it here."
    },
    {
      "start": 4354.97,
      "end": 4357.41,
      "text": "Like the rag build out kind of step by step."
    },
    {
      "start": 4357.41,
      "end": 4361.06,
      "text": "I think as I'm saying it out loud,"
    },
    {
      "start": 4361.06,
      "end": 4362.78,
      "text": "I think you actually explain it reasonably well."
    },
    {
      "start": 4362.78,
      "end": 4365.26,
      "text": "Like the, like putting together the chain"
    },
    {
      "start": 4365.26,
      "end": 4366.86,
      "text": "essentially all that works."
    },
    {
      "start": 4366.86,
      "end": 4369.62,
      "text": "It's just like you said, I just need to actually like"
    },
    {
      "start": 4369.62,
      "end": 4372.62,
      "text": "go in and say, okay, what is the retriever actually doing"
    },
    {
      "start": 4372.62,
      "end": 4374.9,
      "text": "diving into the format docs function,"
    },
    {
      "start": 4374.9,
      "end": 4378.06,
      "text": "diving into what runable pass through means, et cetera."
    },
    {
      "start": 4378.06,
      "end": 4378.9,
      "text": "Oh, yeah."
    },
    {
      "start": 4378.9,
      "end": 4382.38,
      "text": "And yeah, we're gonna, and yeah, as like with each class,"
    },
    {
      "start": 4382.38,
      "end": 4385.46,
      "text": "I think I'm spending a lot more time"
    },
    {
      "start": 4385.46,
      "end": 4389.22,
      "text": "defining each term, looking at like what's happening behind"
    },
    {
      "start": 4389.22,
      "end": 4390.22,
      "text": "the scenes with each term."
    },
    {
      "start": 4390.22,
      "end": 4392.38,
      "text": "I think a little bit more next week"
    },
    {
      "start": 4392.38,
      "end": 4394.1,
      "text": "when we start looking at rag is because"
    },
    {
      "start": 4397.34,
      "end": 4398.5,
      "text": "despite the fact that the comments"
    },
    {
      "start": 4398.5,
      "end": 4401.5,
      "text": "are evolving like one of the things that I want to make sure"
    },
    {
      "start": 4401.5,
      "end": 4404.06,
      "text": "is that, you know, I believe there's,"
    },
    {
      "start": 4404.06,
      "end": 4405.62,
      "text": "I believe there's a wide,"
    },
    {
      "start": 4405.62,
      "end": 4407.74,
      "text": "but like a wide stretch of experience here."
    },
    {
      "start": 4407.74,
      "end": 4410.62,
      "text": "There might be a few folks who are still very new"
    },
    {
      "start": 4410.62,
      "end": 4413.58,
      "text": "to Lang Smith, I need an open AI."
    },
    {
      "start": 4413.58,
      "end": 4415.14,
      "text": "So like I want to try to make sure"
    },
    {
      "start": 4415.14,
      "end": 4416.74,
      "text": "that we're all on the same page."
    },
    {
      "start": 4416.74,
      "end": 4418.1,
      "text": "Yeah, and that would be great."
    },
    {
      "start": 4418.1,
      "end": 4421.02,
      "text": "And that category includes me other than using chat"
    },
    {
      "start": 4421.02,
      "end": 4422.66,
      "text": "to be like everyone else I guess."
    },
    {
      "start": 4422.66,
      "end": 4423.5,
      "text": "Perfect."
    },
    {
      "start": 4423.5,
      "end": 4424.78,
      "text": "Okay, so yeah, so I think what I,"
    },
    {
      "start": 4424.78,
      "end": 4426.9,
      "text": "like that's good feedback because what I can do"
    },
    {
      "start": 4426.9,
      "end": 4428.26,
      "text": "is actually make sure to have"
    },
    {
      "start": 4430.14,
      "end": 4433.34,
      "text": "quick column flashcards for each one of the"
    },
    {
      "start": 4434.74,
      "end": 4435.94,
      "text": "like a brand new."
    },
    {
      "start": 4435.94,
      "end": 4436.98,
      "text": "Yeah, that would be excellent."
    },
    {
      "start": 4436.98,
      "end": 4437.42,
      "text": "Actually,"
    },
    {
      "start": 4438.62,
      "end": 4441.46,
      "text": "other logistical question for homework."
    },
    {
      "start": 4441.46,
      "end": 4444.58,
      "text": "Are we only submitting through the post that you're making,"
    },
    {
      "start": 4444.58,
      "end": 4448.26,
      "text": "Jonathan, or is there another route for that?"
    },
    {
      "start": 4448.26,
      "end": 4453.52,
      "text": "So, yeah, the homework, submitting it as optional,"
    },
    {
      "start": 4456.44,
      "end": 4459.92,
      "text": "the feedback a lot of times will be pretty minimal."
    },
    {
      "start": 4459.92,
      "end": 4461.72,
      "text": "And if you've got a specific question,"
    },
    {
      "start": 4461.72,
      "end": 4463.8,
      "text": "would be glad to address that."
    },
    {
      "start": 4463.8,
      "end": 4465.84,
      "text": "But yeah, I'm going to make a thread,"
    },
    {
      "start": 4465.84,
      "end": 4468.12,
      "text": "put the link into the thread,"
    },
    {
      "start": 4468.12,
      "end": 4471.36,
      "text": "and that now your guided projects will be different."
    },
    {
      "start": 4471.36,
      "end": 4473.04,
      "text": "The guided projects will go into the,"
    },
    {
      "start": 4473.04,
      "end": 4476.04,
      "text": "the four guided projects will go into the portal"
    },
    {
      "start": 4476.04,
      "end": 4478.2,
      "text": "and there'll be a specific process for that"
    },
    {
      "start": 4478.2,
      "end": 4483.09,
      "text": "and that'll be more reviewed and more depth."
    },
    {
      "start": 4483.09,
      "end": 4484.17,
      "text": "But yeah, for the homework,"
    },
    {
      "start": 4484.17,
      "end": 4485.65,
      "text": "if you want somebody to look over it,"
    },
    {
      "start": 4485.65,
      "end": 4486.97,
      "text": "if you've got any questions,"
    },
    {
      "start": 4486.97,
      "end": 4488.33,
      "text": "if you just want to throw it out there,"
    },
    {
      "start": 4488.33,
      "end": 4490.69,
      "text": "put it in that thread ideally because that,"
    },
    {
      "start": 4490.69,
      "end": 4493.21,
      "text": "I keep an eye on it and I'll see it there."
    },
    {
      "start": 4493.21,
      "end": 4495.17,
      "text": "And something I was going to throw in"
    },
    {
      "start": 4495.17,
      "end": 4498.05,
      "text": "about what I think you'll find with this course."
    },
    {
      "start": 4498.05,
      "end": 4500.65,
      "text": "So like for me, I've been an engineer for a while,"
    },
    {
      "start": 4500.65,
      "end": 4505.01,
      "text": "I got into AI and ML a while ago."
    },
    {
      "start": 4505.01,
      "end": 4508.45,
      "text": "I come from mostly with my work,"
    },
    {
      "start": 4508.45,
      "end": 4513.45,
      "text": "an ML background and was working with OpenAI and Langchain"
    },
    {
      "start": 4514.69,
      "end": 4516.97,
      "text": "and a little bit of Langsmith."
    },
    {
      "start": 4516.97,
      "end": 4519.49,
      "text": "I've done this course and I think that you'll find"
    },
    {
      "start": 4519.49,
      "end": 4522.65,
      "text": "a lot of the questions during the first weeks."
    },
    {
      "start": 4522.65,
      "end": 4525.29,
      "text": "I'll build up and when we start getting into agents,"
    },
    {
      "start": 4525.29,
      "end": 4527.41,
      "text": "everything kind of falls together"
    },
    {
      "start": 4527.41,
      "end": 4530.61,
      "text": "and it's like, oh, okay, that makes sense"
    },
    {
      "start": 4530.61,
      "end": 4532.25,
      "text": "why we were doing that."
    },
    {
      "start": 4532.25,
      "end": 4537.09,
      "text": "This has been, it'll, because I like the deep dive as well."
    },
    {
      "start": 4537.09,
      "end": 4538.93,
      "text": "I mean, I can't even talk about the times"
    },
    {
      "start": 4538.93,
      "end": 4542.77,
      "text": "I've deep dove into the layers of neural nets"
    },
    {
      "start": 4542.77,
      "end": 4545.69,
      "text": "with pie torches and transformations"
    },
    {
      "start": 4545.69,
      "end": 4549.53,
      "text": "and everything imaginable under the sun,"
    },
    {
      "start": 4549.53,
      "end": 4552.93,
      "text": "just wasting hours and hours and hours doing it."
    },
    {
      "start": 4552.93,
      "end": 4556.43,
      "text": "But with the course, I think you'll see"
    },
    {
      "start": 4556.43,
      "end": 4559.99,
      "text": "in a couple of weeks, everything's starting to come together"
    },
    {
      "start": 4559.99,
      "end": 4562.43,
      "text": "and by the time it gets done,"
    },
    {
      "start": 4562.43,
      "end": 4567.35,
      "text": "that you'll walk away with a good understanding"
    },
    {
      "start": 4567.35,
      "end": 4569.39,
      "text": "of all these technologies and the ability"
    },
    {
      "start": 4569.39,
      "end": 4573.95,
      "text": "to implement the agents and the multi-agent systems"
    },
    {
      "start": 4573.95,
      "end": 4574.95,
      "text": "confidently."
    },
    {
      "start": 4580.29,
      "end": 4582.65,
      "text": "I appreciate the extra context."
    },
    {
      "start": 4582.65,
      "end": 4584.17,
      "text": "I gotta drop, gotta go make dinner"
    },
    {
      "start": 4584.17,
      "end": 4585.41,
      "text": "but I hope you too have an idea."
    },
    {
      "start": 4585.41,
      "end": 4586.25,
      "text": "Call."
    },
    {
      "start": 4586.25,
      "end": 4587.09,
      "text": "Have a good time."
    },
    {
      "start": 4587.09,
      "end": 4589.98,
      "text": "Thanks."
    },
    {
      "start": 4589.98,
      "end": 4591.3,
      "text": "Thank you guys for everything."
    },
    {
      "start": 4591.3,
      "end": 4592.46,
      "text": "See you."
    },
    {
      "start": 4592.46,
      "end": 4593.46,
      "text": "Bye."
    },
    {
      "start": 4593.46,
      "end": 4594.46,
      "text": "Bye."
    },
    {
      "start": 4594.46,
      "end": 4595.46,
      "text": "Go ahead and pause for a while."
    },
    {
      "start": 4595.46,
      "end": 4596.46,
      "text": "Man."
    }
  ],
  "metadata": {},
  "file_size_mb": 241.72914218902588,
  "model_used": "base",
  "timestamp": "2025-08-14 14:56:53"
}