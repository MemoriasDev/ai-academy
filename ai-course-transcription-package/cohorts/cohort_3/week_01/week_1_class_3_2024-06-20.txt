[00:19 - 00:23] that recording, eight o'clock on the dots.
[00:23 - 00:26] All right, the waiting room thing is gonna,
[00:26 - 00:30] gonna be tricky for me for a little bit.
[00:30 - 00:34] All right, folks, thank you for joining.
[00:34 - 00:35] Happy Thursday.
[00:37 - 00:40] Let's, we actually got quite a bit to go over.
[00:40 - 00:42] So it'll probably be a quick,
[00:42 - 00:43] I'm gonna go ahead and assume
[00:43 - 00:44] that most of them are comfortable
[00:44 - 00:46] with getting the environment set up.
[00:46 - 00:49] So it might just be a kind of quick overflow over
[00:50 - 00:51] how to get all those things down.
[00:52 - 00:53] First things first, I'd like to go ahead
[00:53 - 00:56] and set a questions thread on the Slack channel.
[00:56 - 01:01] So if you have any questions that you don't feel like
[01:01 - 01:04] you want to kind of announce
[01:04 - 01:06] to the, you know, you don't want to use your voice,
[01:06 - 01:09] that's totally okay, I highly recommend you
[01:09 - 01:11] share your questions on the questions thread.
[01:11 - 01:14] I'll make sure to keep an eye on the Slack channel.
[01:15 - 01:17] But yeah, if I've missed something in writing,
[01:17 - 01:18] by all means please give me a shout out.
[01:18 - 01:21] I do occasionally miss when messages
[01:21 - 01:22] are coming either from the questions
[01:22 - 01:24] that I had in the Zoom chat or things like that.
[01:24 - 01:26] So generally, I prefer Slack,
[01:26 - 01:28] that's just my big heads amount of mountain.
[01:30 - 01:32] All right, happy Thursday.
[01:32 - 01:33] Welcome back.
[01:33 - 01:35] Let's share my screen.
[01:35 - 01:40] Let's get started and then yeah, that's our first page.
[01:42 - 01:45] All right, so folks, today we are diving into,
[01:45 - 01:47] today's a little bit of a combination
[01:47 - 01:49] of both kind of working and code in VS code
[01:49 - 01:51] and working with a platform.
[01:52 - 01:54] LangSmith is essentially where we're going to be
[01:54 - 01:55] not quite hosting our code,
[01:55 - 01:58] but essentially comparing and letting our code operate
[01:58 - 02:01] and allows to actually evaluate
[02:01 - 02:03] whether our LLMs are operating in a way
[02:03 - 02:05] that's beneficial for us.
[02:05 - 02:07] This is going to be a very introductory first session.
[02:07 - 02:10] The idea is being like introduce you to
[02:10 - 02:14] what LangSmith is able to do behind the scenes
[02:14 - 02:19] and what it can do for you as one of like,
[02:19 - 02:21] as one of the tools that you're going to,
[02:21 - 02:25] that we're going to be using for most of our LLM creation
[02:25 - 02:28] fine tuning experimentation, all of that.
[02:29 - 02:33] Which is kind of, so I know with what speed
[02:33 - 02:37] and what kind of cadence I should be talking about
[02:37 - 02:38] our concepts today.
[02:38 - 02:39] Can I get a thumbs up from folks
[02:39 - 02:46] if you've worked with LangSmith before?
[02:46 - 02:48] And Lang, Lang, Lang, okay, okay.
[02:48 - 02:50] Cool, all right.
[02:50 - 02:51] I'll pick it slow then.
[02:51 - 02:56] With that said, I have all of our,
[02:56 - 02:57] like all of our repo was already shared
[02:57 - 03:00] on the Slack channel, so I'm going to go ahead and ask you
[03:00 - 03:03] to go ahead and fork if you need to
[03:03 - 03:07] or just clone this repository, whichever one you want it.
[03:07 - 03:09] If you don't fork it, it's fine by me.
[03:09 - 03:12] But if you want to go ahead and clone this repository
[03:12 - 03:14] and you can go ahead and see the slides
[03:14 - 03:15] that we're going to be using today
[03:15 - 03:18] as part of the slides folder, there are only eight slides
[03:18 - 03:19] and I'm not going to be doing a lot of swapping
[03:19 - 03:20] between the slides.
[03:20 - 03:24] Just going to be a point where I hit the code element.
[03:24 - 03:26] And a lot of the rest of the classes
[03:26 - 03:29] just going to be me navigating through the LangSmith
[03:29 - 03:34] and my VS code environment and the LangSmith platform.
[03:36 - 03:40] So I won't be coming back too much to the slides itself,
[03:40 - 03:44] but if you still want to recognize where we are
[03:44 - 03:48] in at which portion of the class,
[03:48 - 03:51] just think of the slides as chapters, for example.
[03:51 - 03:54] But I just want to kind of try to minimize
[03:54 - 03:57] a lot of my screen swapping here.
[03:57 - 04:04] So with that said, good job on day one, welcome to day two.
[04:04 - 04:05] And great job on some of the assignments.
[04:05 - 04:08] I know Jonathan's been going over like overseeing
[04:08 - 04:11] some of the home of some of the assignments
[04:11 - 04:13] and some of the some of the submissions
[04:13 - 04:14] you've been making.
[04:14 - 04:15] I've been hearing some really cool stories
[04:15 - 04:17] on the little bit that I've been able to see
[04:17 - 04:18] and we're seeing some really cool stuff.
[04:18 - 04:20] So keep up the wild squirrels.
[04:20 - 04:24] That is an inside jump between Jonathan and me
[04:24 - 04:28] regarding some of the LLM tools that you've been turning in.
[04:28 - 04:29] So let's go ahead and get started.
[04:29 - 04:30] What are we going to be doing today?
[04:30 - 04:31] Or what are we going?
[04:31 - 04:34] What can we expect to be done with at the end of the day?
[04:34 - 04:35] We're going to introduce you to LangSmith.
[04:35 - 04:37] You're going to have a chance to create an account.
[04:37 - 04:41] You're going to have a chance to create your own API key with them.
[04:41 - 04:43] We're going to talk a little bit about how to set it up,
[04:43 - 04:47] how to kind of create your own free account with LangSmith.
[04:47 - 04:51] Now there are a number of tiers available in LangSmith.
[04:52 - 04:55] Kind of can get a little bit too,
[04:55 - 04:58] it can be a little bit pricey after a certain amount of use.
[04:58 - 05:02] So we are also going to showcase and recommend
[05:02 - 05:06] and potentially depending on how our comfort developers
[05:06 - 05:07] operate and how comfortable we're feeling
[05:07 - 05:08] with one tool versus the other.
[05:08 - 05:12] We may end up adopting some of a very similar product
[05:12 - 05:14] called LangFuse.
[05:14 - 05:17] Think of it as an open source version of LangSmith.
[05:17 - 05:19] We're going to do a little bit of coding.
[05:19 - 05:25] We're going to send some LLM code up to the LangSmith platform
[05:25 - 05:26] and we're going to be able to see
[05:26 - 05:28] how those calls operate within LangSmith.
[05:28 - 05:30] And we're going to be able to really manually,
[05:30 - 05:35] very manually access and create some data sets within LangSmith.
[05:35 - 05:37] And hopefully if we have time,
[05:37 - 05:39] I do have a little bit of code, a little bit of the script
[05:39 - 05:47] to use some of the generated content that GPT creates
[05:47 - 05:53] to use as prompts in order to improve the,
[05:53 - 05:57] use the prompts, use the code that GPT creates to prompt
[05:57 - 05:59] and create and improve some of the code
[05:59 - 06:02] we build down around all of this on LangSmith.
[06:02 - 06:03] But what is really like this meant?
[06:03 - 06:07] So essentially a platform of tools and services
[06:07 - 06:10] that is built into the link chain or built with link chain
[06:10 - 06:14] to really help us build a debug and monitor some of the LLMs
[06:14 - 06:18] that we're going to be creating and building applications for.
[06:18 - 06:20] This is a tool that sort of adds,
[06:20 - 06:23] it creates a one stop, one stop place for all
[06:23 - 06:26] of the different steps from tracking, debugging,
[06:26 - 06:29] creating, looking at a history of all of the LLM calls
[06:29 - 06:32] helps us build some insights into some of the systems
[06:32 - 06:35] that are happening behind the scenes.
[06:35 - 06:38] It'll allow us to look at the monitor,
[06:38 - 06:42] the performance of the LLM and really the debugging aspect
[06:42 - 06:46] of LangSmith is actually really powerful.
[06:46 - 06:52] It's really interesting to be able to see every step of code.
[06:52 - 06:56] It's fun to see like it's not necessarily building
[06:56 - 07:00] a kind of error prompting for every little block of code.
[07:00 - 07:02] But to a certain extent, it will tell you
[07:02 - 07:03] where there might be limitations,
[07:03 - 07:07] there were there might be blockers at which particular component.
[07:07 - 07:09] And that was something that I ended up working with today
[07:09 - 07:12] because as we continue to improve some of the curriculum,
[07:12 - 07:14] I was like building it into LangSmith,
[07:14 - 07:20] we were able to see where some of the models were getting hung up.
[07:20 - 07:25] It's also really cool tool for user interaction
[07:25 - 07:28] in the sense of how to score and how to evaluate your results.
[07:28 - 07:29] We're going to see Bob.
[07:29 - 07:35] I'm going to just show you some of the evaluation tools
[07:35 - 07:36] that LangSmith has.
[07:36 - 07:39] We're not going to be spending too much time on that today.
[07:39 - 07:42] But I am going to show you how you can either through yourself
[07:42 - 07:44] or through a fellow team member,
[07:44 - 07:46] you can evaluate some of the responses
[07:46 - 07:49] that your GPT creates.
[07:49 - 07:52] And of course, it's always good for an environment
[07:52 - 07:55] to store your LLM responses.
[07:55 - 07:59] So with that said, any questions before I move forward?
[08:00 - 08:04] So this is pretty much about all we're going to do with the slides.
[08:04 - 08:06] I'm going to go ahead and just start us off
[08:06 - 08:10] by navigating over to the repository.
[08:10 - 08:14] While I was talking, I'm hoping you've had a chance to fork
[08:14 - 08:15] and clone this repository.
[08:15 - 08:17] We're going to go through very similar steps
[08:17 - 08:20] to what we did yesterday.
[08:20 - 08:24] My advice at this point is for the most part,
[08:24 - 08:28] a lot of our packages are going to be very similar.
[08:28 - 08:30] So we are adding a couple of extra requirements
[08:30 - 08:31] to our TXT file.
[08:31 - 08:36] So in this case, we are including both LangSmith and LangFuse.
[08:36 - 08:38] I'm actually going to be incorporating python.end
[08:38 - 08:41] and the LangShave Hub.
[08:41 - 08:44] This, the beautiful suit for, I do recommend
[08:44 - 08:47] you have your own environment set up for that
[08:47 - 08:50] because it can be a little bit tricky sometimes
[08:50 - 08:53] to depending on your versions of a beautiful suit
[08:53 - 08:56] to access with one of these tools.
[08:56 - 09:02] So I just want to make sure, if I need to go through this step,
[09:02 - 09:05] is there anyone who reads through this list of steps
[09:05 - 09:11] and is a little like, I'm not super comfortable with this?
[09:11 - 09:13] You can go ahead and give me a thumbs up.
[09:13 - 09:13] Like no harm, no fault.
[09:13 - 09:15] Otherwise, I'm just going to go straight
[09:15 - 09:17] into assuming that your environment is set up
[09:17 - 09:19] and you're good to go.
[09:19 - 09:22] I see one on, which is a good thing.
[09:22 - 09:25] I'm OK with that.
[09:25 - 09:26] And if you're having trouble with this,
[09:26 - 09:29] OK, you're welcome to go back to class number one.
[09:29 - 09:31] We had a walkthrough of this session.
[09:31 - 09:32] These instructions are super clear.
[09:32 - 09:34] So if you have any trouble with that,
[09:34 - 09:36] give me a call out, give me a shout out.
[09:36 - 09:39] And sorry, I didn't mean to call anyone out specifically there.
[09:39 - 09:41] I actually, that really helps me in terms of feedback.
[09:41 - 09:43] That means like, cool, we can get going.
[09:43 - 09:44] We can get ahead and get moving.
[09:44 - 09:49] So yeah, if you have your environment set up,
[09:49 - 09:55] I'm going to be doing my first initial bit of code in VSCount.
[09:55 - 09:57] I like to use its terminal there in that environment.
[09:57 - 10:00] And I'm going to go ahead and ask you,
[10:00 - 10:02] give you a couple of minutes to kind of settle in.
[10:02 - 10:05] You have any questions?
[10:05 - 10:06] Good.
[10:06 - 10:07] Yeah, no, I get it.
[10:07 - 10:08] No harm, no foul.
[10:08 - 10:11] It is, like I said, I want to know,
[10:11 - 10:14] I want to keep up to the pace that works for you.
[10:14 - 10:16] But here's what I'm going to do first.
[10:16 - 10:18] We're essentially going to start this lecture off
[10:18 - 10:24] with a little bit of a demo of the session itself.
[10:24 - 10:29] And in this case, we actually are calling the,
[10:29 - 10:30] because this is, I think, some of the code
[10:30 - 10:31] from the documentation directly,
[10:31 - 10:40] we're actually calling OpenAI directly from the OpenAI API
[10:40 - 10:43] from its own API instead of, like, directly from Langston.
[10:43 - 10:44] And the reason for that is I do want
[10:44 - 10:47] to be able to just kind of loss over a little bit
[10:47 - 10:49] about what these tools are doing.
[10:49 - 10:52] So the OpenAI is coming directly from OpenAI.
[10:52 - 10:55] I think this is the only instance where we use that.
[10:55 - 10:58] But Langston and Langshane offer a couple of different wrappers
[10:58 - 11:02] and decorators that we're going to be using in our code.
[11:02 - 11:06] Again, this is intended to be able to fit the packages
[11:06 - 11:11] that we're using within the Langshane framework.
[11:11 - 11:15] This is also a lecture, we'll talk a little bit about how
[11:15 - 11:18] the chains actually operate in the Python code.
[11:18 - 11:21] So wrap OpenAI is going to be a wrapper
[11:21 - 11:24] that we're going to be using for accessing the OpenAI
[11:24 - 11:27] within the Langshane framework.
[11:27 - 11:28] Traceable is going to be a decorator
[11:28 - 11:31] that we're going to be using for some of the code
[11:31 - 11:32] in order to commute.
[11:32 - 11:37] Essentially, think of it as a way to aim to Langshanith
[11:37 - 11:42] that an operation is being performed with Langshanith.
[11:42 - 11:44] And we'll be able to see the code that we're running
[11:44 - 11:51] in our local environment on the Langshanith framework.
[11:51 - 11:52] With that said, the code behind this
[11:52 - 11:55] is essentially just going to be creating a decorator
[11:55 - 11:56] over the pipeline.
[11:56 - 12:00] We're just going to create a very simple hello world
[12:00 - 12:06] just going to be asking our LLM to communicate just
[12:06 - 12:08] a very simple prompt.
[12:08 - 12:12] Before we run this command, I do want
[12:12 - 12:14] to make sure that we talk a little bit about making
[12:14 - 12:18] sure that you have your OpenAI keys set up.
[12:19 - 12:22] One more thing to make sure we're set here.
[12:27 - 12:31] And then we'll make sure to create an account in Langshanith
[12:31 - 12:33] after that.
[12:33 - 12:40] So hang on there.
[12:40 - 12:46] So this is PT, which we'll post.
[12:46 - 12:51] And then this is AI school.
[12:51 - 12:55] Let's go to Langshanith, let's do that up.
[12:55 - 12:59] And what am I doing here?
[12:59 - 12:59] Yeah.
[12:59 - 13:10] So what I want to showcase is the environment here.
[13:10 - 13:13] All right, so showcasing a little bit of my keys,
[13:13 - 13:14] these are going to be deleted after today.
[13:14 - 13:18] So if you do just add to showcase those, that's fine.
[13:18 - 13:21] But what are we going to need for today?
[13:21 - 13:23] Is I'm going to need you to have access to the API key
[13:23 - 13:25] for OpenAI.
[13:25 - 13:28] We're going to go to Langshanith and Langshanith
[13:28 - 13:31] to access both the API keys from them.
[13:31 - 13:34] And we're also going to be accessing Langshanith
[13:34 - 13:36] just as a demo process.
[13:36 - 13:41] So once you have that built into your.environment file,
[13:41 - 13:44] you're either welcome to use that in your.environment file.
[13:44 - 13:48] Or you can also use the code from that load environment,
[13:48 - 13:51] or from load.environment to include that
[13:51 - 13:55] in the environment you created.
[13:55 - 13:57] I'm still using, where I should still be using.
[14:01 - 14:05] Second, there.
[14:05 - 14:07] Okay, I'm not actually operating in my environment,
[14:07 - 14:10] so I'll fix that in just a moment.
[14:10 - 14:14] But what we're going to be doing first from here
[14:14 - 14:19] is actually just opening up an instance of Langshanith.
[14:20 - 14:26] So Langshanith is pretty straightforward to open up.
[14:26 - 14:31] Just go over to the, just do a quick search for it.
[14:31 - 14:33] You actually can go into the sign-up session.
[14:33 - 14:35] I've already created an account with BloomTech,
[14:35 - 14:40] but I want you to get first through this section here.
[14:40 - 14:50] This is the first part where we're going to be calling out information.
[14:50 - 14:51] And once you've created an account,
[14:51 - 14:55] usually there's a little bit of a series of prompts.
[14:55 - 14:57] Because your dashboard have got zero projects
[14:57 - 14:59] I've essentially been deleting everything
[14:59 - 15:21] as I've been creating it, but that was there for a second.
[15:21 - 15:24] And from here, you can actually create your own API keys
[15:24 - 15:26] from going over to the settings,
[15:26 - 15:29] and simply create an API key.
[15:29 - 15:32] Now, hopefully you selected your free billing.
[15:32 - 15:35] The cut, we're not really going to be paying
[15:35 - 15:36] for the $39 per month.
[15:39 - 15:42] We've been going hard on Langshanith all month,
[15:42 - 15:46] and I still haven't gotten close to the 5,000 free traces.
[15:46 - 15:51] So we should be able to use this for a significant run
[15:51 - 15:53] of the lectures and class.
[15:53 - 15:57] But if you don't end up having trouble with that,
[15:57 - 16:00] I do want to go ahead and also recommend
[16:00 - 16:03] the Langfuse environment.
[16:03 - 16:08] So Langfuse is a very similar project to Langsmith.
[16:09 - 16:12] It's just intended to be much more open-sourced.
[16:12 - 16:14] You can access the tool by logging in.
[16:14 - 16:15] It's very similar.
[16:15 - 16:18] You can see we played around with this just a little bit
[16:18 - 16:20] on this today, but a lot of the framework
[16:20 - 16:22] is going to be very similar.
[16:22 - 16:23] And a lot of the things you can do here
[16:23 - 16:27] are going to follow a lot of the same processes.
[16:27 - 16:30] It allows you to kind of create that evaluation process.
[16:30 - 16:34] I don't expect it to necessarily seem like no, what's going on.
[16:34 - 16:38] But we'll have a much more in-depth tour in just a moment.
[16:38 - 16:41] But I just wanted to highlight that between these two tools
[16:41 - 16:45] we've got a very similar framework
[16:45 - 16:48] or a similar user experience.
[16:48 - 16:50] So you can go from here to the settings.
[16:50 - 16:53] At this point, it's a little bit different
[16:53 - 16:57] in the sense that for Langfuse, you're actually creating
[16:57 - 16:59] and you're actually going to need both a secret key
[16:59 - 17:01] and a public key.
[17:01 - 17:05] So make sure you have both of those elements set up.
[17:05 - 17:11] Once you've had a chance to do that,
[17:11 - 17:18] your environment should hopefully look a little bit like this.
[17:18 - 17:30] That's not where we're at.
[17:30 - 17:32] But your environment should look something like this.
[17:32 - 17:34] And the only parts that you need to include
[17:34 - 17:37] are the your super secret key elements for OpenAI.
[17:37 - 17:42] That's the one that BloomTech is sharing with you.
[17:42 - 17:44] So that's on Slack, Langshane API key.
[17:44 - 17:47] That's going to be the same one you can use for Langsmith.
[17:47 - 17:50] And your super secret key for Langfuse
[17:50 - 17:52] just make sure to include that in your secret key.
[17:52 - 17:56] But also make sure that your public key is also included there.
[17:56 - 18:00] And I'll give you a minute to get that set up.
[18:00 - 18:04] Really, when it comes to setting up Langfuse Langshane,
[18:04 - 18:06] that's it.
[18:06 - 18:14] It's not easy.
[18:14 - 18:18] So again, not trying to rush there.
[18:18 - 18:20] We're just trying to go over a couple
[18:20 - 18:21] like quite a bit of things
[18:21 - 18:22] and I want to make sure that you're set up.
[18:22 - 18:25] But I'm going to do a quick check-in.
[18:25 - 18:27] You're feeling okay.
[18:27 - 18:31] Let's keep it going.
[18:31 - 18:33] Okay.
[18:33 - 18:34] So with that said,
[18:34 - 18:38] really all that I'm doing with this demonstration
[18:38 - 18:40] is essentially just showcasing what,
[18:40 - 18:42] like how to connect our local computer
[18:42 - 18:44] to the Langsmith framework.
[18:44 - 18:47] So what happens here is that all I'm really doing
[18:47 - 18:52] is essentially creating a decorator
[18:52 - 18:53] that's going to take this function.
[18:53 - 18:56] It's going to create essentially
[18:56 - 19:01] invoke a specific invoke in Langsmith,
[19:02 - 19:04] I'm sorry, the language for me is still stuck
[19:04 - 19:06] on the Langsmith language.
[19:06 - 19:11] But with the base open AI tool,
[19:11 - 19:13] we're simply just creating a chat objects
[19:13 - 19:15] to create a series of messages.
[19:15 - 19:17] Again, this is the role that we created earlier.
[19:17 - 19:21] We're creating a user-based message.
[19:21 - 19:25] The content's going to come from us here.
[19:25 - 19:28] We're going to be using the 3.5 to do the turbo.
[19:28 - 19:31] And then simply put all I'm going to have it do is
[19:31 - 19:34] just do a standard call out world.
[19:34 - 19:39] Let me run a terminal right here in this environment, perfect.
[19:39 - 19:46] And it's going to be Python 3 in class.
[19:46 - 19:49] You get down one level there so that I'm
[19:49 - 19:51] not typing back for much.
[19:51 - 19:53] Yeah, perfect.
[19:53 - 19:58] So Python 3 for me in class,
[19:58 - 20:04] and this one's the Langsmith demo.
[20:04 - 20:08] Come on, I can type.
[20:08 - 20:09] All right, so pretty straightforward.
[20:09 - 20:12] That's how that works, or really all I'm doing is
[20:12 - 20:14] is having it print out the hello world in my environment.
[20:14 - 20:19] But what I want to actually notice,
[20:19 - 20:21] is that if we go now to our Langsmith,
[20:21 - 20:22] we'll see that our project's popped up
[20:22 - 20:27] on my local computer, or on my Langsmith platform.
[20:27 - 20:29] That Langsmith platform, essentially,
[20:29 - 20:31] you can see that I just created a moment ago.
[20:31 - 20:33] We've got a lot of information about the tool
[20:33 - 20:34] that I've just created.
[20:34 - 20:36] I've only run this once.
[20:36 - 20:38] No errors.
[20:38 - 20:41] Pretty standard number of tokens, a little bit of information.
[20:41 - 20:45] This is so inexpensive on my side, but it's essentially
[20:45 - 20:49] calling the pipeline that I've created.
[20:49 - 20:51] Again, this is under the trace pipeline
[20:51 - 20:53] that we built a second ago.
[20:53 - 20:55] Let me close this up as I'm not going to.
[20:55 - 20:57] I might not, I may need that again in a second.
[20:57 - 20:59] But all we're doing is essentially
[20:59 - 21:02] telling that we ran this code within this environment.
[21:02 - 21:06] And there's a lot of information that we can get from it.
[21:06 - 21:08] It can essentially tell us what the input was,
[21:08 - 21:13] what the output from the GBT framework returned.
[21:13 - 21:14] You click on this.
[21:14 - 21:16] It's essentially just a little bit more
[21:16 - 21:18] additional data, including metadata
[21:18 - 21:24] about the call and the output itself.
[21:24 - 21:25] Pretty straightforward, right?
[21:25 - 21:27] Nothing too complex from that.
[21:27 - 21:30] But this is where things start.
[21:30 - 21:33] If we know that our LLMs are being recorded somewhere,
[21:33 - 21:36] it means that we can now do a lot more with this.
[21:36 - 21:39] We can essentially take a look at how we can add this
[21:39 - 21:40] to a data set.
[21:40 - 21:42] We'll talk a little bit more about the annotation queue.
[21:42 - 21:44] But the information behind this is
[21:44 - 21:46] that we are now starting to create a framework
[21:46 - 21:51] where we can either run it again, perhaps
[21:51 - 21:53] with a different message.
[21:53 - 21:54] Hello folks.
[21:54 - 21:57] I don't know, we'll do that if we wanted to.
[21:57 - 21:58] Pretty straightforward.
[21:58 - 22:03] And it's going to be recorded inside the call
[22:03 - 22:04] as its own separate call.
[22:04 - 22:06] But it's still going to be part of the same project.
[22:06 - 22:11] Because we traced this, this particular script
[22:11 - 22:13] as part of this default, this project
[22:13 - 22:16] that we just happened to name the fault.
[22:16 - 22:19] And there's additional metadata about that.
[22:19 - 22:24] So the same thing will happen with Langfews.
[22:24 - 22:29] So in this case, we're using again, a very similar operator
[22:29 - 22:34] or excuse me, decorator to the traceable decorator
[22:34 - 22:36] that exists within LangSmith.
[22:36 - 22:38] But the observer decorator is essentially
[22:38 - 22:40] going to be built about around this function
[22:40 - 22:44] that's going to be using the OpenAI chat create framework.
[22:44 - 22:47] Again, this is all exactly the same thing
[22:47 - 22:53] as we did with the LangSmith code.
[22:53 - 22:55] We're just going to pull the content directly.
[22:55 - 22:57] The decorator is going to look at the function itself,
[22:57 - 22:59] and it's going to return that main story
[22:59 - 23:01] or the main story function that we created here.
[23:01 - 23:03] And again, we're just asking it's
[23:03 - 23:05] OK, you're a great storyteller.
[23:05 - 23:09] Fill out the rest of the content here
[23:09 - 23:10] and what would that look like?
[23:10 - 23:15] So if I were to run this code instead of LangSmith,
[23:15 - 23:20] just going to take Langfews demo.
[23:20 - 23:21] It's got a second.
[23:21 - 23:23] Looks like it ran.
[23:23 - 23:33] If I go over to Langfews, I should have projects.
[23:33 - 23:37] Yeah.
[23:37 - 23:39] Could you do?
[23:39 - 23:42] Let's see.
[23:42 - 23:43] OK.
[23:43 - 23:45] So this is my full of the trace.
[23:45 - 23:46] There you go.
[23:46 - 23:47] Let's look it up.
[23:47 - 23:50] Here we go.
[23:50 - 23:50] Yep.
[23:50 - 23:52] So here's that.
[23:52 - 23:54] I can click on the trace detail.
[23:54 - 23:58] And it's all essentially very similar.
[23:58 - 23:59] Except this one's open source.
[23:59 - 24:02] It's a little bit less expensive than LangSmith.
[24:02 - 24:06] So everything's just kind of organized a little bit different.
[24:06 - 24:08] So we just wanted to introduce both tools
[24:08 - 24:13] to give you the chance to select your preferred path to work with.
[24:13 - 24:16] And from there, you can essentially
[24:16 - 24:20] operate from that environment.
[24:20 - 24:22] Any questions in this case?
[24:22 - 24:23] You don't need to use both.
[24:23 - 24:24] You're not going to be expected to use both.
[24:24 - 24:26] Most of the material as it's built so far
[24:26 - 24:27] is built using LangSmith.
[24:27 - 24:30] So it's up to you if you have a preference.
[24:30 - 24:31] But if you're going to be putting your own credit card down,
[24:31 - 24:33] and that's a budget as a concern,
[24:33 - 24:38] Langfews is another option.
[24:38 - 24:44] Moment there to see if any questions have come through.
[24:44 - 24:45] OK, wait, one question.
[24:45 - 24:46] Oh, hang on.
[24:46 - 24:47] Next session, small nifty.
[24:47 - 24:48] Irish is quite craft.
[24:48 - 24:50] Ooh, thank you.
[24:50 - 24:54] Up the resolution, Luke, are we talking about?
[24:54 - 24:55] Alex, thank you for that feedback.
[24:55 - 25:00] Sorry that I took me a second to actually look at it.
[25:00 - 25:01] It's no rush.
[25:01 - 25:03] It's fine for this session.
[25:03 - 25:04] Oh, OK.
[25:04 - 25:05] Or better?
[25:05 - 25:06] Yeah, perfect.
[25:06 - 25:08] Yeah, man, I can see it.
[25:08 - 25:10] Yeah, and again, if I miss a message,
[25:10 - 25:13] which is a thing that happens, please call me out.
[25:13 - 25:16] That happens sometimes.
[25:16 - 25:19] I'm not shy.
[25:19 - 25:24] OK.
[25:24 - 25:27] Cool, all right, so no questions about Langfews.
[25:27 - 25:29] Let's go ahead and I'm going to go ahead for myself.
[25:29 - 25:31] I'm going to close up Langfews because most of the rest
[25:31 - 25:38] of the content is going to be built on top of Langfews' tool.
[25:38 - 25:41] And that was for later.
[25:41 - 25:44] I'm going to skip the prompting demo for right now
[25:44 - 25:47] because that's going to make sense in a little bit
[25:47 - 25:50] in a little bit for the next bit.
[25:50 - 25:54] So I'm going to pull up the slides once more.
[25:54 - 25:57] The slides I've managed to actually close up.
[25:57 - 26:01] Sorry about that.
[26:01 - 26:03] Yeah.
[26:03 - 26:06] Because we've tested both of these tools.
[26:06 - 26:07] This is Langfews.
[26:07 - 26:09] We actually did it through this.
[26:09 - 26:11] We're going to be spending more time next week
[26:11 - 26:12] talking about Rags in general.
[26:12 - 26:15] But I do want to essentially address a little bit
[26:15 - 26:19] about how you can use Rags within Langsmiths environment
[26:19 - 26:23] to kind of see the different steps that we've just talked about.
[26:23 - 26:26] How do you evaluate the multiple steps
[26:26 - 26:28] that kind of go through?
[26:28 - 26:32] How you can eventually evaluate the individual costs
[26:32 - 26:33] of a particular process.
[26:33 - 26:36] Like you could actually monitor where a specific element
[26:36 - 26:38] is potentially created.
[26:38 - 26:40] So I'm going to be guiding the next part
[26:40 - 26:43] of this lecture with these questions in mind.
[26:43 - 26:46] But I don't want to have necessarily the slides open
[26:46 - 26:48] for this whole time.
[26:48 - 26:52] But I am going to ask that if you want to follow along,
[26:52 - 26:54] if you want to see for yourself what this looks like
[26:54 - 26:59] in the Langsmith environment, check out the notebook format.
[26:59 - 27:01] And I created this in a notebook format simply
[27:01 - 27:04] because I want to be able to talk a little bit about the couple
[27:04 - 27:08] of different parts of the code here.
[27:08 - 27:14] So again, some of this we'll talk more about next week.
[27:14 - 27:20] A lot of our tools are going to be saved into the vector databases
[27:20 - 27:23] that we're going to be using as a local database called
[27:23 - 27:24] Chroma, more on that later on.
[27:24 - 27:27] But essentially all of these come from the Langchain package,
[27:27 - 27:29] including the Langchain community.
[27:29 - 27:31] Again, Langchain community is essentially
[27:31 - 27:34] where users can submit their own tools
[27:34 - 27:36] or their own frameworks, models, things like that
[27:36 - 27:41] in order to create different scrapers, web loaders,
[27:41 - 27:45] interpreters of like beautiful text, for example,
[27:45 - 27:48] which is web-based loader, like I don't know about you,
[27:48 - 27:50] but once I started using this, like BS4,
[27:51 - 27:57] it just doesn't, it works so well.
[27:57 - 28:00] If you remember in the last class, we were adding dot content
[28:00 - 28:03] at the end of all of our LLM calls.
[28:03 - 28:06] String out parser is essentially Langchain's alternative
[28:06 - 28:07] to that.
[28:07 - 28:09] And again, this will be more about it next week.
[28:09 - 28:12] But I do want to be familiar with that what this does
[28:12 - 28:14] or what String out parser does essentially just
[28:14 - 28:19] takes the output or the text-based output of the code itself.
[28:19 - 28:22] We'll be embedding all of these tools, again,
[28:22 - 28:25] that's going to be getting back into Chrome itself.
[28:25 - 28:27] The other tool that you may have heard for,
[28:27 - 28:29] you may have been familiar with this Python gun,
[28:29 - 28:32] but that's what we're going to be working with here.
[28:32 - 28:34] And again, recursive character text
[28:34 - 28:38] litter, all of this are just cleaning tools.
[28:38 - 28:39] Make sure that works.
[28:39 - 28:41] So what I'm going to be taking is I'm
[28:41 - 28:47] going to be accessing a specific document
[28:47 - 28:51] from Lillian Wang from this particular GitHub,
[28:51 - 28:55] just to showcase where we're getting our notes from.
[28:55 - 29:00] This is a blog that's going to have pretty much instructions
[29:00 - 29:04] on how to create autonomous agents or LLM-powered autonomous
[29:04 - 29:06] agents.
[29:06 - 29:08] We'll talk, feel free to read through this,
[29:08 - 29:09] but we're not actually going to be spending too much time
[29:09 - 29:10] on the blog.
[29:10 - 29:13] We're actually just going to have our LLM take all of this
[29:13 - 29:19] and summarize it for us and create it in a framework
[29:19 - 29:25] that I can then build an agent or a mini LLM that's
[29:25 - 29:28] going to take the data that it learned from looking
[29:28 - 29:32] through this document to return its own answers for us.
[29:32 - 29:36] So there's a lot of text here, again, not really worth our
[29:36 - 29:41] time to read through it, but we can actually use some
[29:41 - 29:46] of the LLM-chain properties, in this case, GBT3.5,
[29:46 - 29:52] to access that website, load it, essentially re-graded into
[29:52 - 29:56] a SUP object from beautiful SUP, which is going to take
[29:56 - 29:58] some of the contents of none of the images,
[29:58 - 30:01] and I want to load it into a document.
[30:01 - 30:04] I'm going to take all of the text from that document,
[30:04 - 30:07] and I want to split it into individual documents that's
[30:07 - 30:09] essentially going to be what I'm going to be embedding
[30:09 - 30:13] into the, essentially, I'm going to be embedding all of that text
[30:13 - 30:15] into that interpretable format.
[30:15 - 30:17] So this is doing it for me.
[30:17 - 30:19] The code is pretty straightforward.
[30:19 - 30:23] And then I'm going to be taking from the Community Hub,
[30:23 - 30:26] essentially the same network where you can look at different
[30:26 - 30:29] models, and I want to essentially be able to create a
[30:29 - 30:36] prompt based off of that document.
[30:36 - 30:38] This last function is essentially going to take all of that
[30:38 - 30:40] content formatted into a document.
[30:40 - 30:44] And I'm like, this might be some syntax that you may not
[30:44 - 30:47] have seen, even if you've been working with Python for a while.
[30:47 - 30:51] This is usually the like, and signifier, if you're trying
[30:51 - 30:56] to compare two values, in LLM-chain, what this tool does is
[30:56 - 30:59] essentially creates that step-by-step process in the chain.
[30:59 - 31:02] And I'll showcase another example in just a moment so that
[31:02 - 31:04] we can kind of take it slow.
[31:04 - 31:07] But what our tool is going to be doing is essentially going to
[31:07 - 31:10] be taking the retriever within the context that we created
[31:10 - 31:14] above, along with the documents as we formatted.
[31:14 - 31:16] And that the question is going to be processed through a
[31:16 - 31:18] multiple pass through, essentially going to be
[31:18 - 31:22] interpreting all of the content on all the embedded contents.
[31:22 - 31:26] Finally, like after we created the prompt object, this is
[31:26 - 31:32] as it was pulled from one of the like, the prompt that
[31:32 - 31:36] we're creating early on, I can actually showcase what
[31:36 - 31:40] that looks like for us.
[31:40 - 31:49] And that prompt, as it was built out, is simply a chat
[31:49 - 31:53] prompt template, essentially the prompt that we, like, if
[31:53 - 31:55] you remember from last last, when we talked about like, hey,
[31:55 - 31:57] I want you to structure my answer.
[31:57 - 32:00] I want your answers to sort of look like this.
[32:00 - 32:04] So the prompt itself is going to look like, let me just scroll
[32:04 - 32:04] through this.
[32:04 - 32:07] You're an assistant for question answering tasks.
[32:07 - 32:10] Use the following pieces of retrieved context to answer
[32:10 - 32:11] the question.
[32:11 - 32:13] If you don't know the answer, just say you don't know, but
[32:13 - 32:15] three cents and maximum keep the answer concise.
[32:15 - 32:19] This is something that a different user has built.
[32:19 - 32:23] And again, this is all essentially going to be what it
[32:23 - 32:26] returns for the document that we created or that we move
[32:26 - 32:28] from online.
[32:28 - 32:32] So when we created that prompt, we're
[32:32 - 32:35] accessing, we're telling the prompt to, we're
[32:36 - 32:41] telling our LLM to build answers using that prompt.
[32:41 - 32:45] And finally, the last step is going to be to, like, to
[32:45 - 32:51] output the answer or the answer that the LLM invoked as
[32:51 - 32:53] essentially a string text.
[32:53 - 32:57] So this case, what I'm trying to do is take all of the
[32:57 - 33:04] information from this document and tell me what is task
[33:04 - 33:08] to composition for the record.
[33:08 - 33:11] This is something that I technically advise with folks
[33:11 - 33:15] when I've been working for them like longer class sessions.
[33:15 - 33:17] I grew up in Puerto Rico, English is actually my second
[33:17 - 33:18] language.
[33:18 - 33:21] So there's a B words that occasionally like, I don't
[33:21 - 33:22] pronounce correctly.
[33:22 - 33:23] You'll free to call me out.
[33:23 - 33:27] It's always a fun time.
[33:27 - 33:28] But there are some words that I'm going to look at
[33:28 - 33:30] and I'm like, to composition, the composition never
[33:30 - 33:32] quite sure how it's pronounced.
[33:32 - 33:33] But yeah, so the answer we get from this is tasked
[33:33 - 33:36] composition together like, OK, we're familiar with that
[33:36 - 33:36] part.
[33:36 - 33:37] We understand what happens.
[33:37 - 33:41] We can expect that the answer from that is going to be
[33:41 - 33:46] built from the, is going to be built in their summer from
[33:46 - 33:48] from the document that it returned.
[33:48 - 33:50] That's not the point of what we're trying to do.
[33:50 - 33:55] We're trying to see how this worked within the framework
[33:55 - 33:57] of our LLAMG Smith environment.
[33:57 - 34:00] So that ran properly.
[34:00 - 34:08] We should have built, let's see where that put.
[34:08 - 34:09] Yep, there we go.
[34:09 - 34:12] Inside our default, inside our default process, you'll see
[34:12 - 34:16] this runable sequence object.
[34:16 - 34:19] And here, we do a dropdown.
[34:19 - 34:21] We're actually beginning to see all of the different
[34:21 - 34:25] tasks that we just created, including that final answer,
[34:25 - 34:29] like that final answer, what is tasked composition.
[34:29 - 34:30] And we can start to see that there are all of the
[34:30 - 34:34] different steps are listed for us, including but not
[34:34 - 34:39] limited the input that the model essentially decided to
[34:39 - 34:43] incorporate what is tasked composition and the context of
[34:43 - 34:47] what it built, the, like, what context it actually used to
[34:47 - 34:49] create the answer.
[34:49 - 34:51] The prompt template, remember what we said earlier, is
[34:51 - 34:59] essentially, how to create, where is that?
[34:59 - 35:02] Yeah, how to create what the, like, what, like, what that
[35:02 - 35:04] content would look like.
[35:04 - 35:07] And the chat, like, the chat, the, the, the, the year we got.
[35:07 - 35:08] This is what it was looking for.
[35:08 - 35:11] So this is what it would look like if we were answering this
[35:11 - 35:13] within a chat, open AI framework.
[35:13 - 35:15] This was us answering the question.
[35:15 - 35:20] There is the prompt that we hold from the community light
[35:20 - 35:22] from the length and community hub.
[35:22 - 35:25] And it essentially was able to create and output that
[35:25 - 35:28] within that specific, within that specific prompt
[35:28 - 35:29] structure.
[35:29 - 35:33] At the string out parser, like we discussed earlier,
[35:33 - 35:36] was essentially being able to take all of that information and
[35:36 - 35:40] remove all of the additional data that metadata and call
[35:40 - 35:42] that information as a string.
[35:42 - 35:45] So what I like about this is that it's already beginning to
[35:45 - 35:47] tell you and create, give you a lot of additional information
[35:47 - 35:49] about the tool itself.
[35:49 - 35:54] We can look at how long it took 1.54 seconds to run from
[35:54 - 35:55] beginning to end.
[35:55 - 35:59] We can look at other elements, including how much did
[35:59 - 36:05] each particular step where we had to invoke the open AI
[36:05 - 36:08] processes or the, like the parts that cost money, we can
[36:08 - 36:11] actually begin to incorporate that.
[36:11 - 36:14] So this guy's not, you know, negligibly expensive.
[36:14 - 36:16] But of course, it's going to be much more expensive than
[36:16 - 36:19] we're incorporating additional information.
[36:19 - 36:24] The documents that we pulled again were pulled from the,
[36:24 - 36:26] from the Lillian Wing website.
[36:26 - 36:30] And that can be determined based off of the,
[36:30 - 36:32] based off of this tool.
[36:32 - 36:36] So we can see that as part of our chat prompt template.
[36:36 - 36:39] We can see that from where we got the information itself.
[36:39 - 36:42] So it's essentially seeing that it is built to follow the
[36:42 - 36:46] same steps that we built in our local environment.
[36:46 - 36:50] And that context essentially is created here in our code
[36:50 - 36:54] from the very beginning.
[36:54 - 36:57] So these components are essentially intended for us to then
[36:57 - 37:00] make certain choices as to what we want to do with it.
[37:00 - 37:02] Like, is there a specific test?
[37:02 - 37:04] Is there a specific output that we're interested in working
[37:04 - 37:08] with a little bit more, a little bit more fully?
[37:08 - 37:11] Perhaps that's going to be the next thing we're going to be
[37:11 - 37:13] talking about in just a moment.
[37:13 - 37:17] So if I'm the last question is, this is a question I'm going
[37:17 - 37:21] to pose for you, given your ability to kind of explore this
[37:21 - 37:25] or your, like, from what we're seeing here,
[37:25 - 37:27] do you get the sense that you're able to, can you determine
[37:27 - 37:33] what the response should I put this question?
[37:33 - 37:37] How do I find this question?
[37:37 - 37:39] What are some of the methods?
[37:39 - 37:41] What are some of the methods?
[37:41 - 37:43] What comes to mind as far as usefulness for something
[37:43 - 37:46] like this, particularly if you're working
[37:46 - 38:00] within a team dynamic?
[38:00 - 38:14] This is a leading question to some extent.
[38:14 - 38:16] I don't have a good sense of this tool yet.
[38:16 - 38:19] But if I had to make an assumption, if different parts of the
[38:19 - 38:23] team are working on different parts of the overall process,
[38:23 - 38:27] this gives you that granularity to see what exactly each
[38:27 - 38:29] piece is doing, how it's configured, how it's performing,
[38:29 - 38:31] how much it costs, et cetera, et cetera.
[38:31 - 38:34] So I guess it gives you a better cross functional visibility.
[38:34 - 38:36] But again, that's for that a lot of context.
[38:36 - 38:37] For sure.
[38:37 - 38:39] And what happens if, you know, for another example,
[38:39 - 38:41] perhaps one day if you're not a fan of like,
[38:41 - 38:44] what if you have someone who's suggesting that open AI maybe
[38:44 - 38:46] that that enthropic may be a better model
[38:46 - 38:49] to use in a specific scenario?
[38:49 - 38:50] What is this useful for?
[38:50 - 38:52] Well, like you can actually come up with like a particular,
[38:52 - 38:55] you can create different projects that actually compare,
[38:55 - 38:58] like that you can actually compare the different models
[38:58 - 39:01] at the different steps the model is taking.
[39:01 - 39:02] So you can actually monitor speed.
[39:02 - 39:04] You can actually monitor price.
[39:04 - 39:08] You can actually monitor a lot of like back granularity
[39:08 - 39:10] that you're talking about Ryan can essentially be incorporated
[39:10 - 39:13] with tools like this to then compare what's the best tool
[39:13 - 39:14] for the job?
[39:14 - 39:18] Any other comments or thoughts to face?
[39:18 - 39:20] I'm guessing that also really helps you
[39:20 - 39:22] understand if different pieces are built
[39:22 - 39:24] by different team members, the place and where they touch
[39:24 - 39:26] and how they may be interacting incorrectly there?
[39:26 - 39:28] For sure.
[39:28 - 39:30] And yeah, with essentially being a part of a team
[39:30 - 39:32] just kind of sharing that language,
[39:32 - 39:35] like that language, like that language key,
[39:35 - 39:37] you can essentially begin to create a specific set,
[39:37 - 39:40] like you can essentially begin to really dive
[39:40 - 39:43] into the nitty gritty of like what your model is doing.
[39:43 - 39:45] And this is essentially how you begin
[39:45 - 39:46] to build a successful model.
[39:46 - 39:48] And this is essentially step one.
[39:48 - 39:49] Of course, we're going to be diving,
[39:49 - 39:51] we're going to be spending a lot of time here,
[39:51 - 39:54] but I just want you to kind of take this class,
[39:54 - 39:57] start kind of flicking around.
[39:57 - 39:59] There's not a whole lot to click around.
[39:59 - 40:01] The next bit that we're going to be talking about right now
[40:01 - 40:05] is going to be a little bit more in depth.
[40:05 - 40:07] But yeah, that's about it.
[40:07 - 40:09] And again, next week we'll talk a little bit more
[40:09 - 40:11] about Rags in detail so that we can kind of talk
[40:11 - 40:15] a little bit about how those documents get embedded,
[40:15 - 40:17] how those documents work behind the scenes.
[40:17 - 40:20] So, that doesn't quite yet.
[40:20 - 40:24] Let's talk a little bit, not that.
[40:24 - 40:27] Let's talk about one more thing here.
[40:27 - 40:30] As in order for you to do that your specific homework,
[40:30 - 40:33] there's one of the elements that I started the class
[40:33 - 40:35] talking about, and one of the comments
[40:35 - 40:39] that really usually comes up with this sort of conversation.
[40:39 - 40:44] It's like, hey, how do I know if my LLM is working?
[40:44 - 40:49] How do I know for a fact that my output
[40:49 - 40:51] is providing the right answer for my customers,
[40:51 - 40:54] for my clients, for my team?
[40:54 - 41:01] Really, how do you evaluate those specific responses?
[41:01 - 41:03] And so, there's a couple of different answers to that.
[41:03 - 41:06] One, you have both automated methods
[41:06 - 41:11] and where you can essentially determine whether the model
[41:11 - 41:15] seems to be correctly identifying a particular value.
[41:15 - 41:17] If it's correctly identifying a specific label,
[41:17 - 41:19] that's specifically if you're working with labeled data set.
[41:19 - 41:24] But what if your data is necessarily
[41:24 - 41:28] like a value that can be easily labeled?
[41:28 - 41:32] What if it's something like, for example, a terrible joke
[41:32 - 41:34] or what if it's something like a specific assessment
[41:34 - 41:38] or a particular think of it as maybe a creative opinion
[41:38 - 41:41] or even like, I don't know, a lot of the work I do,
[41:41 - 41:45] I've been doing recently has been like trying to create
[41:45 - 41:50] tools that work best with posting on social media in a way
[41:50 - 41:54] that includes variety, creativity and different values.
[41:54 - 41:58] So, how do you evaluate what makes a good social media post?
[41:58 - 42:00] For example, the answer to that's often
[42:00 - 42:02] similar complicated, there's some few metrics
[42:02 - 42:05] you can evaluate from there, but beyond that,
[42:05 - 42:06] let's kind of assess this within the context
[42:06 - 42:11] of what makes a good dad joke for our purposes right now.
[42:11 - 42:16] Well, it's whether your kids like you enough
[42:16 - 42:18] to laugh at your jokes, I don't know.
[42:18 - 42:20] What's the metric we want to use there?
[42:20 - 42:22] Well, right now, the answer or the short answer
[42:22 - 42:24] that I'm sort of like jumping around to is that
[42:24 - 42:27] we can actually incorporate our own opinion
[42:27 - 42:30] or our own evaluation with lagsmith.
[42:30 - 42:33] And if we want to do that manual evaluation,
[42:33 - 42:35] lagsmith allows us the chance to do that.
[42:35 - 42:39] It also allows us the chance to create some automated processes
[42:39 - 42:41] to evaluate those specific tools.
[42:41 - 42:45] And we're talking more about that automated evaluation
[42:45 - 42:46] a little bit down the line right now.
[42:46 - 42:49] I just want to showcase, how do you incorporate
[42:49 - 42:53] a specific output from an LLM into data value
[42:53 - 42:55] or a data set that you can store?
[42:55 - 42:58] And then you can create that evaluation
[42:58 - 43:00] within lagsmiths framework.
[43:00 - 43:05] So I'm going to go over to the lagsmith.jokes.py tool,
[43:05 - 43:07] going back to the chat-open AI tool
[43:07 - 43:10] from lag chain itself.
[43:10 - 43:13] This is these other packages should be fairly familiar.
[43:13 - 43:15] I don't actually need this,
[43:15 - 43:17] but if you want to incorporate your code
[43:17 - 43:21] into your environment, that's absolutely fine.
[43:21 - 43:25] But all I'm doing here is asking open AI
[43:25 - 43:28] to create five dad jokes.
[43:28 - 43:31] And I want those dad jokes to be in story format.
[43:31 - 43:32] Excuse me.
[43:32 - 43:36] And I'm just going to have that run behind the scenes
[43:36 - 43:41] in class examples that is lagsmith dad joke.
[43:41 - 43:44] So we run that on its own.
[43:44 - 43:48] And that'll take a second or two.
[43:48 - 43:51] It's running in the lagsmith environment.
[43:51 - 43:55] I'm going to close that up here and close this up.
[43:55 - 43:57] Not going to need that.
[43:57 - 43:59] That should be done running.
[43:59 - 44:07] All right, so I took about 10 seconds.
[44:07 - 44:09] Took about 589 tokens.
[44:09 - 44:13] Each joke took about 2.27 seconds to run.
[44:13 - 44:16] And we can actually start to evaluate the jokes
[44:16 - 44:17] directly from here.
[44:17 - 44:19] If you click on each or particular object,
[44:19 - 44:20] we have one joke.
[44:20 - 44:21] Jokes should be in story format.
[44:21 - 44:23] That's about a time of dad to send tickets into the zoo, blah, blah, blah.
[44:23 - 44:25] OK, it's probably a terrible joke.
[44:25 - 44:26] Let's look at this next joke.
[44:26 - 44:27] It's a little bit long when it's about 10.
[44:27 - 44:30] So there's like three paragraphs out about the not actually
[44:30 - 44:31] reading through those jokes.
[44:31 - 44:32] They're probably terrible.
[44:32 - 44:35] But this one's a little bit longer.
[44:35 - 44:38] OK, this was a waste of time.
[44:38 - 44:38] World their eyes.
[44:38 - 44:42] OK, and this one's a lot shorter.
[44:42 - 44:46] So I'm going to ask you to kind of help me out a little bit
[44:46 - 44:48] for this next step, because I'm going
[44:48 - 44:51] to go ahead and try to evaluate these jokes by commending.
[44:51 - 44:53] We're not going to do any specific metric.
[44:53 - 44:58] But the way you can begin to create and create that manual evaluation,
[44:58 - 45:00] there's three tools up here.
[45:00 - 45:02] There's the annotate tool.
[45:02 - 45:05] Essentially means that you can make some create.
[45:05 - 45:08] You can essentially make some adjustments to the input
[45:08 - 45:11] and the output of the LLM responses themselves.
[45:11 - 45:15] We have the ability to incorporate these objects into a data set.
[45:15 - 45:17] We'll get to that in just a moment.
[45:17 - 45:19] But I want to be able to add each one of these jokes
[45:19 - 45:21] to an annotation queue.
[45:21 - 45:24] So I can just show you guys what we're going to do here.
[45:24 - 45:27] So I'm going to go ahead and select that.
[45:27 - 45:29] I haven't created any particular queue yet.
[45:29 - 45:32] So let's go ahead and just to show you what that looked like.
[45:32 - 45:34] I'm going to click on annotation queue.
[45:34 - 45:37] I'm going to click on new to create a new queue.
[45:37 - 45:45] And I'm going to name this, see if it's not letting me detect.
[45:45 - 45:46] Here we go.
[45:46 - 45:48] OK, here we go.
[45:48 - 45:53] Yeah, perfect.
[45:53 - 45:59] I'm going to name it here again, add annotation queue, new.
[45:59 - 46:05] A list, a list of terrible jokes.
[46:05 - 46:06] And I need a name.
[46:06 - 46:13] So let's call this an annotation joke judgment.
[46:13 - 46:16] I don't know, doing a little spicy there.
[46:16 - 46:18] That's all we need.
[46:18 - 46:19] I can also create a data set that I'm
[46:19 - 46:23] going to be adding these tools if I feel like the joke actually
[46:23 - 46:29] fits the standard of what I want to fill in my particular
[46:29 - 46:32] to fill in to create essentially a model that
[46:32 - 46:35] makes the best dad jokes that we as a group
[46:35 - 46:37] are potentially like working with.
[46:37 - 46:41] So this is going to be my selection for joke judgment.
[46:41 - 46:43] I'm going to create a new data set.
[46:43 - 46:46] We can actually upload already built in data sets.
[46:46 - 46:46] We can name this.
[46:46 - 46:54] This is going to be my selected jokes, the jokes,
[46:54 - 46:57] and for the description, I'm just adding some description for here.
[46:57 - 47:03] And this is just the jokes that made the cut.
[47:03 - 47:06] And we have three different data set times.
[47:06 - 47:10] We have key value pairs, essentially, the input output type objects.
[47:10 - 47:14] We can actually also include different types of frameworks
[47:14 - 47:18] for this type of, for this type of the value.
[47:18 - 47:21] They're essentially, they're similar in structure.
[47:21 - 47:23] But for all I'm trying to do here
[47:23 - 47:28] is essentially create a chat-based dictionary type object.
[47:28 - 47:32] So the input is going to be the joke that we're
[47:32 - 47:36] asked or the prompt that we're asking the AI to create.
[47:36 - 47:38] And the joke will be whatever the output is.
[47:38 - 47:41] So in this case, it's just kind of a chat-based conversation.
[47:41 - 47:43] So that's what I'm going to be creating.
[47:43 - 47:45] This is going to be my default data set.
[47:45 - 47:49] Joke judgment, and I'm going to create an evaluator.
[47:49 - 47:53] So that's going to be, we've added one object to the annotation tool.
[47:54 - 47:57] I'm just going to go ahead and do that for the rest here.
[47:57 - 47:59] And this is a little bit manual.
[47:59 - 48:01] There's easier ways to do this.
[48:01 - 48:04] But I do just want to showcase those individual steps.
[48:04 - 48:07] Just kind of click and click.
[48:07 - 48:09] And then I can then go to the annotation tool.
[48:09 - 48:11] I'm going to get right there for a second.
[48:11 - 48:12] Sorry.
[48:12 - 48:17] And as you can see here, this is our joke judgment evaluator tool.
[48:17 - 48:20] And the way that this is going to be evaluated in our case,
[48:20 - 48:23] because we're creating this in a kind of manual user
[48:23 - 48:25] like the human is going to be the person who's evaluated,
[48:25 - 48:28] whether this prompt makes sense to use.
[48:28 - 48:32] We can then have a certain set of tools
[48:32 - 48:37] to determine whether I want this to be part of my data set object.
[48:37 - 48:41] So we can either add this back to our data set.
[48:41 - 48:47] We can evaluate this as saying like this joke is super proper.
[48:47 - 48:49] And then we can actually make an evaluation
[48:49 - 48:52] as to whether this input seems correct.
[48:52 - 48:55] So if I said, tell me a dad joke of joke should be its story format.
[48:55 - 48:58] What's fun of time with dad to say so?
[48:58 - 48:59] They were walking around.
[48:59 - 49:02] So I'm sure they're curious about this as a primate.
[49:02 - 49:03] OK, run.
[49:03 - 49:05] Does this look like it met the prompt?
[49:05 - 49:06] Let's go ahead and say, yeah, sure.
[49:06 - 49:07] It looks like a story.
[49:07 - 49:08] It looks like a joke.
[49:08 - 49:13] I didn't laugh, but we're going to go ahead and just call that.
[49:13 - 49:14] And we're just going to evaluate that as done.
[49:14 - 49:15] Let's go to the next one.
[49:15 - 49:17] This is another joke.
[49:17 - 49:18] Another story.
[49:18 - 49:20] This one's a little bit longer.
[49:20 - 49:22] Dad laughed and said, well, I guess you could say that
[49:22 - 49:23] deal was half day.
[49:23 - 49:24] It does start with once upon a time.
[49:24 - 49:26] So it does sort of look like a story.
[49:26 - 49:30] OK, let's go ahead and say, maybe that's correct too.
[49:30 - 49:33] Let's go ahead and do finish that up.
[49:33 - 49:35] Let's say that for whatever reason,
[49:35 - 49:37] we think that the joke doesn't quite match.
[49:37 - 49:40] Maybe it's not actually funny for us.
[49:40 - 49:41] Maybe we're not just a fan of it.
[49:41 - 49:43] And maybe we're tired of seeing this repetitive.
[49:43 - 49:46] Like we're kind of starting to see a pattern here
[49:46 - 49:48] for whatever reason.
[49:48 - 49:50] Let's say that for what some arbitrary reason,
[49:50 - 49:51] I don't like this joke.
[49:51 - 49:55] I'm going to go ahead and label that as incorrect.
[49:55 - 49:56] I'm not interested in using that.
[49:56 - 49:59] I'm going to go ahead and click Done.
[49:59 - 50:04] And I want to make sure that I'm adding about the data set.
[50:04 - 50:07] Let's say this one's correct too.
[50:07 - 50:09] I'm going to go ahead and click Done with that one.
[50:09 - 50:11] And this one isn't so much of a story,
[50:11 - 50:13] so I'm just going to go ahead and click that as incorrect.
[50:13 - 50:15] Label that done.
[50:15 - 50:18] So that should be good.
[50:18 - 50:21] Let's see if I added this to my data sets automatically.
[50:21 - 50:22] Yes.
[50:22 - 50:26] So as part of my data sets, how I did that,
[50:26 - 50:27] I'm directly to it by that.
[50:27 - 50:30] I forgot to be adding these tools to the keys themselves.
[50:30 - 50:33] So the other thing is as part of the annotation key,
[50:33 - 50:37] you can also add those tools to the data set itself.
[50:37 - 50:39] But if you just like I just did now,
[50:39 - 50:43] forgot to add it to the tool itself.
[50:43 - 50:45] Let's go back to the run sequence.
[50:45 - 50:48] Just going to go ahead and take all of these objects
[50:48 - 50:52] added to the data set.
[50:52 - 50:54] You just submit that as part of the data set.
[50:54 - 50:58] And I think I said that one was correct.
[50:58 - 51:00] This one was correct.
[51:00 - 51:08] And I think I decided that last one was correct.
[51:08 - 51:12] So we're going to add that to the data set itself.
[51:12 - 51:14] Submit that in.
[51:14 - 51:15] And when I look at the data set,
[51:15 - 51:18] I now have an input output based information
[51:18 - 51:21] that gives me both information about the output,
[51:21 - 51:25] what it was created, and how that information worked.
[51:25 - 51:27] Excuse me.
[51:27 - 51:30] So this is essentially where we are
[51:30 - 51:32] beginning to like create a data set of the prompts
[51:32 - 51:35] that worked for us.
[51:35 - 51:39] These were the elements where as part of that framework
[51:39 - 51:41] or as part of that team dynamic,
[51:41 - 51:43] we checked in with our other users
[51:43 - 51:44] and the other users in our environment
[51:44 - 51:47] and essentially said, hey, this joke worked.
[51:47 - 51:49] Open AI did a good job here.
[51:49 - 51:50] The other two that we've decided
[51:50 - 51:52] to keep out of the data set that now works.
[51:52 - 51:55] So we implied those values as an evaluation
[51:55 - 51:59] of zero, not correct outputs for the prompts we created.
[51:59 - 52:03] There's a few other things that we can also look at.
[52:03 - 52:05] Like, if we're not feeling like going through every single joke
[52:05 - 52:07] and determining whether it's correct,
[52:07 - 52:10] open AI and some of the other packages
[52:10 - 52:11] have evaluators that essentially create
[52:11 - 52:13] this in an automatic environment.
[52:13 - 52:17] So all you need to do is just select the new experiment
[52:17 - 52:19] and you can see that it's pretty much the same code
[52:19 - 52:20] over and over again.
[52:20 - 52:23] All you're really doing is just adding a line of code
[52:23 - 52:25] to the evaluators at the end.
[52:25 - 52:28] So you can evaluate each output
[52:28 - 52:31] or if you wish to include that information
[52:31 - 52:33] for correctness, relevance, and helpfulness.
[52:33 - 52:38] And each one of these terms has its own specific definition.
[52:38 - 52:39] A lot of these definitions, these evaluators
[52:39 - 52:41] are essentially built to look
[52:41 - 52:44] or specifically keywords or specific embeddings
[52:44 - 52:49] that would follow or fit that specific evaluation.
[52:50 - 52:54] But again, this is if you wanna automate that process,
[52:54 - 52:56] that's an option that you have.
[52:56 - 52:59] And this is simply something that you code through,
[52:59 - 53:01] apply into the model itself
[53:01 - 53:06] and build it into your particular platform.
[53:06 - 53:10] But that is step one,
[53:10 - 53:12] and that is essentially one of the advantages
[53:12 - 53:17] of using LancsNet as part of your evaluation process.
[53:18 - 53:20] Okay, I've got maybe about seven minutes ago,
[53:20 - 53:22] so I might go a little bit above time.
[53:22 - 53:24] But let's talk about this.
[53:24 - 53:27] I've now got three jokes that I decided
[53:27 - 53:31] arbitrarily or that we decided as part of the class
[53:31 - 53:31] kind of worked.
[53:33 - 53:36] So what I want is, I wanna bring this back in.
[53:41 - 53:44] And I'm going to take them back to my prompting panel.
[53:44 - 53:49] So I'm going to open up another tool here.
[53:49 - 53:53] And what I want to showcase is how do we use
[53:53 - 53:57] Lancchains tool, I might have to bounce
[53:57 - 54:02] a little bit between, but just to be able to let us see this.
[54:02 - 54:04] This is a, this is pretty much,
[54:04 - 54:08] this is similar to what we can create within LancsNet.
[54:08 - 54:11] But let's say that we've already done the evaluation.
[54:11 - 54:13] We've determined that those three jokes
[54:13 - 54:14] are the best dad jokes ever.
[54:14 - 54:15] They're not, I read them,
[54:15 - 54:17] just skimming through them, they look terrible.
[54:17 - 54:21] But let's say we want our LLM to start creating dad jokes
[54:21 - 54:23] that follow that same framework.
[54:23 - 54:26] Well, there's a bit, like the bit of code
[54:26 - 54:28] just requires us to create
[54:28 - 54:33] and create, use those jokes that we used as the prompts
[54:34 - 54:38] for our model to create the next set of jokes,
[54:38 - 54:41] following what it learned from reading
[54:41 - 54:44] those prompts that we created earlier.
[54:44 - 54:48] So I'm going to use two tools, the chat prompt template
[54:48 - 54:51] and the few shot chat message prompt template.
[54:51 - 54:54] And this is where the few shot prompting comes into play.
[54:54 - 54:57] And the way this works, and again,
[54:57 - 54:59] otherwise everything else is the same.
[54:59 - 55:01] I'm using the low dot environment to call the environment.
[55:01 - 55:03] I'm accessing, not actually accessing
[55:03 - 55:05] LLM at this point, I'm just doing this
[55:05 - 55:09] from the joke itself,
[55:09 - 55:11] from like, from the jokes themselves.
[55:11 - 55:15] So I'm just going to go ahead and take these jokes.
[55:15 - 55:18] And it's going to be a little bit manual.
[55:18 - 55:22] But what I'm going to do is I'm going to add to these jokes,
[55:22 - 55:29] the output that you would for that specific tool.
[55:29 - 55:31] Let me just go ahead and add,
[55:31 - 55:34] because I decided to use three jokes here.
[55:34 - 55:35] Let's leave that.
[55:35 - 55:40] So my input is tell me the joke should be in story format.
[55:40 - 55:43] So I'm just going to update the output I got
[55:43 - 55:44] from those three jokes.
[55:44 - 55:48] So bear with me, this is going to be a little bit manual.
[55:48 - 55:52] I'm going to copy that output, put that there.
[55:52 - 55:55] So that was a messier than I wanted that to be.
[55:55 - 56:02] But sorry, bear with me for five seconds.
[56:02 - 56:12] Right, too many, too much of that.
[56:12 - 56:15] Much of that, I might limit myself to two,
[56:15 - 56:20] because this is this might get tedious.
[56:20 - 56:23] And the other joke I'm creating is the same thing.
[56:23 - 56:25] Both of these jokes, actually that's a pretty good example.
[56:25 - 56:29] Once upon a time there's that, but it starts the same way.
[56:29 - 56:30] Let's do that.
[56:30 - 56:32] Let's do that.
[56:32 - 56:35] Let's do that.
[56:36 - 56:52] That is a lot of dialogue here.
[56:52 - 56:54] OK, let's see.
[56:54 - 56:56] I'll put this that look right.
[56:56 - 56:58] All right, so let's clean this up a little bit.
[56:58 - 57:00] All right, so I have two sets of inputs.
[57:00 - 57:01] So I'm just going to use two prompts.
[57:01 - 57:03] Those are my few shots here.
[57:03 - 57:05] That works.
[57:05 - 57:08] All right, so from here, my example prompt
[57:08 - 57:11] is taking the chat prompt template from these messages,
[57:11 - 57:13] from these examples that I just created.
[57:13 - 57:15] Both of these jokes start with once upon a time.
[57:15 - 57:18] There was a dad or a dad.
[57:18 - 57:20] So both of these jokes are going to start out the way.
[57:20 - 57:23] And the human message is essentially always going to be,
[57:23 - 57:25] or you would presume that the input,
[57:25 - 57:28] when you get an input, that looks like,
[57:28 - 57:28] tell me a dad joke.
[57:28 - 57:30] The joke should be in story format.
[57:30 - 57:33] The output should look something like this.
[57:33 - 57:35] And this few shot prompt is essentially
[57:35 - 57:38] going to be taking that prompt template
[57:38 - 57:40] from the example prompts that we created above.
[57:40 - 57:43] And it's going to be taking a case from the examples
[57:43 - 57:49] that we used in our prompts from earlier.
[57:49 - 57:53] And format those jokes so that they potentially
[57:53 - 57:55] look a little bit alike this.
[57:55 - 57:57] So any time the human asks something about a dad joke,
[57:57 - 58:00] the joke should be in story format,
[58:00 - 58:05] we can expect the AI to respond something like this.
[58:05 - 58:06] Let's try that out.
[58:06 - 58:09] We've trained our model quote unquote
[58:09 - 58:11] with the framework or the prompts
[58:11 - 58:13] that we created earlier.
[58:13 - 58:16] And I want to add one final prompt, which
[58:16 - 58:19] is I'm telling the system we're adding a system message
[58:19 - 58:21] just to make sure that this is working
[58:21 - 58:24] or that the model has learned from both the prompts
[58:24 - 58:25] and the information that I've created.
[58:25 - 58:27] I want all of these jokes and with the phrase
[58:27 - 58:31] visinga, because I'm terrible like that sometimes.
[58:31 - 58:34] Still going to follow the few shot prompts
[58:34 - 58:37] and still going to require that human input.
[58:37 - 58:39] So if I have this run on its own,
[58:39 - 58:43] I'm going to use the Langshan chat open AI, just importing that.
[58:43 - 58:45] And I'm going to call that final prompt.
[58:45 - 58:47] And again, essentially just informing the chain
[58:47 - 58:50] that I'm going to be using as part of open AI.
[58:50 - 58:53] Remember that with chat open AI on Monday,
[58:53 - 58:57] we created a chat open AI tool that invoked the information
[58:57 - 58:59] or the call.
[58:59 - 59:01] In this case, the difference is that I'm
[59:01 - 59:04] calling the final prompt first so that it actually,
[59:04 - 59:06] the chain actually learns from the information
[59:06 - 59:08] I shared in that final prompt, the examples
[59:08 - 59:10] I created earlier.
[59:10 - 59:14] And again, the few shot prompts are already built into that final
[59:14 - 59:15] prompt.
[59:15 - 59:17] I've got it set to a temperature of 7.
[59:17 - 59:20] And I'm actually asking the joke so that it follows
[59:20 - 59:24] the joke to be in that story format.
[59:24 - 59:26] And I should probably include and string up parts of what
[59:26 - 59:28] I'm not going to do that.
[59:28 - 59:28] So all right.
[59:28 - 59:32] And now, when I've run the package,
[59:32 - 59:34] I've added somewhat quite a bit amount of creativity.
[59:34 - 59:37] Let me just go ahead and add a little bit more creativity.
[59:37 - 59:39] And I'm just going to run this a few times.
[59:39 - 59:41] But once upon a time, my dad was helping
[59:41 - 59:44] his son with his math homework, a terrible joke.
[59:44 - 59:46] And even though he was still frustrating with the math,
[59:46 - 59:48] oh, didn't he mount and clean with a single?
[59:48 - 59:49] Did I miss that mark?
[59:49 - 59:56] Run that, run that, let's see.
[59:56 - 59:56] Oh, there he is.
[59:56 - 59:57] All right.
[59:57 - 59:58] So there's the busy end beyond.
[59:58 - 59:59] So that's correct.
[59:59 - 01:00:00] Once upon a time, there was a daddy while he's
[01:00:00 - 01:00:02] dreamed of being a comedic great.
[01:00:02 - 01:00:03] So let's try this again.
[01:00:03 - 01:00:05] This is three times.
[01:00:05 - 01:00:07] Once upon a time, my dad decided to use that.
[01:00:07 - 01:00:09] So now we're seeing that all of the jokes that
[01:00:09 - 01:00:12] we're starting to come out have the information
[01:00:12 - 01:00:13] from the prompts that we created earlier.
[01:00:13 - 01:00:15] And again, that's because we, as a group,
[01:00:15 - 01:00:18] decided that the prompts or a good dad joke
[01:00:18 - 01:00:21] must start with once upon a time,
[01:00:21 - 01:00:23] and or at least the two prompts that we use all
[01:00:23 - 01:00:27] had to start with once upon a time.
[01:00:27 - 01:00:28] And this is essentially where you start to,
[01:00:28 - 01:00:31] even with a temperature of high as 0.09,
[01:00:31 - 01:00:34] like that framework, that structure,
[01:00:34 - 01:00:41] that those elements of those elements
[01:00:41 - 01:00:45] of the model of the prompts are essentially helping us
[01:00:45 - 01:00:50] inform what we want our model to return and look like.
[01:00:50 - 01:00:51] All right.
[01:00:51 - 01:00:53] So what does that mean?
[01:00:53 - 01:00:56] This is something that we can essentially
[01:00:56 - 01:00:59] help determine using a tool like Lancement.
[01:00:59 - 01:01:01] We can essentially do all of this in Python JavaScript,
[01:01:01 - 01:01:04] whatever tool you want to use, and essentially build
[01:01:04 - 01:01:06] and manually create what prompts seems to work for you
[01:01:06 - 01:01:11] and add that into like a future LLM
[01:01:11 - 01:01:13] that you would build on your own.
[01:01:13 - 01:01:15] Or you could essentially use a tool that essentially keeps
[01:01:15 - 01:01:20] all of the calls you've made in a nice organized fashion.
[01:01:20 - 01:01:23] So Lancement, on top of a couple of other different features
[01:01:23 - 01:01:24] that we're going to be working with,
[01:01:24 - 01:01:27] has a method and certain set love sets of tools
[01:01:27 - 01:01:33] that allow you to kind of annotate, evaluate,
[01:01:33 - 01:01:36] and determine whether a specific step is worthwhile
[01:01:36 - 01:01:38] for you to use.
[01:01:38 - 01:01:41] One thing I didn't mention as part of the annotation tool,
[01:01:41 - 01:01:44] let me just go ahead and showcase that one more time.
[01:01:44 - 01:01:49] We go back to this dad and show a tool basis.
[01:01:52 - 01:01:53] There it is, there's the run.
[01:01:53 - 01:01:57] Let me just go ahead and add that back to the annotation queue.
[01:01:57 - 01:02:00] Okay, I'm gonna go back to the judgment.
[01:02:00 - 01:02:03] You can actually modify your tools
[01:02:03 - 01:02:05] as like your evaluations as well.
[01:02:05 - 01:02:08] So this is where like a human or a team member
[01:02:08 - 01:02:09] can essentially all sit down and be like,
[01:02:09 - 01:02:13] I don't like how open AI is like building out these prompts.
[01:02:13 - 01:02:17] Maybe a human can like help create a better joke,
[01:02:17 - 01:02:20] for example, to like structure this in a better way.
[01:02:20 - 01:02:21] And once you've done that,
[01:02:21 - 01:02:22] you can then add that back into the data set.
[01:02:22 - 01:02:24] That was the stuff that I wasn't doing
[01:02:24 - 01:02:31] as I was going through the annotation tool.
[01:02:31 - 01:02:35] Fun stuff, thank you, we'll use it.
[01:02:35 - 01:02:37] Maybe, I don't know.
[01:02:37 - 01:02:39] Well, if you don't use that, we also again,
[01:02:39 - 01:02:40] like I said, Langfuse is another option.
[01:02:40 - 01:02:43] A lot of the same things work very similarly.
[01:02:45 - 01:02:47] I haven't used, to be honest, I haven't used Langfuse
[01:02:47 - 01:02:49] a whole lot, it is Jonathan.
[01:02:49 - 01:02:53] Do we know how old Langfuse is currently,
[01:02:53 - 01:02:57] or how long have it's been around town?
[01:02:57 - 01:02:59] I'm not exactly sure.
[01:02:59 - 01:03:01] I heard of it a while back,
[01:03:01 - 01:03:03] but the first time I've messed with it
[01:03:03 - 01:03:05] was a few days ago when it got brought up.
[01:03:05 - 01:03:07] Say, no.
[01:03:07 - 01:03:08] No, but it looks really cool.
[01:03:08 - 01:03:11] I mean, if it's your dime on it,
[01:03:11 - 01:03:15] I'm not a bit like I would recommend it.
[01:03:19 - 01:03:21] Let me just check my notes here.
[01:03:21 - 01:03:24] Yeah, but that is about it.
[01:03:24 - 01:03:27] We are showcasing here how to use Langsmith
[01:03:27 - 01:03:28] and essentially showcasing a place
[01:03:28 - 01:03:31] where you can now build like the code that you built,
[01:03:31 - 01:03:33] the things that your model's evaluated.
[01:03:33 - 01:03:35] You now have a place where you can look and study
[01:03:35 - 01:03:37] and analyze and think about whether
[01:03:38 - 01:03:41] those tools work for you behind the scenes
[01:03:42 - 01:03:46] and the next step is up to you to practice with this
[01:03:46 - 01:03:48] and literally like laying around with us
[01:03:48 - 01:03:51] it's a very easy user interface.
[01:03:51 - 01:03:52] You won't get too hung up on this,
[01:03:52 - 01:03:54] like you'll find everything that you need to do
[01:03:54 - 01:03:55] fairly quickly.
[01:03:55 - 01:03:57] But one of the things we're going to recommend
[01:03:57 - 01:03:59] for you to practice with one of their homeworks
[01:03:59 - 01:04:03] is to take a look at all of these different reviews,
[01:04:04 - 01:04:07] build them into like think of them as customer feedback
[01:04:07 - 01:04:12] from a particular company and just determine
[01:04:12 - 01:04:15] what the results would look like in Langsmith.
[01:04:15 - 01:04:18] So you determine what is a good response,
[01:04:18 - 01:04:20] what is a good review
[01:04:20 - 01:04:25] and determine from there, assign it to a data set.
[01:04:25 - 01:04:28] You want to prompt it so that you can now create
[01:04:28 - 01:04:31] for the person who I think there was one person in the class,
[01:04:31 - 01:04:34] wanted to like start creating a Twitter bots
[01:04:34 - 01:04:36] or something like that.
[01:04:36 - 01:04:38] This is how you can begin to determine
[01:04:38 - 01:04:40] what kind of tweet, Twitter bot message
[01:04:40 - 01:04:45] you want to start creating.
[01:04:45 - 01:04:47] That's it.
[01:04:47 - 01:04:49] That's all I have for you today.
[01:04:49 - 01:04:53] So you are released unless you have any questions
[01:04:53 - 01:04:55] you'd like to take a look at something
[01:04:55 - 01:04:57] a little bit more deeply.
[01:04:57 - 01:04:59] Feel free to stick around.
[01:04:59 - 01:05:03] Both Jonathan and I are here for the next few moments.
[01:05:03 - 01:05:09] Thank you.
[01:05:09 - 01:05:11] Hopefully you'll have some fun with this.
[01:05:11 - 01:05:44] Have a wonderful evening otherwise.
[01:05:44 - 01:05:47] Projects.
[01:05:47 - 01:05:48] Yeah, all right.
[01:05:48 - 01:05:49] Oh, wow.
[01:05:49 - 01:05:50] Oh, my gosh, I just looked at myself
[01:05:50 - 01:05:52] and I am sitting in darkness.
[01:05:52 - 01:05:54] That.
[01:05:54 - 01:06:15] Ah.
[01:06:15 - 01:06:19] It's up to Julian that I've lied.
[01:06:19 - 01:06:22] Lang came for and you mentioned it a little bit
[01:06:22 - 01:06:26] of playground is just going straight from the trace
[01:06:26 - 01:06:29] into the playground you were talking about
[01:06:29 - 01:06:30] trying to decide models.
[01:06:30 - 01:06:33] Most of them you have to use put an API key in there.
[01:06:33 - 01:06:37] I've got some API keys in mind and they have a couple
[01:06:37 - 01:06:39] free options like chat fireworks,
[01:06:39 - 01:06:41] but you can actually experiment around
[01:06:41 - 01:06:43] with the different models and see the same response
[01:06:43 - 01:06:46] based on the prompt and change the parameters
[01:06:46 - 01:06:48] and it logs all of that.
[01:06:48 - 01:06:50] So I actually use that at work
[01:06:50 - 01:06:52] when we were arguing.
[01:06:52 - 01:06:56] Professionally arguing about what model we were going
[01:06:56 - 01:06:57] to use for something.
[01:06:57 - 01:07:00] And it was the first time I had seen it use.
[01:07:00 - 01:07:03] This was a couple months ago, I guess.
[01:07:03 - 01:07:06] The actual playground that we were messing around
[01:07:06 - 01:07:08] in the playground and saving all the outputs in.
[01:07:08 - 01:07:12] And it's pretty handy for a tool
[01:07:12 - 01:07:17] that we all picked up on using within an hour or so.
[01:07:17 - 01:07:18] Yeah.
[01:07:18 - 01:07:19] From what I saw from the curriculum,
[01:07:19 - 01:07:23] it looks like the playground comes into the vogue a lot
[01:07:23 - 01:07:25] in what we started talking about the valuation
[01:07:25 - 01:07:28] of the fine tuning, but it could be meant,
[01:07:28 - 01:07:31] but yeah, no, I feel like if that's something I missed,
[01:07:31 - 01:07:34] I'm happy to like go deeper into it
[01:07:34 - 01:07:38] on connecting the next session for sure.
[01:07:38 - 01:07:40] Yeah, when you're in it, all you gotta,
[01:07:40 - 01:07:41] when you're on a specific trace,
[01:07:41 - 01:07:46] if you just hit the playground, the playground opens up
[01:07:46 - 01:07:49] and it'll bring the input and output into the playground
[01:07:49 - 01:07:52] and you can just on the side, there's a side bar
[01:07:52 - 01:07:55] where you can start choosing providers and models,
[01:07:55 - 01:07:58] set temperatures and tokens and whatnot.
[01:07:58 - 01:08:00] Now it's, I just went into it now
[01:08:00 - 01:08:04] because with that 3.5, my results were less than stellar
[01:08:04 - 01:08:07] and funny enough, one of their free models
[01:08:07 - 01:08:09] was giving me incredibly better results
[01:08:09 - 01:08:12] with the cat fireworks without even using tokens on
[01:08:12 - 01:08:16] that I'm paying for.
[01:08:16 - 01:08:20] Yeah, I guess I didn't touch on that.
[01:08:21 - 01:08:25] That's good.
[01:08:25 - 01:08:27] No, yeah, I didn't really, really,
[01:08:27 - 01:08:30] let me just go over that.
[01:08:30 - 01:08:35] Yeah, there's a lot to Lang Smith.
[01:08:35 - 01:08:41] I'm hoping to the end of the second on Tuesday.
[01:08:41 - 01:08:45] Are there, I was trying to think about my question is,
[01:08:45 - 01:08:48] today's lesson felt to me a little like the 10 minute
[01:08:48 - 01:08:51] video that you all sent, like there's a huge amount
[01:08:51 - 01:08:52] of information and there's a huge amount of like
[01:08:52 - 01:08:54] capability in the platform.
[01:08:54 - 01:08:58] I still don't necessarily feel clarity, I suppose.
[01:08:58 - 01:09:02] And that's also just because obviously it's only been an hour.
[01:09:02 - 01:09:04] I'm curious if there's any resources you recommend
[01:09:04 - 01:09:05] outside the ones that you've already posted.
[01:09:05 - 01:09:07] Otherwise, I still need to watch the one hour one
[01:09:07 - 01:09:12] and the deep dive documentation.
[01:09:12 - 01:09:13] Julian?
[01:09:13 - 01:09:17] Oh, I mean, I mean, my process of learning
[01:09:17 - 01:09:19] is not a process I recommend.
[01:09:19 - 01:09:22] I spend a lot of time at the documentation.
[01:09:23 - 01:09:27] So it's essentially, my methods is extremely academic.
[01:09:27 - 01:09:29] It is very much just making sure that I understand
[01:09:29 - 01:09:31] like what each class, what each function is doing
[01:09:31 - 01:09:34] to find the scenes and then making sure
[01:09:34 - 01:09:35] I've put it into practice somehow.
[01:09:35 - 01:09:37] It is time consuming.
[01:09:38 - 01:09:42] So you know, the YouTube bit, like there are,
[01:09:42 - 01:09:44] there are not a lot of good YouTube videos out there.
[01:09:44 - 01:09:45] Yeah.
[01:09:45 - 01:09:47] Like it is, like they're all at least 10 years old
[01:09:47 - 01:09:51] and all of the methods have gotten like completely outdated.
[01:09:53 - 01:09:57] So my current, my current tech,
[01:09:57 - 01:10:03] like my current best recommendation is just exhaustive.
[01:10:03 - 01:10:06] Yeah, I was going to go like one by line
[01:10:06 - 01:10:09] through the implementation and like, what a soup strainer.
[01:10:09 - 01:10:10] Okay, here's soup strainer.
[01:10:10 - 01:10:12] It is, it is tedious.
[01:10:13 - 01:10:18] And like I can't vouch by, I can't vouch to it's effectiveness
[01:10:18 - 01:10:21] but it is like I read it once
[01:10:21 - 01:10:23] and I know how to come back to it down the road.
[01:10:24 - 01:10:26] Yeah, no, you're right that the resources are like this
[01:10:26 - 01:10:30] like Smith is still changing so rapidly
[01:10:30 - 01:10:33] that it's hard to find but Jonathan, what do you,
[01:10:33 - 01:10:35] what do you, what have you found?
[01:10:35 - 01:10:39] That video that, that's posted the hour long video
[01:10:39 - 01:10:42] that came out four or five months ago,
[01:10:42 - 01:10:45] that's the first video I would watch the hour long video.
[01:10:45 - 01:10:50] It's the 10 minute video is, he goes over that same stuff
[01:10:50 - 01:10:52] but he covers a lot more.
[01:10:52 - 01:10:54] I watched that hour long video
[01:10:54 - 01:10:57] and then my way of learning is to make,
[01:10:57 - 01:11:00] sometimes I find myself lost in documents
[01:11:00 - 01:11:02] and then I just like to start experimenting
[01:11:02 - 01:11:05] and seeing what I can do with it.
[01:11:05 - 01:11:09] And that's how I learned my, the one,
[01:11:10 - 01:11:15] the one good video I would recommend that I've seen
[01:11:15 - 01:11:17] is the one that I put up there for the hour
[01:11:17 - 01:11:20] because you're not gonna spend half a day watching it
[01:11:20 - 01:11:21] but it's a pretty good wrap up
[01:11:21 - 01:11:23] and it's pretty up to date, it's only,
[01:11:23 - 01:11:25] I'm looking at it now it's four,
[01:11:25 - 01:11:27] came out four or four and a half months ago,
[01:11:27 - 01:11:27] it looks like.
[01:11:29 - 01:11:34] It goes through that and then just start messing
[01:11:34 - 01:11:36] with the homework or messing with your own projects
[01:11:36 - 01:11:41] or that's my way of learning.
[01:11:41 - 01:11:44] Yeah, it makes sense, so.
[01:11:44 - 01:11:47] I think I'm adapting to this course
[01:11:47 - 01:11:48] because I like the deep dive
[01:11:48 - 01:11:52] but it's like deep diving plus working with the full day
[01:11:52 - 01:11:56] and finding that extra hour to get into one of these things.
[01:11:56 - 01:11:57] Okay, I'll have a life.
[01:11:57 - 01:12:01] Yeah, it's all good, I appreciate it.
[01:12:04 - 01:12:08] But sure, so I do want to touch on that feedback
[01:12:08 - 01:12:10] because that's good feedback to you.
[01:12:10 - 01:12:13] It sounds to be like you wanted a deeper dive.
[01:12:13 - 01:12:17] I think like we jumped into lane chain
[01:12:22 - 01:12:24] and then started running queries
[01:12:24 - 01:12:27] and kind of like digging into run feedback, metadata,
[01:12:27 - 01:12:27] et cetera, et cetera.
[01:12:27 - 01:12:31] And then you did the section with the documentation
[01:12:31 - 01:12:34] where you walk through, let me go through it here.
[01:12:34 - 01:12:37] Like the rag build out kind of step by step.
[01:12:37 - 01:12:41] I think as I'm saying it out loud,
[01:12:41 - 01:12:42] I think you actually explain it reasonably well.
[01:12:42 - 01:12:45] Like the, like putting together the chain
[01:12:45 - 01:12:46] essentially all that works.
[01:12:46 - 01:12:49] It's just like you said, I just need to actually like
[01:12:49 - 01:12:52] go in and say, okay, what is the retriever actually doing
[01:12:52 - 01:12:54] diving into the format docs function,
[01:12:54 - 01:12:58] diving into what runable pass through means, et cetera.
[01:12:58 - 01:12:58] Oh, yeah.
[01:12:58 - 01:13:02] And yeah, we're gonna, and yeah, as like with each class,
[01:13:02 - 01:13:05] I think I'm spending a lot more time
[01:13:05 - 01:13:09] defining each term, looking at like what's happening behind
[01:13:09 - 01:13:10] the scenes with each term.
[01:13:10 - 01:13:12] I think a little bit more next week
[01:13:12 - 01:13:14] when we start looking at rag is because
[01:13:17 - 01:13:18] despite the fact that the comments
[01:13:18 - 01:13:21] are evolving like one of the things that I want to make sure
[01:13:21 - 01:13:24] is that, you know, I believe there's,
[01:13:24 - 01:13:25] I believe there's a wide,
[01:13:25 - 01:13:27] but like a wide stretch of experience here.
[01:13:27 - 01:13:30] There might be a few folks who are still very new
[01:13:30 - 01:13:33] to Lang Smith, I need an open AI.
[01:13:33 - 01:13:35] So like I want to try to make sure
[01:13:35 - 01:13:36] that we're all on the same page.
[01:13:36 - 01:13:38] Yeah, and that would be great.
[01:13:38 - 01:13:41] And that category includes me other than using chat
[01:13:41 - 01:13:42] to be like everyone else I guess.
[01:13:42 - 01:13:43] Perfect.
[01:13:43 - 01:13:44] Okay, so yeah, so I think what I,
[01:13:44 - 01:13:46] like that's good feedback because what I can do
[01:13:46 - 01:13:48] is actually make sure to have
[01:13:50 - 01:13:53] quick column flashcards for each one of the
[01:13:54 - 01:13:55] like a brand new.
[01:13:55 - 01:13:56] Yeah, that would be excellent.
[01:13:56 - 01:13:57] Actually,
[01:13:58 - 01:14:01] other logistical question for homework.
[01:14:01 - 01:14:04] Are we only submitting through the post that you're making,
[01:14:04 - 01:14:08] Jonathan, or is there another route for that?
[01:14:08 - 01:14:13] So, yeah, the homework, submitting it as optional,
[01:14:16 - 01:14:19] the feedback a lot of times will be pretty minimal.
[01:14:19 - 01:14:21] And if you've got a specific question,
[01:14:21 - 01:14:23] would be glad to address that.
[01:14:23 - 01:14:25] But yeah, I'm going to make a thread,
[01:14:25 - 01:14:28] put the link into the thread,
[01:14:28 - 01:14:31] and that now your guided projects will be different.
[01:14:31 - 01:14:33] The guided projects will go into the,
[01:14:33 - 01:14:36] the four guided projects will go into the portal
[01:14:36 - 01:14:38] and there'll be a specific process for that
[01:14:38 - 01:14:43] and that'll be more reviewed and more depth.
[01:14:43 - 01:14:44] But yeah, for the homework,
[01:14:44 - 01:14:45] if you want somebody to look over it,
[01:14:45 - 01:14:46] if you've got any questions,
[01:14:46 - 01:14:48] if you just want to throw it out there,
[01:14:48 - 01:14:50] put it in that thread ideally because that,
[01:14:50 - 01:14:53] I keep an eye on it and I'll see it there.
[01:14:53 - 01:14:55] And something I was going to throw in
[01:14:55 - 01:14:58] about what I think you'll find with this course.
[01:14:58 - 01:15:00] So like for me, I've been an engineer for a while,
[01:15:00 - 01:15:05] I got into AI and ML a while ago.
[01:15:05 - 01:15:08] I come from mostly with my work,
[01:15:08 - 01:15:13] an ML background and was working with OpenAI and Langchain
[01:15:14 - 01:15:16] and a little bit of Langsmith.
[01:15:16 - 01:15:19] I've done this course and I think that you'll find
[01:15:19 - 01:15:22] a lot of the questions during the first weeks.
[01:15:22 - 01:15:25] I'll build up and when we start getting into agents,
[01:15:25 - 01:15:27] everything kind of falls together
[01:15:27 - 01:15:30] and it's like, oh, okay, that makes sense
[01:15:30 - 01:15:32] why we were doing that.
[01:15:32 - 01:15:37] This has been, it'll, because I like the deep dive as well.
[01:15:37 - 01:15:38] I mean, I can't even talk about the times
[01:15:38 - 01:15:42] I've deep dove into the layers of neural nets
[01:15:42 - 01:15:45] with pie torches and transformations
[01:15:45 - 01:15:49] and everything imaginable under the sun,
[01:15:49 - 01:15:52] just wasting hours and hours and hours doing it.
[01:15:52 - 01:15:56] But with the course, I think you'll see
[01:15:56 - 01:15:59] in a couple of weeks, everything's starting to come together
[01:15:59 - 01:16:02] and by the time it gets done,
[01:16:02 - 01:16:07] that you'll walk away with a good understanding
[01:16:07 - 01:16:09] of all these technologies and the ability
[01:16:09 - 01:16:13] to implement the agents and the multi-agent systems
[01:16:13 - 01:16:14] confidently.
[01:16:20 - 01:16:22] I appreciate the extra context.
[01:16:22 - 01:16:24] I gotta drop, gotta go make dinner
[01:16:24 - 01:16:25] but I hope you too have an idea.
[01:16:25 - 01:16:26] Call.
[01:16:26 - 01:16:27] Have a good time.
[01:16:27 - 01:16:29] Thanks.
[01:16:29 - 01:16:31] Thank you guys for everything.
[01:16:31 - 01:16:32] See you.
[01:16:32 - 01:16:33] Bye.
[01:16:33 - 01:16:34] Bye.
[01:16:34 - 01:16:35] Go ahead and pause for a while.
[01:16:35 - 01:16:36] Man.